{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "## 仅供交叉验证 前馈神经网络（NNAR）-按趋势分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from utils import *\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "n_input = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the gene_editing array: (2643, 17, 10)\n",
      "Shape of the transplant array: (5141, 17, 10)\n"
     ]
    }
   ],
   "source": [
    "# gene_arr_path = r'../output/gene_editing/es_with_decay.array'\n",
    "# transplant_arr_path = r'../output/transplant/es_with_decay.array'\n",
    "\n",
    "# gene_arr = pickle.load(open(gene_arr_path, mode='rb'))\n",
    "# transplant_arr = pickle.load(open(transplant_arr_path, mode='rb'))\n",
    "\n",
    "# print('Shape of the gene_editing array:',gene_arr.shape)\n",
    "# print('Shape of the transplant array:',transplant_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 截断数据\n",
    "2019年为无效数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the gene_editing array: (2643, 16, 10)\n",
      "Shape of the transplant array: (5141, 16, 10)\n"
     ]
    }
   ],
   "source": [
    "# gene_arr = gene_arr[:, :-1, :]\n",
    "# transplant_arr = transplant_arr[:, :-1, :]\n",
    "\n",
    "# print('Shape of the gene_editing array:',gene_arr.shape)\n",
    "# print('Shape of the transplant array:',transplant_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 规范数据并获取5折交叉检验所需的训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler, data = scale_data(transplant_arr, 'standard')\n",
    "\n",
    "# # 用预测第二年的类别变量作为分成Kfold的依据，不支持浮点数\n",
    "# X, y, y_cat = data[:, :n_input, :], data[:, n_input:, -2],transplant_arr[:, n_input, -1]\n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按趋势划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_by_trend(data, targets):\n",
    "    up_data = []\n",
    "    down_data = []\n",
    "    up_target = []\n",
    "    down_target = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        a, b = np.polyfit(range(len(data[i])), data[i, :, -2].reshape(-1), 1)\n",
    "        if a > 0:\n",
    "            up_data.append(data[i])\n",
    "            up_target.append(targets[i])\n",
    "        else:\n",
    "            down_data.append(data[i])\n",
    "            down_target.append(targets[i])\n",
    "    return np.array(up_data), np.array(up_target), np.array(down_data), np.array(down_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.638885614178983"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef([1,2,9,4,9,6], [1,2,3,4,5,6])[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return keras.backend.sqrt(keras.backend.mean(keras.backend.square(y_pred - y_true), axis=-1)) \n",
    "\n",
    "def build_direct_dnn_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(5))\n",
    "    \n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(loss=root_mean_squared_error, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进行训练和评估\n",
    "使用EarlyStopping和Checkpoint做训练停止方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, y, y_cat, kfold, scaler):\n",
    "    overall_metrics = {\n",
    "        'mae':[],\n",
    "        'rmse':[],\n",
    "        'ndcg':[]\n",
    "    }\n",
    "\n",
    "    annual_metrics = {\n",
    "        'mae':[],\n",
    "        'rmse':[],\n",
    "        'ndcg':[]\n",
    "    }\n",
    "    for train, test in kfold.split(X, y_cat):\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        models = []\n",
    "        \n",
    "        # 按总量划分数据集\n",
    "        X_train1, y_train1, X_train2, y_train2 = split_data_by_trend(X_train, y_train)\n",
    "        train_xs = [X_train1, X_train2]\n",
    "        train_ys = [y_train1, y_train2]\n",
    "        \n",
    "        X_test1, y_test1, X_test2, y_test2 = split_data_by_trend(X_test, y_test)\n",
    "        test_xs = [X_test1, X_test2]\n",
    "        test_ys = [y_test1, y_test2]\n",
    "        i_s = [1, 2]\n",
    "        \n",
    "        # 训练\n",
    "        for i in range(len(i_s)):\n",
    "            model = build_direct_dnn_model()\n",
    "            history = model.fit(train_xs[i], train_ys[i], epochs=100, batch_size=16, verbose=1, validation_data=(test_xs[i], test_ys[i]),\n",
    "                           callbacks=[\n",
    "                               EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto', restore_best_weights=True)\n",
    "                           ])\n",
    "            models.append(model)\n",
    "        \n",
    "        # 预测\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "        for i in range(len(i_s)):\n",
    "            y_test.append(test_ys[i])\n",
    "            y_pred.append(models[i].predict(test_xs[i]).reshape(test_ys[i].shape))\n",
    "        \n",
    "        y_test = np.concatenate(y_test)\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "\n",
    "        metrics = ['mae', 'rmse','ndcg']\n",
    "        for m in metrics:\n",
    "            overall, annual = eval_model(m, y_test, y_pred, scaler)\n",
    "            overall_metrics[m].append(overall)\n",
    "            annual_metrics[m].append(annual)\n",
    "    \n",
    "    return overall_metrics, annual_metrics\n",
    "\n",
    "#     for train, test in kfold.split(X, y_cat):\n",
    "#         model = build_direct_dnn_model()\n",
    "#         history = model.fit(X[train], y[train], epochs=100, batch_size=16, verbose=1, validation_data=(X[test], y[test]),\n",
    "#                            callbacks=[\n",
    "#                                EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto', restore_best_weights=True)\n",
    "#                            ])\n",
    "\n",
    "#         y_test = y[test]\n",
    "#         y_pred = model.predict(X[test]).reshape(y[test].shape)\n",
    "\n",
    "#         metrics = ['mae', 'rmse','ndcg']\n",
    "#         for m in metrics:\n",
    "#             overall, annual = eval_model(m, y_test, y_pred, scaler)\n",
    "#             overall_metrics[m].append(overall)\n",
    "#             annual_metrics[m].append(annual)\n",
    "    \n",
    "#     return overall_metrics, annual_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline():\n",
    "    gene_arr_path = r'../output/gene_editing/es_with_decay.array'\n",
    "    transplant_arr_path = r'../output/transplant/es_with_decay.array'\n",
    "\n",
    "    gene_arr = pickle.load(open(gene_arr_path, mode='rb'))\n",
    "    transplant_arr = pickle.load(open(transplant_arr_path, mode='rb'))\n",
    "    \n",
    "    gene_arr = gene_arr[:, :-1, :]\n",
    "    transplant_arr = transplant_arr[:, :-1, :]\n",
    "\n",
    "    print('Shape of the gene_editing array:',gene_arr.shape)\n",
    "    print('Shape of the transplant array:',transplant_arr.shape)\n",
    "    \n",
    "    metrics = {\n",
    "        'gene':{\n",
    "            'overall':{},\n",
    "            'annual':{}\n",
    "        },\n",
    "        'transplant':{\n",
    "            'overall':{},\n",
    "            'annual':{}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for name, dataset in zip(['gene', 'transplant'], [gene_arr, transplant_arr]):\n",
    "        scaler, data = scale_data(dataset, 'standard')\n",
    "\n",
    "        # 用预测第二年的类别变量作为分成Kfold的依据，不支持浮点数\n",
    "        X, y, y_cat = data[:, :n_input, :], data[:, n_input:, -2], dataset[:, n_input, -1]\n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        overall_metrics, annual_metrics = cross_validation(X, y, y_cat, kfold, scaler)\n",
    "        \n",
    "        for metric, value in overall_metrics.items():\n",
    "            metrics[name]['overall'][metric] = np.mean(value)\n",
    "        \n",
    "        for metric, value in annual_metrics.items():\n",
    "            metrics[name]['annual'][metric] = np.mean(np.array(value), axis=0)\n",
    "    \n",
    "#     pickle.dump(metrics, open('mlp_metrics.dict', 'wb'))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the gene_editing array: (2643, 16, 10)\n",
      "Shape of the transplant array: (5141, 16, 10)\n",
      "Train on 988 samples, validate on 256 samples\n",
      "Epoch 1/100\n",
      "988/988 [==============================] - 1s 803us/sample - loss: 1.1069 - val_loss: 1.0758\n",
      "Epoch 2/100\n",
      "988/988 [==============================] - 0s 169us/sample - loss: 1.0539 - val_loss: 1.0848\n",
      "Epoch 3/100\n",
      "988/988 [==============================] - 0s 167us/sample - loss: 1.0419 - val_loss: 1.0745\n",
      "Epoch 4/100\n",
      "988/988 [==============================] - 0s 165us/sample - loss: 1.0341 - val_loss: 1.0797\n",
      "Epoch 5/100\n",
      "988/988 [==============================] - 0s 163us/sample - loss: 1.0255 - val_loss: 1.0769\n",
      "Epoch 6/100\n",
      "988/988 [==============================] - 0s 165us/sample - loss: 1.0138 - val_loss: 1.0754\n",
      "Epoch 7/100\n",
      "988/988 [==============================] - 0s 165us/sample - loss: 1.0091 - val_loss: 1.0728\n",
      "Epoch 8/100\n",
      "988/988 [==============================] - 0s 165us/sample - loss: 1.0000 - val_loss: 1.0689\n",
      "Epoch 9/100\n",
      "988/988 [==============================] - 0s 162us/sample - loss: 0.9934 - val_loss: 1.0801\n",
      "Epoch 10/100\n",
      "988/988 [==============================] - 0s 167us/sample - loss: 0.9864 - val_loss: 1.0674\n",
      "Epoch 11/100\n",
      "988/988 [==============================] - 0s 161us/sample - loss: 0.9775 - val_loss: 1.0797\n",
      "Epoch 12/100\n",
      "988/988 [==============================] - 0s 163us/sample - loss: 0.9690 - val_loss: 1.0738\n",
      "Epoch 13/100\n",
      "988/988 [==============================] - 0s 169us/sample - loss: 0.9642 - val_loss: 1.0737\n",
      "Epoch 14/100\n",
      "988/988 [==============================] - 0s 240us/sample - loss: 0.9572 - val_loss: 1.0851\n",
      "Epoch 15/100\n",
      "988/988 [==============================] - 0s 167us/sample - loss: 0.9506 - val_loss: 1.0721\n",
      "Epoch 16/100\n",
      "988/988 [==============================] - 0s 165us/sample - loss: 0.9424 - val_loss: 1.0789\n",
      "Epoch 17/100\n",
      "988/988 [==============================] - 0s 164us/sample - loss: 0.9389 - val_loss: 1.0873\n",
      "Epoch 18/100\n",
      "988/988 [==============================] - 0s 163us/sample - loss: 0.9310 - val_loss: 1.0851\n",
      "Epoch 19/100\n",
      "988/988 [==============================] - 0s 161us/sample - loss: 0.9300 - val_loss: 1.0869\n",
      "Epoch 20/100\n",
      "988/988 [==============================] - 0s 164us/sample - loss: 0.9196 - val_loss: 1.0913\n",
      "Train on 1124 samples, validate on 275 samples\n",
      "Epoch 1/100\n",
      "1124/1124 [==============================] - 1s 906us/sample - loss: 0.7807 - val_loss: 0.7141\n",
      "Epoch 2/100\n",
      "1124/1124 [==============================] - 0s 163us/sample - loss: 0.7653 - val_loss: 0.7134\n",
      "Epoch 3/100\n",
      "1124/1124 [==============================] - 0s 161us/sample - loss: 0.7652 - val_loss: 0.7198\n",
      "Epoch 4/100\n",
      "1124/1124 [==============================] - 0s 164us/sample - loss: 0.7642 - val_loss: 0.7162\n",
      "Epoch 5/100\n",
      "1124/1124 [==============================] - 0s 163us/sample - loss: 0.7617 - val_loss: 0.7143\n",
      "Epoch 6/100\n",
      "1124/1124 [==============================] - 0s 163us/sample - loss: 0.7625 - val_loss: 0.7150\n",
      "Epoch 7/100\n",
      "1124/1124 [==============================] - 0s 175us/sample - loss: 0.7601 - val_loss: 0.7178\n",
      "Epoch 8/100\n",
      "1124/1124 [==============================] - 0s 184us/sample - loss: 0.7599 - val_loss: 0.7179\n",
      "Epoch 9/100\n",
      "1124/1124 [==============================] - 0s 161us/sample - loss: 0.7594 - val_loss: 0.7104\n",
      "Epoch 10/100\n",
      "1124/1124 [==============================] - 0s 169us/sample - loss: 0.7601 - val_loss: 0.7112\n",
      "Epoch 11/100\n",
      "1124/1124 [==============================] - 0s 177us/sample - loss: 0.7583 - val_loss: 0.7121\n",
      "Epoch 12/100\n",
      "1124/1124 [==============================] - 0s 183us/sample - loss: 0.7578 - val_loss: 0.7110\n",
      "Epoch 13/100\n",
      "1124/1124 [==============================] - 0s 170us/sample - loss: 0.7572 - val_loss: 0.7121\n",
      "Epoch 14/100\n",
      "1124/1124 [==============================] - 0s 204us/sample - loss: 0.7571 - val_loss: 0.7123\n",
      "Epoch 15/100\n",
      "1124/1124 [==============================] - 0s 183us/sample - loss: 0.7559 - val_loss: 0.7132\n",
      "Epoch 16/100\n",
      "1124/1124 [==============================] - 0s 169us/sample - loss: 0.7551 - val_loss: 0.7150\n",
      "Epoch 17/100\n",
      "1124/1124 [==============================] - 0s 198us/sample - loss: 0.7549 - val_loss: 0.7145\n",
      "Epoch 18/100\n",
      "1124/1124 [==============================] - 0s 168us/sample - loss: 0.7556 - val_loss: 0.7157\n",
      "Epoch 19/100\n",
      "1124/1124 [==============================] - 0s 191us/sample - loss: 0.7544 - val_loss: 0.7168\n",
      "Train on 998 samples, validate on 246 samples\n",
      "Epoch 1/100\n",
      "998/998 [==============================] - 1s 787us/sample - loss: 1.0985 - val_loss: 1.1044\n",
      "Epoch 2/100\n",
      "998/998 [==============================] - 0s 171us/sample - loss: 1.0516 - val_loss: 1.0978\n",
      "Epoch 3/100\n",
      "998/998 [==============================] - 0s 171us/sample - loss: 1.0327 - val_loss: 1.0935\n",
      "Epoch 4/100\n",
      "998/998 [==============================] - 0s 170us/sample - loss: 1.0286 - val_loss: 1.1007\n",
      "Epoch 5/100\n",
      "998/998 [==============================] - 0s 173us/sample - loss: 1.0148 - val_loss: 1.1049\n",
      "Epoch 6/100\n",
      "998/998 [==============================] - 0s 171us/sample - loss: 1.0098 - val_loss: 1.0960\n",
      "Epoch 7/100\n",
      "998/998 [==============================] - 0s 173us/sample - loss: 0.9984 - val_loss: 1.0927\n",
      "Epoch 8/100\n",
      "998/998 [==============================] - 0s 177us/sample - loss: 0.9902 - val_loss: 1.1023\n",
      "Epoch 9/100\n",
      "998/998 [==============================] - 0s 175us/sample - loss: 0.9869 - val_loss: 1.1070\n",
      "Epoch 10/100\n",
      "998/998 [==============================] - 0s 174us/sample - loss: 0.9792 - val_loss: 1.0916\n",
      "Epoch 11/100\n",
      "998/998 [==============================] - 0s 176us/sample - loss: 0.9720 - val_loss: 1.1015\n",
      "Epoch 12/100\n",
      "998/998 [==============================] - 0s 171us/sample - loss: 0.9681 - val_loss: 1.1059\n",
      "Epoch 13/100\n",
      "998/998 [==============================] - 0s 166us/sample - loss: 0.9640 - val_loss: 1.1098\n",
      "Epoch 14/100\n",
      "998/998 [==============================] - 0s 167us/sample - loss: 0.9580 - val_loss: 1.1029\n",
      "Epoch 15/100\n",
      "998/998 [==============================] - 0s 164us/sample - loss: 0.9535 - val_loss: 1.0990\n",
      "Epoch 16/100\n",
      "998/998 [==============================] - 0s 166us/sample - loss: 0.9430 - val_loss: 1.1121\n",
      "Epoch 17/100\n",
      "998/998 [==============================] - 0s 184us/sample - loss: 0.9343 - val_loss: 1.1051\n",
      "Epoch 18/100\n",
      "998/998 [==============================] - 0s 208us/sample - loss: 0.9265 - val_loss: 1.1196\n",
      "Epoch 19/100\n",
      "998/998 [==============================] - 0s 177us/sample - loss: 0.9257 - val_loss: 1.1124\n",
      "Epoch 20/100\n",
      "998/998 [==============================] - 0s 179us/sample - loss: 0.9160 - val_loss: 1.1161\n",
      "Train on 1115 samples, validate on 284 samples\n",
      "Epoch 1/100\n",
      "1115/1115 [==============================] - 1s 792us/sample - loss: 0.7673 - val_loss: 0.7791\n",
      "Epoch 2/100\n",
      "1115/1115 [==============================] - 0s 184us/sample - loss: 0.7484 - val_loss: 0.7771\n",
      "Epoch 3/100\n",
      "1115/1115 [==============================] - 0s 189us/sample - loss: 0.7458 - val_loss: 0.7786\n",
      "Epoch 4/100\n",
      "1115/1115 [==============================] - 0s 170us/sample - loss: 0.7454 - val_loss: 0.7776\n",
      "Epoch 5/100\n",
      "1115/1115 [==============================] - 0s 194us/sample - loss: 0.7446 - val_loss: 0.7777\n",
      "Epoch 6/100\n",
      "1115/1115 [==============================] - 0s 171us/sample - loss: 0.7462 - val_loss: 0.7807\n",
      "Epoch 7/100\n",
      "1115/1115 [==============================] - 0s 183us/sample - loss: 0.7434 - val_loss: 0.7809\n",
      "Epoch 8/100\n",
      "1115/1115 [==============================] - 0s 185us/sample - loss: 0.7421 - val_loss: 0.7750\n",
      "Epoch 9/100\n",
      "1115/1115 [==============================] - 0s 173us/sample - loss: 0.7437 - val_loss: 0.7753\n",
      "Epoch 10/100\n",
      "1115/1115 [==============================] - 0s 187us/sample - loss: 0.7427 - val_loss: 0.7760\n",
      "Epoch 11/100\n",
      "1115/1115 [==============================] - 0s 179us/sample - loss: 0.7411 - val_loss: 0.7804\n",
      "Epoch 12/100\n",
      "1115/1115 [==============================] - 0s 187us/sample - loss: 0.7412 - val_loss: 0.7762\n",
      "Epoch 13/100\n",
      "1115/1115 [==============================] - 0s 178us/sample - loss: 0.7386 - val_loss: 0.7760\n",
      "Epoch 14/100\n",
      "1115/1115 [==============================] - 0s 172us/sample - loss: 0.7401 - val_loss: 0.7806\n",
      "Epoch 15/100\n",
      "1115/1115 [==============================] - 0s 193us/sample - loss: 0.7385 - val_loss: 0.7812\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115/1115 [==============================] - 0s 183us/sample - loss: 0.7381 - val_loss: 0.7770\n",
      "Epoch 17/100\n",
      "1115/1115 [==============================] - 0s 180us/sample - loss: 0.7387 - val_loss: 0.7810\n",
      "Epoch 18/100\n",
      "1115/1115 [==============================] - 0s 186us/sample - loss: 0.7398 - val_loss: 0.7807\n",
      "Train on 995 samples, validate on 249 samples\n",
      "Epoch 1/100\n",
      "995/995 [==============================] - 1s 1ms/sample - loss: 1.1095 - val_loss: 1.0524\n",
      "Epoch 2/100\n",
      "995/995 [==============================] - 0s 176us/sample - loss: 1.0572 - val_loss: 1.0508\n",
      "Epoch 3/100\n",
      "995/995 [==============================] - 0s 216us/sample - loss: 1.0430 - val_loss: 1.0563\n",
      "Epoch 4/100\n",
      "995/995 [==============================] - 0s 189us/sample - loss: 1.0380 - val_loss: 1.0499\n",
      "Epoch 5/100\n",
      "995/995 [==============================] - 0s 188us/sample - loss: 1.0258 - val_loss: 1.0575\n",
      "Epoch 6/100\n",
      "995/995 [==============================] - 0s 202us/sample - loss: 1.0215 - val_loss: 1.0535\n",
      "Epoch 7/100\n",
      "995/995 [==============================] - 0s 207us/sample - loss: 1.0124 - val_loss: 1.0517\n",
      "Epoch 8/100\n",
      "995/995 [==============================] - 0s 210us/sample - loss: 1.0002 - val_loss: 1.0602\n",
      "Epoch 9/100\n",
      "995/995 [==============================] - 0s 210us/sample - loss: 0.9956 - val_loss: 1.0552\n",
      "Epoch 10/100\n",
      "995/995 [==============================] - 0s 207us/sample - loss: 0.9919 - val_loss: 1.0716\n",
      "Epoch 11/100\n",
      "995/995 [==============================] - 0s 208us/sample - loss: 0.9796 - val_loss: 1.0588\n",
      "Epoch 12/100\n",
      "995/995 [==============================] - 0s 209us/sample - loss: 0.9775 - val_loss: 1.0614\n",
      "Epoch 13/100\n",
      "995/995 [==============================] - 0s 209us/sample - loss: 0.9704 - val_loss: 1.0626\n",
      "Epoch 14/100\n",
      "995/995 [==============================] - 0s 210us/sample - loss: 0.9610 - val_loss: 1.0626\n",
      "Train on 1120 samples, validate on 279 samples\n",
      "Epoch 1/100\n",
      "1120/1120 [==============================] - 1s 714us/sample - loss: 0.7689 - val_loss: 0.7606\n",
      "Epoch 2/100\n",
      "1120/1120 [==============================] - 0s 200us/sample - loss: 0.7520 - val_loss: 0.7638\n",
      "Epoch 3/100\n",
      "1120/1120 [==============================] - 0s 200us/sample - loss: 0.7505 - val_loss: 0.7654\n",
      "Epoch 4/100\n",
      "1120/1120 [==============================] - 0s 221us/sample - loss: 0.7498 - val_loss: 0.7638\n",
      "Epoch 5/100\n",
      "1120/1120 [==============================] - 0s 206us/sample - loss: 0.7483 - val_loss: 0.7613\n",
      "Epoch 6/100\n",
      "1120/1120 [==============================] - 0s 203us/sample - loss: 0.7478 - val_loss: 0.7637\n",
      "Epoch 7/100\n",
      "1120/1120 [==============================] - 0s 205us/sample - loss: 0.7491 - val_loss: 0.7620\n",
      "Epoch 8/100\n",
      "1120/1120 [==============================] - 0s 206us/sample - loss: 0.7462 - val_loss: 0.7616\n",
      "Epoch 9/100\n",
      "1120/1120 [==============================] - 0s 240us/sample - loss: 0.7447 - val_loss: 0.7640\n",
      "Epoch 10/100\n",
      "1120/1120 [==============================] - 0s 203us/sample - loss: 0.7461 - val_loss: 0.7618\n",
      "Epoch 11/100\n",
      "1120/1120 [==============================] - 0s 210us/sample - loss: 0.7467 - val_loss: 0.7631\n",
      "Train on 991 samples, validate on 253 samples\n",
      "Epoch 1/100\n",
      "991/991 [==============================] - 1s 823us/sample - loss: 1.1323 - val_loss: 1.0536\n",
      "Epoch 2/100\n",
      "991/991 [==============================] - 0s 203us/sample - loss: 1.0541 - val_loss: 1.0725\n",
      "Epoch 3/100\n",
      "991/991 [==============================] - 0s 218us/sample - loss: 1.0463 - val_loss: 1.0906\n",
      "Epoch 4/100\n",
      "991/991 [==============================] - 0s 210us/sample - loss: 1.0349 - val_loss: 1.0758\n",
      "Epoch 5/100\n",
      "991/991 [==============================] - 0s 209us/sample - loss: 1.0266 - val_loss: 1.0881\n",
      "Epoch 6/100\n",
      "991/991 [==============================] - 0s 212us/sample - loss: 1.0128 - val_loss: 1.1144\n",
      "Epoch 7/100\n",
      "991/991 [==============================] - 0s 206us/sample - loss: 1.0127 - val_loss: 1.0874\n",
      "Epoch 8/100\n",
      "991/991 [==============================] - 0s 206us/sample - loss: 1.0021 - val_loss: 1.0845\n",
      "Epoch 9/100\n",
      "991/991 [==============================] - 0s 222us/sample - loss: 0.9960 - val_loss: 1.1111\n",
      "Epoch 10/100\n",
      "991/991 [==============================] - 0s 219us/sample - loss: 0.9873 - val_loss: 1.1039\n",
      "Epoch 11/100\n",
      "991/991 [==============================] - 0s 220us/sample - loss: 0.9769 - val_loss: 1.1150\n",
      "Train on 1125 samples, validate on 274 samples\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 1s 978us/sample - loss: 0.7592 - val_loss: 0.7939\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 0s 191us/sample - loss: 0.7479 - val_loss: 0.7958\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 0s 203us/sample - loss: 0.7448 - val_loss: 0.7943\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 0s 207us/sample - loss: 0.7429 - val_loss: 0.7964\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 0s 210us/sample - loss: 0.7414 - val_loss: 0.8035\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 0s 211us/sample - loss: 0.7432 - val_loss: 0.8023\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 0s 208us/sample - loss: 0.7390 - val_loss: 0.8087\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 0s 213us/sample - loss: 0.7410 - val_loss: 0.8021\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 0s 253us/sample - loss: 0.7383 - val_loss: 0.8012\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 0s 209us/sample - loss: 0.7379 - val_loss: 0.7986\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 0s 210us/sample - loss: 0.7369 - val_loss: 0.8018\n",
      "Train on 1004 samples, validate on 240 samples\n",
      "Epoch 1/100\n",
      "1004/1004 [==============================] - 1s 932us/sample - loss: 1.1061 - val_loss: 1.0411\n",
      "Epoch 2/100\n",
      "1004/1004 [==============================] - 0s 388us/sample - loss: 1.0620 - val_loss: 1.0342\n",
      "Epoch 3/100\n",
      "1004/1004 [==============================] - 0s 226us/sample - loss: 1.0513 - val_loss: 1.0246\n",
      "Epoch 4/100\n",
      "1004/1004 [==============================] - 0s 206us/sample - loss: 1.0434 - val_loss: 1.0287\n",
      "Epoch 5/100\n",
      "1004/1004 [==============================] - 0s 211us/sample - loss: 1.0365 - val_loss: 1.0253\n",
      "Epoch 6/100\n",
      "1004/1004 [==============================] - 0s 209us/sample - loss: 1.0295 - val_loss: 1.0237\n",
      "Epoch 7/100\n",
      "1004/1004 [==============================] - 0s 209us/sample - loss: 1.0252 - val_loss: 1.0183\n",
      "Epoch 8/100\n",
      "1004/1004 [==============================] - 0s 207us/sample - loss: 1.0119 - val_loss: 1.0421\n",
      "Epoch 9/100\n",
      "1004/1004 [==============================] - 0s 208us/sample - loss: 1.0035 - val_loss: 1.0302\n",
      "Epoch 10/100\n",
      "1004/1004 [==============================] - 0s 244us/sample - loss: 1.0000 - val_loss: 1.0204\n",
      "Epoch 11/100\n",
      "1004/1004 [==============================] - 0s 262us/sample - loss: 0.9911 - val_loss: 1.0181\n",
      "Epoch 12/100\n",
      "1004/1004 [==============================] - 0s 233us/sample - loss: 0.9846 - val_loss: 1.0215\n",
      "Epoch 13/100\n",
      "1004/1004 [==============================] - 0s 307us/sample - loss: 0.9801 - val_loss: 1.0221\n",
      "Epoch 14/100\n",
      "1004/1004 [==============================] - 0s 282us/sample - loss: 0.9725 - val_loss: 1.0245\n",
      "Epoch 15/100\n",
      "1004/1004 [==============================] - 0s 242us/sample - loss: 0.9726 - val_loss: 1.0324\n",
      "Epoch 16/100\n",
      "1004/1004 [==============================] - 0s 356us/sample - loss: 0.9621 - val_loss: 1.0302\n",
      "Epoch 17/100\n",
      "1004/1004 [==============================] - 0s 261us/sample - loss: 0.9572 - val_loss: 1.0246\n",
      "Epoch 18/100\n",
      "1004/1004 [==============================] - 0s 224us/sample - loss: 0.9445 - val_loss: 1.0268\n",
      "Epoch 19/100\n",
      "1004/1004 [==============================] - 0s 220us/sample - loss: 0.9496 - val_loss: 1.0377\n",
      "Epoch 20/100\n",
      "1004/1004 [==============================] - 0s 223us/sample - loss: 0.9381 - val_loss: 1.0469\n",
      "Epoch 21/100\n",
      "1004/1004 [==============================] - 0s 238us/sample - loss: 0.9328 - val_loss: 1.0414\n",
      "Train on 1112 samples, validate on 287 samples\n",
      "Epoch 1/100\n",
      "1112/1112 [==============================] - 1s 824us/sample - loss: 0.7864 - val_loss: 0.7399\n",
      "Epoch 2/100\n",
      "1112/1112 [==============================] - 0s 241us/sample - loss: 0.7627 - val_loss: 0.7335\n",
      "Epoch 3/100\n",
      "1112/1112 [==============================] - 0s 234us/sample - loss: 0.7618 - val_loss: 0.7321\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1112/1112 [==============================] - 0s 236us/sample - loss: 0.7611 - val_loss: 0.7275\n",
      "Epoch 5/100\n",
      "1112/1112 [==============================] - 0s 239us/sample - loss: 0.7570 - val_loss: 0.7261\n",
      "Epoch 6/100\n",
      "1112/1112 [==============================] - 0s 244us/sample - loss: 0.7564 - val_loss: 0.7246\n",
      "Epoch 7/100\n",
      "1112/1112 [==============================] - 0s 219us/sample - loss: 0.7538 - val_loss: 0.7275\n",
      "Epoch 8/100\n",
      "1112/1112 [==============================] - 0s 220us/sample - loss: 0.7553 - val_loss: 0.7301\n",
      "Epoch 9/100\n",
      "1112/1112 [==============================] - 0s 214us/sample - loss: 0.7548 - val_loss: 0.7268\n",
      "Epoch 10/100\n",
      "1112/1112 [==============================] - 0s 213us/sample - loss: 0.7542 - val_loss: 0.7251\n",
      "Epoch 11/100\n",
      "1112/1112 [==============================] - 0s 209us/sample - loss: 0.7534 - val_loss: 0.7290\n",
      "Epoch 12/100\n",
      "1112/1112 [==============================] - 0s 234us/sample - loss: 0.7518 - val_loss: 0.7302\n",
      "Epoch 13/100\n",
      "1112/1112 [==============================] - 0s 218us/sample - loss: 0.7502 - val_loss: 0.7243\n",
      "Epoch 14/100\n",
      "1112/1112 [==============================] - 0s 214us/sample - loss: 0.7513 - val_loss: 0.7288\n",
      "Epoch 15/100\n",
      "1112/1112 [==============================] - 0s 219us/sample - loss: 0.7499 - val_loss: 0.7316\n",
      "Epoch 16/100\n",
      "1112/1112 [==============================] - 0s 213us/sample - loss: 0.7490 - val_loss: 0.7318\n",
      "Epoch 17/100\n",
      "1112/1112 [==============================] - 0s 207us/sample - loss: 0.7495 - val_loss: 0.7303\n",
      "Epoch 18/100\n",
      "1112/1112 [==============================] - 0s 220us/sample - loss: 0.7495 - val_loss: 0.7354\n",
      "Epoch 19/100\n",
      "1112/1112 [==============================] - 0s 224us/sample - loss: 0.7475 - val_loss: 0.7324\n",
      "Epoch 20/100\n",
      "1112/1112 [==============================] - 0s 211us/sample - loss: 0.7488 - val_loss: 0.7328\n",
      "Epoch 21/100\n",
      "1112/1112 [==============================] - 0s 221us/sample - loss: 0.7470 - val_loss: 0.7315\n",
      "Epoch 22/100\n",
      "1112/1112 [==============================] - 0s 219us/sample - loss: 0.7463 - val_loss: 0.7266\n",
      "Epoch 23/100\n",
      "1112/1112 [==============================] - 0s 231us/sample - loss: 0.7459 - val_loss: 0.7313\n",
      "Train on 3531 samples, validate on 884 samples\n",
      "Epoch 1/100\n",
      "3531/3531 [==============================] - 2s 443us/sample - loss: 0.6732 - val_loss: 0.6529\n",
      "Epoch 2/100\n",
      "3531/3531 [==============================] - 1s 243us/sample - loss: 0.6392 - val_loss: 0.6365\n",
      "Epoch 3/100\n",
      "3531/3531 [==============================] - 1s 214us/sample - loss: 0.6263 - val_loss: 0.6348\n",
      "Epoch 4/100\n",
      "3531/3531 [==============================] - 1s 194us/sample - loss: 0.6183 - val_loss: 0.6412\n",
      "Epoch 5/100\n",
      "3531/3531 [==============================] - 1s 180us/sample - loss: 0.6100 - val_loss: 0.6304\n",
      "Epoch 6/100\n",
      "3531/3531 [==============================] - 1s 175us/sample - loss: 0.6029 - val_loss: 0.6448\n",
      "Epoch 7/100\n",
      "3531/3531 [==============================] - 1s 175us/sample - loss: 0.5988 - val_loss: 0.6375\n",
      "Epoch 8/100\n",
      "3531/3531 [==============================] - 1s 175us/sample - loss: 0.5893 - val_loss: 0.6347\n",
      "Epoch 9/100\n",
      "3531/3531 [==============================] - 1s 175us/sample - loss: 0.5818 - val_loss: 0.6410\n",
      "Epoch 10/100\n",
      "3531/3531 [==============================] - 1s 176us/sample - loss: 0.5743 - val_loss: 0.6404\n",
      "Epoch 11/100\n",
      "3531/3531 [==============================] - 1s 176us/sample - loss: 0.5634 - val_loss: 0.6419\n",
      "Epoch 12/100\n",
      "3531/3531 [==============================] - 1s 176us/sample - loss: 0.5535 - val_loss: 0.6558\n",
      "Epoch 13/100\n",
      "3531/3531 [==============================] - 1s 177us/sample - loss: 0.5478 - val_loss: 0.6531\n",
      "Epoch 14/100\n",
      "3531/3531 [==============================] - 1s 176us/sample - loss: 0.5359 - val_loss: 0.6574\n",
      "Epoch 15/100\n",
      "3531/3531 [==============================] - 1s 186us/sample - loss: 0.5309 - val_loss: 0.6620\n",
      "Train on 580 samples, validate on 146 samples\n",
      "Epoch 1/100\n",
      "580/580 [==============================] - 1s 1ms/sample - loss: 0.4764 - val_loss: 0.4847\n",
      "Epoch 2/100\n",
      "580/580 [==============================] - 0s 227us/sample - loss: 0.4113 - val_loss: 0.4768\n",
      "Epoch 3/100\n",
      "580/580 [==============================] - 0s 237us/sample - loss: 0.3950 - val_loss: 0.4757\n",
      "Epoch 4/100\n",
      "580/580 [==============================] - 0s 237us/sample - loss: 0.3809 - val_loss: 0.4758\n",
      "Epoch 5/100\n",
      "580/580 [==============================] - 0s 241us/sample - loss: 0.3669 - val_loss: 0.4625\n",
      "Epoch 6/100\n",
      "580/580 [==============================] - 0s 232us/sample - loss: 0.3720 - val_loss: 0.4628\n",
      "Epoch 7/100\n",
      "580/580 [==============================] - 0s 234us/sample - loss: 0.3562 - val_loss: 0.4653\n",
      "Epoch 8/100\n",
      "580/580 [==============================] - 0s 237us/sample - loss: 0.3462 - val_loss: 0.4738\n",
      "Epoch 9/100\n",
      "580/580 [==============================] - 0s 237us/sample - loss: 0.3398 - val_loss: 0.4629\n",
      "Epoch 10/100\n",
      "580/580 [==============================] - 0s 236us/sample - loss: 0.3290 - val_loss: 0.4720\n",
      "Epoch 11/100\n",
      "580/580 [==============================] - 0s 241us/sample - loss: 0.3336 - val_loss: 0.4714\n",
      "Epoch 12/100\n",
      "580/580 [==============================] - 0s 236us/sample - loss: 0.3214 - val_loss: 0.4676\n",
      "Epoch 13/100\n",
      "580/580 [==============================] - 0s 237us/sample - loss: 0.3153 - val_loss: 0.4680\n",
      "Epoch 14/100\n",
      "580/580 [==============================] - 0s 230us/sample - loss: 0.3123 - val_loss: 0.4744\n",
      "Epoch 15/100\n",
      "580/580 [==============================] - 0s 244us/sample - loss: 0.3010 - val_loss: 0.4694\n",
      "Train on 3542 samples, validate on 873 samples\n",
      "Epoch 1/100\n",
      "3542/3542 [==============================] - 1s 331us/sample - loss: 0.6683 - val_loss: 0.6479\n",
      "Epoch 2/100\n",
      "3542/3542 [==============================] - 1s 174us/sample - loss: 0.6387 - val_loss: 0.6469\n",
      "Epoch 3/100\n",
      "3542/3542 [==============================] - 1s 174us/sample - loss: 0.6230 - val_loss: 0.6434\n",
      "Epoch 4/100\n",
      "3542/3542 [==============================] - 1s 176us/sample - loss: 0.6146 - val_loss: 0.6386\n",
      "Epoch 5/100\n",
      "3542/3542 [==============================] - 1s 175us/sample - loss: 0.6052 - val_loss: 0.6413\n",
      "Epoch 6/100\n",
      "3542/3542 [==============================] - 1s 175us/sample - loss: 0.5982 - val_loss: 0.6414\n",
      "Epoch 7/100\n",
      "3542/3542 [==============================] - 1s 176us/sample - loss: 0.5909 - val_loss: 0.6487\n",
      "Epoch 8/100\n",
      "3542/3542 [==============================] - 1s 175us/sample - loss: 0.5842 - val_loss: 0.6462\n",
      "Epoch 9/100\n",
      "3542/3542 [==============================] - 1s 174us/sample - loss: 0.5764 - val_loss: 0.6467\n",
      "Epoch 10/100\n",
      "3542/3542 [==============================] - 1s 174us/sample - loss: 0.5702 - val_loss: 0.6564\n",
      "Epoch 11/100\n",
      "3542/3542 [==============================] - 1s 175us/sample - loss: 0.5591 - val_loss: 0.6517\n",
      "Epoch 12/100\n",
      "3542/3542 [==============================] - 1s 175us/sample - loss: 0.5501 - val_loss: 0.6665\n",
      "Epoch 13/100\n",
      "3542/3542 [==============================] - 1s 174us/sample - loss: 0.5424 - val_loss: 0.6576\n",
      "Epoch 14/100\n",
      "3542/3542 [==============================] - 1s 177us/sample - loss: 0.5325 - val_loss: 0.6553\n",
      "Train on 570 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "570/570 [==============================] - 1s 2ms/sample - loss: 0.5039 - val_loss: 0.4403\n",
      "Epoch 2/100\n",
      "570/570 [==============================] - 0s 206us/sample - loss: 0.4199 - val_loss: 0.4334\n",
      "Epoch 3/100\n",
      "570/570 [==============================] - 0s 222us/sample - loss: 0.3988 - val_loss: 0.4322\n",
      "Epoch 4/100\n",
      "570/570 [==============================] - 0s 234us/sample - loss: 0.3879 - val_loss: 0.4419\n",
      "Epoch 5/100\n",
      "570/570 [==============================] - 0s 238us/sample - loss: 0.3777 - val_loss: 0.4368\n",
      "Epoch 6/100\n",
      "570/570 [==============================] - 0s 243us/sample - loss: 0.3751 - val_loss: 0.4353\n",
      "Epoch 7/100\n",
      "570/570 [==============================] - 0s 238us/sample - loss: 0.3566 - val_loss: 0.4348\n",
      "Epoch 8/100\n",
      "570/570 [==============================] - 0s 233us/sample - loss: 0.3451 - val_loss: 0.4393\n",
      "Epoch 9/100\n",
      "570/570 [==============================] - 0s 241us/sample - loss: 0.3392 - val_loss: 0.4415\n",
      "Epoch 10/100\n",
      "570/570 [==============================] - 0s 240us/sample - loss: 0.3323 - val_loss: 0.4453\n",
      "Epoch 11/100\n",
      "570/570 [==============================] - 0s 238us/sample - loss: 0.3320 - val_loss: 0.4468\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 0s 234us/sample - loss: 0.3225 - val_loss: 0.4437\n",
      "Epoch 13/100\n",
      "570/570 [==============================] - 0s 241us/sample - loss: 0.3108 - val_loss: 0.4459\n",
      "Train on 3535 samples, validate on 880 samples\n",
      "Epoch 1/100\n",
      "3535/3535 [==============================] - 1s 327us/sample - loss: 0.6695 - val_loss: 0.6499\n",
      "Epoch 2/100\n",
      "3535/3535 [==============================] - 1s 171us/sample - loss: 0.6344 - val_loss: 0.6538\n",
      "Epoch 3/100\n",
      "3535/3535 [==============================] - 1s 174us/sample - loss: 0.6237 - val_loss: 0.6469\n",
      "Epoch 4/100\n",
      "3535/3535 [==============================] - 1s 174us/sample - loss: 0.6142 - val_loss: 0.6458\n",
      "Epoch 5/100\n",
      "3535/3535 [==============================] - 1s 174us/sample - loss: 0.6052 - val_loss: 0.6453\n",
      "Epoch 6/100\n",
      "3535/3535 [==============================] - 1s 173us/sample - loss: 0.5982 - val_loss: 0.6433\n",
      "Epoch 7/100\n",
      "3535/3535 [==============================] - 1s 173us/sample - loss: 0.5904 - val_loss: 0.6516\n",
      "Epoch 8/100\n",
      "3535/3535 [==============================] - 1s 172us/sample - loss: 0.5807 - val_loss: 0.6557\n",
      "Epoch 9/100\n",
      "3535/3535 [==============================] - 1s 186us/sample - loss: 0.5753 - val_loss: 0.6554\n",
      "Epoch 10/100\n",
      "3535/3535 [==============================] - 1s 172us/sample - loss: 0.5703 - val_loss: 0.6584\n",
      "Epoch 11/100\n",
      "3535/3535 [==============================] - 1s 172us/sample - loss: 0.5597 - val_loss: 0.6673\n",
      "Epoch 12/100\n",
      "3535/3535 [==============================] - 1s 174us/sample - loss: 0.5514 - val_loss: 0.6675\n",
      "Epoch 13/100\n",
      "3535/3535 [==============================] - 1s 172us/sample - loss: 0.5428 - val_loss: 0.6685\n",
      "Epoch 14/100\n",
      "3535/3535 [==============================] - 1s 171us/sample - loss: 0.5340 - val_loss: 0.6704\n",
      "Epoch 15/100\n",
      "3535/3535 [==============================] - 1s 172us/sample - loss: 0.5208 - val_loss: 0.6730\n",
      "Epoch 16/100\n",
      "3535/3535 [==============================] - 1s 173us/sample - loss: 0.5138 - val_loss: 0.6819\n",
      "Train on 577 samples, validate on 149 samples\n",
      "Epoch 1/100\n",
      "577/577 [==============================] - 1s 1ms/sample - loss: 0.4977 - val_loss: 0.4302\n",
      "Epoch 2/100\n",
      "577/577 [==============================] - 0s 230us/sample - loss: 0.4330 - val_loss: 0.4259\n",
      "Epoch 3/100\n",
      "577/577 [==============================] - 0s 237us/sample - loss: 0.4059 - val_loss: 0.4228\n",
      "Epoch 4/100\n",
      "577/577 [==============================] - 0s 240us/sample - loss: 0.3932 - val_loss: 0.4238\n",
      "Epoch 5/100\n",
      "577/577 [==============================] - 0s 239us/sample - loss: 0.3835 - val_loss: 0.4355\n",
      "Epoch 6/100\n",
      "577/577 [==============================] - 0s 233us/sample - loss: 0.3754 - val_loss: 0.4259\n",
      "Epoch 7/100\n",
      "577/577 [==============================] - 0s 240us/sample - loss: 0.3664 - val_loss: 0.4228\n",
      "Epoch 8/100\n",
      "577/577 [==============================] - 0s 237us/sample - loss: 0.3578 - val_loss: 0.4277\n",
      "Epoch 9/100\n",
      "577/577 [==============================] - 0s 242us/sample - loss: 0.3478 - val_loss: 0.4301\n",
      "Epoch 10/100\n",
      "577/577 [==============================] - 0s 240us/sample - loss: 0.3426 - val_loss: 0.4336\n",
      "Epoch 11/100\n",
      "577/577 [==============================] - 0s 235us/sample - loss: 0.3295 - val_loss: 0.4337\n",
      "Epoch 12/100\n",
      "577/577 [==============================] - 0s 237us/sample - loss: 0.3225 - val_loss: 0.4429\n",
      "Epoch 13/100\n",
      "577/577 [==============================] - 0s 240us/sample - loss: 0.3244 - val_loss: 0.4482\n",
      "Epoch 14/100\n",
      "577/577 [==============================] - 0s 232us/sample - loss: 0.3203 - val_loss: 0.4398\n",
      "Epoch 15/100\n",
      "577/577 [==============================] - 0s 239us/sample - loss: 0.3146 - val_loss: 0.4473\n",
      "Epoch 16/100\n",
      "577/577 [==============================] - 0s 240us/sample - loss: 0.3092 - val_loss: 0.4523\n",
      "Epoch 17/100\n",
      "577/577 [==============================] - 0s 242us/sample - loss: 0.2963 - val_loss: 0.4501\n",
      "Train on 3515 samples, validate on 900 samples\n",
      "Epoch 1/100\n",
      "3515/3515 [==============================] - 1s 335us/sample - loss: 0.6732 - val_loss: 0.6291\n",
      "Epoch 2/100\n",
      "3515/3515 [==============================] - 1s 174us/sample - loss: 0.6386 - val_loss: 0.6310\n",
      "Epoch 3/100\n",
      "3515/3515 [==============================] - 1s 175us/sample - loss: 0.6273 - val_loss: 0.6307\n",
      "Epoch 4/100\n",
      "3515/3515 [==============================] - 1s 175us/sample - loss: 0.6212 - val_loss: 0.6340\n",
      "Epoch 5/100\n",
      "3515/3515 [==============================] - 1s 175us/sample - loss: 0.6119 - val_loss: 0.6281\n",
      "Epoch 6/100\n",
      "3515/3515 [==============================] - 1s 175us/sample - loss: 0.6054 - val_loss: 0.6356\n",
      "Epoch 7/100\n",
      "3515/3515 [==============================] - 1s 175us/sample - loss: 0.6004 - val_loss: 0.6342\n",
      "Epoch 8/100\n",
      "3515/3515 [==============================] - 1s 174us/sample - loss: 0.5936 - val_loss: 0.6323\n",
      "Epoch 9/100\n",
      "3515/3515 [==============================] - 1s 175us/sample - loss: 0.5831 - val_loss: 0.6430\n",
      "Epoch 10/100\n",
      "3515/3515 [==============================] - 1s 175us/sample - loss: 0.5754 - val_loss: 0.6358\n",
      "Epoch 11/100\n",
      "3515/3515 [==============================] - 1s 175us/sample - loss: 0.5722 - val_loss: 0.6440\n",
      "Epoch 12/100\n",
      "3515/3515 [==============================] - 1s 175us/sample - loss: 0.5599 - val_loss: 0.6349\n",
      "Epoch 13/100\n",
      "3515/3515 [==============================] - 1s 176us/sample - loss: 0.5510 - val_loss: 0.6346\n",
      "Epoch 14/100\n",
      "3515/3515 [==============================] - 1s 176us/sample - loss: 0.5436 - val_loss: 0.6469\n",
      "Epoch 15/100\n",
      "3515/3515 [==============================] - 1s 176us/sample - loss: 0.5371 - val_loss: 0.6480\n",
      "Train on 599 samples, validate on 127 samples\n",
      "Epoch 1/100\n",
      "599/599 [==============================] - 1s 2ms/sample - loss: 0.4914 - val_loss: 0.4304\n",
      "Epoch 2/100\n",
      "599/599 [==============================] - 0s 201us/sample - loss: 0.4211 - val_loss: 0.4658\n",
      "Epoch 3/100\n",
      "599/599 [==============================] - 0s 215us/sample - loss: 0.4084 - val_loss: 0.4131\n",
      "Epoch 4/100\n",
      "599/599 [==============================] - 0s 221us/sample - loss: 0.3890 - val_loss: 0.4276\n",
      "Epoch 5/100\n",
      "599/599 [==============================] - 0s 231us/sample - loss: 0.3835 - val_loss: 0.4112\n",
      "Epoch 6/100\n",
      "599/599 [==============================] - 0s 228us/sample - loss: 0.3660 - val_loss: 0.4306\n",
      "Epoch 7/100\n",
      "599/599 [==============================] - 0s 228us/sample - loss: 0.3646 - val_loss: 0.4336\n",
      "Epoch 8/100\n",
      "599/599 [==============================] - 0s 226us/sample - loss: 0.3510 - val_loss: 0.4270\n",
      "Epoch 9/100\n",
      "599/599 [==============================] - 0s 228us/sample - loss: 0.3444 - val_loss: 0.4256\n",
      "Epoch 10/100\n",
      "599/599 [==============================] - 0s 226us/sample - loss: 0.3414 - val_loss: 0.4353\n",
      "Epoch 11/100\n",
      "599/599 [==============================] - 0s 230us/sample - loss: 0.3444 - val_loss: 0.4270\n",
      "Epoch 12/100\n",
      "599/599 [==============================] - 0s 228us/sample - loss: 0.3290 - val_loss: 0.4486\n",
      "Epoch 13/100\n",
      "599/599 [==============================] - 0s 228us/sample - loss: 0.3343 - val_loss: 0.4383\n",
      "Epoch 14/100\n",
      "599/599 [==============================] - 0s 233us/sample - loss: 0.3157 - val_loss: 0.4386\n",
      "Epoch 15/100\n",
      "599/599 [==============================] - 0s 235us/sample - loss: 0.3152 - val_loss: 0.4507\n",
      "Train on 3537 samples, validate on 878 samples\n",
      "Epoch 1/100\n",
      "3537/3537 [==============================] - 1s 332us/sample - loss: 0.6642 - val_loss: 0.6645\n",
      "Epoch 2/100\n",
      "3537/3537 [==============================] - 1s 176us/sample - loss: 0.6312 - val_loss: 0.6622\n",
      "Epoch 3/100\n",
      "3537/3537 [==============================] - 1s 177us/sample - loss: 0.6189 - val_loss: 0.6585\n",
      "Epoch 4/100\n",
      "3537/3537 [==============================] - 1s 176us/sample - loss: 0.6091 - val_loss: 0.6625\n",
      "Epoch 5/100\n",
      "3537/3537 [==============================] - 1s 176us/sample - loss: 0.6036 - val_loss: 0.6563\n",
      "Epoch 6/100\n",
      "3537/3537 [==============================] - 1s 175us/sample - loss: 0.5947 - val_loss: 0.6657\n",
      "Epoch 7/100\n",
      "3537/3537 [==============================] - 1s 177us/sample - loss: 0.5896 - val_loss: 0.6595\n",
      "Epoch 8/100\n",
      "3537/3537 [==============================] - 1s 177us/sample - loss: 0.5778 - val_loss: 0.6707\n",
      "Epoch 9/100\n",
      "3537/3537 [==============================] - 1s 175us/sample - loss: 0.5745 - val_loss: 0.6721\n",
      "Epoch 10/100\n",
      "3537/3537 [==============================] - 1s 191us/sample - loss: 0.5638 - val_loss: 0.6632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "3537/3537 [==============================] - 1s 175us/sample - loss: 0.5573 - val_loss: 0.6697\n",
      "Epoch 12/100\n",
      "3537/3537 [==============================] - 1s 173us/sample - loss: 0.5518 - val_loss: 0.6694\n",
      "Epoch 13/100\n",
      "3537/3537 [==============================] - 1s 175us/sample - loss: 0.5435 - val_loss: 0.6709\n",
      "Epoch 14/100\n",
      "3537/3537 [==============================] - 1s 174us/sample - loss: 0.5309 - val_loss: 0.6718\n",
      "Epoch 15/100\n",
      "3537/3537 [==============================] - 1s 176us/sample - loss: 0.5243 - val_loss: 0.6856\n",
      "Train on 578 samples, validate on 148 samples\n",
      "Epoch 1/100\n",
      "578/578 [==============================] - 1s 1ms/sample - loss: 0.5011 - val_loss: 0.4442\n",
      "Epoch 2/100\n",
      "578/578 [==============================] - 0s 229us/sample - loss: 0.4229 - val_loss: 0.4426\n",
      "Epoch 3/100\n",
      "578/578 [==============================] - 0s 231us/sample - loss: 0.4084 - val_loss: 0.4366\n",
      "Epoch 4/100\n",
      "578/578 [==============================] - 0s 240us/sample - loss: 0.3950 - val_loss: 0.4263\n",
      "Epoch 5/100\n",
      "578/578 [==============================] - 0s 243us/sample - loss: 0.3809 - val_loss: 0.4230\n",
      "Epoch 6/100\n",
      "578/578 [==============================] - 0s 240us/sample - loss: 0.3745 - val_loss: 0.4166\n",
      "Epoch 7/100\n",
      "578/578 [==============================] - 0s 240us/sample - loss: 0.3631 - val_loss: 0.4212\n",
      "Epoch 8/100\n",
      "578/578 [==============================] - 0s 231us/sample - loss: 0.3538 - val_loss: 0.4322\n",
      "Epoch 9/100\n",
      "578/578 [==============================] - 0s 238us/sample - loss: 0.3459 - val_loss: 0.4264\n",
      "Epoch 10/100\n",
      "578/578 [==============================] - 0s 240us/sample - loss: 0.3353 - val_loss: 0.4306\n",
      "Epoch 11/100\n",
      "578/578 [==============================] - 0s 235us/sample - loss: 0.3323 - val_loss: 0.4180\n",
      "Epoch 12/100\n",
      "578/578 [==============================] - 0s 233us/sample - loss: 0.3229 - val_loss: 0.4244\n",
      "Epoch 13/100\n",
      "578/578 [==============================] - 0s 233us/sample - loss: 0.3224 - val_loss: 0.4290\n",
      "Epoch 14/100\n",
      "578/578 [==============================] - 0s 240us/sample - loss: 0.3136 - val_loss: 0.4046\n",
      "Epoch 15/100\n",
      "578/578 [==============================] - 0s 231us/sample - loss: 0.3075 - val_loss: 0.4442\n",
      "Epoch 16/100\n",
      "578/578 [==============================] - 0s 236us/sample - loss: 0.3245 - val_loss: 0.4117\n",
      "Epoch 17/100\n",
      "578/578 [==============================] - 0s 235us/sample - loss: 0.2968 - val_loss: 0.4307\n",
      "Epoch 18/100\n",
      "578/578 [==============================] - 0s 233us/sample - loss: 0.2962 - val_loss: 0.4271\n",
      "Epoch 19/100\n",
      "578/578 [==============================] - 0s 247us/sample - loss: 0.2857 - val_loss: 0.4400\n",
      "Epoch 20/100\n",
      "578/578 [==============================] - 0s 292us/sample - loss: 0.2860 - val_loss: 0.4167\n",
      "Epoch 21/100\n",
      "578/578 [==============================] - 0s 236us/sample - loss: 0.2854 - val_loss: 0.4208\n",
      "Epoch 22/100\n",
      "578/578 [==============================] - 0s 235us/sample - loss: 0.2775 - val_loss: 0.4282\n",
      "Epoch 23/100\n",
      "578/578 [==============================] - 0s 240us/sample - loss: 0.2692 - val_loss: 0.4265\n",
      "Epoch 24/100\n",
      "578/578 [==============================] - 0s 238us/sample - loss: 0.2734 - val_loss: 0.4275\n"
     ]
    }
   ],
   "source": [
    "metrics = full_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gene': {'overall': {'mae': 0.7299490896746337,\n",
       "   'rmse': 1.2918968704150449,\n",
       "   'ndcg': 0.44835543717483367},\n",
       "  'annual': {'mae': array([0.41098335, 0.57326106, 0.75468637, 0.88329084, 1.02752384]),\n",
       "   'rmse': array([0.74612466, 0.97067574, 1.33166402, 1.48635163, 1.66849718]),\n",
       "   'ndcg': array([0.46505046, 0.36096419, 0.14908492, 0.19261638, 0.15743147])}},\n",
       " 'transplant': {'overall': {'mae': 0.7718043551135649,\n",
       "   'rmse': 1.2752554128409044,\n",
       "   'ndcg': 0.48122490028670706},\n",
       "  'annual': {'mae': array([0.75218725, 0.77410503, 0.74279975, 0.7759474 , 0.81398235]),\n",
       "   'rmse': array([1.30078556, 1.29846621, 1.21739863, 1.22831554, 1.31962679]),\n",
       "   'ndcg': array([0.09773368, 0.07247887, 0.02053076, 0.10604713, 0.11611737])}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': [0.7786941820597671,\n",
       "  0.7788960884233309,\n",
       "  0.7729668810238098,\n",
       "  0.7533253829680581,\n",
       "  0.7765691004200828],\n",
       " 'rmse': [1.27086824299393,\n",
       "  1.2638911023240982,\n",
       "  1.247003894606875,\n",
       "  1.2303769903078015,\n",
       "  1.3186515565011414],\n",
       " 'ndcg': [0.06715128409921688,\n",
       "  0.27366708122800754,\n",
       "  0.7082721967796911,\n",
       "  0.7802365522730148,\n",
       "  0.07262263474874978]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
