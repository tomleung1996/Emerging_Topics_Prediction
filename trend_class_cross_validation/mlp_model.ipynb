{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "## 仅供交叉验证 前馈神经网络（NNAR）-按趋势分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from utils import *\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "n_input = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the gene_editing array: (2643, 17, 10)\n",
      "Shape of the transplant array: (5141, 17, 10)\n"
     ]
    }
   ],
   "source": [
    "# gene_arr_path = r'../output/gene_editing/es_with_decay.array'\n",
    "# transplant_arr_path = r'../output/transplant/es_with_decay.array'\n",
    "\n",
    "# gene_arr = pickle.load(open(gene_arr_path, mode='rb'))\n",
    "# transplant_arr = pickle.load(open(transplant_arr_path, mode='rb'))\n",
    "\n",
    "# print('Shape of the gene_editing array:',gene_arr.shape)\n",
    "# print('Shape of the transplant array:',transplant_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 截断数据\n",
    "2019年为无效数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the gene_editing array: (2643, 16, 10)\n",
      "Shape of the transplant array: (5141, 16, 10)\n"
     ]
    }
   ],
   "source": [
    "# gene_arr = gene_arr[:, :-1, :]\n",
    "# transplant_arr = transplant_arr[:, :-1, :]\n",
    "\n",
    "# print('Shape of the gene_editing array:',gene_arr.shape)\n",
    "# print('Shape of the transplant array:',transplant_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 规范数据并获取5折交叉检验所需的训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler, data = scale_data(transplant_arr, 'standard')\n",
    "\n",
    "# # 用预测第二年的类别变量作为分成Kfold的依据，不支持浮点数\n",
    "# X, y, y_cat = data[:, :n_input, :], data[:, n_input:, -2],transplant_arr[:, n_input, -1]\n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按趋势划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_by_trend(data, targets):\n",
    "    up_data = []\n",
    "    down_data = []\n",
    "    up_target = []\n",
    "    down_target = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        a, b = np.polyfit(range(len(data[i])), data[i, :, -2].reshape(-1), 1)\n",
    "        if a > 0:\n",
    "            up_data.append(data[i])\n",
    "            up_target.append(targets[i])\n",
    "        else:\n",
    "            down_data.append(data[i])\n",
    "            down_target.append(targets[i])\n",
    "    return np.array(up_data), np.array(up_target), np.array(down_data), np.array(down_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return keras.backend.sqrt(keras.backend.mean(keras.backend.square(y_pred - y_true), axis=-1)) \n",
    "\n",
    "def build_direct_dnn_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(5))\n",
    "    \n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(loss=root_mean_squared_error, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进行训练和评估\n",
    "使用EarlyStopping和Checkpoint做训练停止方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, y, y_cat, kfold, scaler):\n",
    "    overall_metrics = {\n",
    "        'mae':[],\n",
    "        'rmse':[],\n",
    "        'ndcg':[],\n",
    "        'mape':[],\n",
    "        'r2':[],\n",
    "        'pearson':[],\n",
    "        'acc':[]\n",
    "    }\n",
    "\n",
    "    annual_metrics = {\n",
    "        'mae':[],\n",
    "        'rmse':[],\n",
    "        'ndcg':[],\n",
    "        'mape':[],\n",
    "        'r2':[],\n",
    "        'pearson':[],\n",
    "        'acc':[]\n",
    "    }\n",
    "    \n",
    "    for train, test in kfold.split(X, y_cat):\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        models = []\n",
    "        \n",
    "        # 按总量划分数据集\n",
    "        X_train1, y_train1, X_train2, y_train2 = split_data_by_trend(X_train, y_train)\n",
    "        train_xs = [X_train1, X_train2]\n",
    "        train_ys = [y_train1, y_train2]\n",
    "        \n",
    "        X_test1, y_test1, X_test2, y_test2 = split_data_by_trend(X_test, y_test)\n",
    "        test_xs = [X_test1, X_test2]\n",
    "        test_ys = [y_test1, y_test2]\n",
    "        i_s = [1, 2]\n",
    "        \n",
    "        # 训练\n",
    "        for i in range(len(i_s)):\n",
    "            model = build_direct_dnn_model()\n",
    "            history = model.fit(train_xs[i], train_ys[i], epochs=100, batch_size=16, verbose=1, validation_data=(test_xs[i], test_ys[i]),\n",
    "                           callbacks=[\n",
    "                               EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto', restore_best_weights=True)\n",
    "                           ])\n",
    "            models.append(model)\n",
    "        \n",
    "        # 预测\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "        for i in range(len(i_s)):\n",
    "            y_test.append(test_ys[i])\n",
    "            y_pred.append(models[i].predict(test_xs[i]).reshape(test_ys[i].shape))\n",
    "        \n",
    "        y_test = np.concatenate(y_test)\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "\n",
    "        metrics = ['mae', 'rmse','ndcg', 'mape', 'r2', 'pearson', 'acc']\n",
    "        for m in metrics:\n",
    "            overall, annual = eval_model(m, y_test, y_pred, scaler)\n",
    "            overall_metrics[m].append(overall)\n",
    "            annual_metrics[m].append(annual)\n",
    "    \n",
    "    return overall_metrics, annual_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline():\n",
    "    gene_arr_path = r'../output/gene_editing/es_with_decay.array'\n",
    "    transplant_arr_path = r'../output/transplant/es_with_decay.array'\n",
    "\n",
    "    gene_arr = pickle.load(open(gene_arr_path, mode='rb'))\n",
    "    transplant_arr = pickle.load(open(transplant_arr_path, mode='rb'))\n",
    "    \n",
    "    gene_arr = gene_arr[:, :-1, :]\n",
    "    transplant_arr = transplant_arr[:, :-1, :]\n",
    "\n",
    "    print('Shape of the gene_editing array:',gene_arr.shape)\n",
    "    print('Shape of the transplant array:',transplant_arr.shape)\n",
    "    \n",
    "    metrics = {\n",
    "        'gene':{\n",
    "            'overall':{},\n",
    "            'annual':{}\n",
    "        },\n",
    "        'transplant':{\n",
    "            'overall':{},\n",
    "            'annual':{}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for name, dataset in zip(['gene', 'transplant'], [gene_arr, transplant_arr]):\n",
    "        scaler, data = scale_data(dataset, 'standard')\n",
    "\n",
    "        # 用预测第二年的类别变量作为分成Kfold的依据，不支持浮点数\n",
    "        X, y, y_cat = data[:, :n_input, :], data[:, n_input:, -2], dataset[:, n_input, -1]\n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        overall_metrics, annual_metrics = cross_validation(X, y, y_cat, kfold, scaler)\n",
    "        \n",
    "        for metric, value in overall_metrics.items():\n",
    "            metrics[name]['overall'][metric] = np.mean(value)\n",
    "        \n",
    "        for metric, value in annual_metrics.items():\n",
    "            metrics[name]['annual'][metric] = np.mean(np.array(value), axis=0)\n",
    "    \n",
    "    pickle.dump(metrics, open('mlp_metrics.dict', 'wb'))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the gene_editing array: (2643, 16, 10)\n",
      "Shape of the transplant array: (5141, 16, 10)\n",
      "Train on 988 samples, validate on 256 samples\n",
      "Epoch 1/100\n",
      "988/988 [==============================] - 1s 1ms/sample - loss: 1.2508 - val_loss: 1.1335\n",
      "Epoch 2/100\n",
      "988/988 [==============================] - 0s 191us/sample - loss: 1.0905 - val_loss: 1.0782\n",
      "Epoch 3/100\n",
      "988/988 [==============================] - 0s 186us/sample - loss: 1.0605 - val_loss: 1.0703\n",
      "Epoch 4/100\n",
      "988/988 [==============================] - 0s 188us/sample - loss: 1.0519 - val_loss: 1.0671\n",
      "Epoch 5/100\n",
      "988/988 [==============================] - 0s 189us/sample - loss: 1.0460 - val_loss: 1.0668\n",
      "Epoch 6/100\n",
      "988/988 [==============================] - 0s 197us/sample - loss: 1.0415 - val_loss: 1.0646\n",
      "Epoch 7/100\n",
      "988/988 [==============================] - 0s 187us/sample - loss: 1.0373 - val_loss: 1.0656\n",
      "Epoch 8/100\n",
      "988/988 [==============================] - 0s 187us/sample - loss: 1.0330 - val_loss: 1.0664\n",
      "Epoch 9/100\n",
      "988/988 [==============================] - 0s 192us/sample - loss: 1.0292 - val_loss: 1.0664\n",
      "Epoch 10/100\n",
      "988/988 [==============================] - 0s 187us/sample - loss: 1.0267 - val_loss: 1.0663\n",
      "Epoch 11/100\n",
      "988/988 [==============================] - 0s 187us/sample - loss: 1.0232 - val_loss: 1.0656\n",
      "Epoch 12/100\n",
      "988/988 [==============================] - 0s 189us/sample - loss: 1.0196 - val_loss: 1.0657\n",
      "Epoch 13/100\n",
      "988/988 [==============================] - 0s 186us/sample - loss: 1.0169 - val_loss: 1.0656\n",
      "Epoch 14/100\n",
      "988/988 [==============================] - 0s 190us/sample - loss: 1.0148 - val_loss: 1.0626\n",
      "Epoch 15/100\n",
      "988/988 [==============================] - 0s 190us/sample - loss: 1.0118 - val_loss: 1.0646\n",
      "Epoch 16/100\n",
      "988/988 [==============================] - 0s 193us/sample - loss: 1.0107 - val_loss: 1.0632\n",
      "Epoch 17/100\n",
      "988/988 [==============================] - 0s 192us/sample - loss: 1.0066 - val_loss: 1.0649\n",
      "Epoch 18/100\n",
      "988/988 [==============================] - 0s 189us/sample - loss: 1.0035 - val_loss: 1.0652\n",
      "Epoch 19/100\n",
      "988/988 [==============================] - 0s 188us/sample - loss: 1.0022 - val_loss: 1.0625\n",
      "Epoch 20/100\n",
      "988/988 [==============================] - 0s 192us/sample - loss: 0.9982 - val_loss: 1.0626\n",
      "Epoch 21/100\n",
      "988/988 [==============================] - 0s 187us/sample - loss: 0.9974 - val_loss: 1.0650\n",
      "Epoch 22/100\n",
      "988/988 [==============================] - 0s 197us/sample - loss: 0.9950 - val_loss: 1.0640\n",
      "Epoch 23/100\n",
      "988/988 [==============================] - 0s 192us/sample - loss: 0.9917 - val_loss: 1.0612\n",
      "Epoch 24/100\n",
      "988/988 [==============================] - 0s 191us/sample - loss: 0.9896 - val_loss: 1.0616\n",
      "Epoch 25/100\n",
      "988/988 [==============================] - 0s 190us/sample - loss: 0.9876 - val_loss: 1.0624\n",
      "Epoch 26/100\n",
      "988/988 [==============================] - 0s 191us/sample - loss: 0.9853 - val_loss: 1.0592\n",
      "Epoch 27/100\n",
      "988/988 [==============================] - 0s 192us/sample - loss: 0.9838 - val_loss: 1.0617\n",
      "Epoch 28/100\n",
      "988/988 [==============================] - 0s 189us/sample - loss: 0.9808 - val_loss: 1.0622\n",
      "Epoch 29/100\n",
      "988/988 [==============================] - 0s 192us/sample - loss: 0.9799 - val_loss: 1.0609\n",
      "Epoch 30/100\n",
      "988/988 [==============================] - 0s 190us/sample - loss: 0.9777 - val_loss: 1.0608\n",
      "Epoch 31/100\n",
      "988/988 [==============================] - 0s 203us/sample - loss: 0.9745 - val_loss: 1.0593\n",
      "Epoch 32/100\n",
      "988/988 [==============================] - 0s 210us/sample - loss: 0.9728 - val_loss: 1.0597\n",
      "Epoch 33/100\n",
      "988/988 [==============================] - 0s 212us/sample - loss: 0.9700 - val_loss: 1.0605\n",
      "Epoch 34/100\n",
      "988/988 [==============================] - 0s 221us/sample - loss: 0.9698 - val_loss: 1.0582\n",
      "Epoch 35/100\n",
      "988/988 [==============================] - 0s 227us/sample - loss: 0.9681 - val_loss: 1.0597\n",
      "Epoch 36/100\n",
      "988/988 [==============================] - 0s 236us/sample - loss: 0.9643 - val_loss: 1.0588\n",
      "Epoch 37/100\n",
      "988/988 [==============================] - 0s 223us/sample - loss: 0.9640 - val_loss: 1.0570\n",
      "Epoch 38/100\n",
      "988/988 [==============================] - 0s 223us/sample - loss: 0.9604 - val_loss: 1.0563\n",
      "Epoch 39/100\n",
      "988/988 [==============================] - 0s 206us/sample - loss: 0.9584 - val_loss: 1.0576\n",
      "Epoch 40/100\n",
      "988/988 [==============================] - 0s 206us/sample - loss: 0.9565 - val_loss: 1.0549\n",
      "Epoch 41/100\n",
      "988/988 [==============================] - 0s 198us/sample - loss: 0.9559 - val_loss: 1.0577\n",
      "Epoch 42/100\n",
      "988/988 [==============================] - 0s 201us/sample - loss: 0.9536 - val_loss: 1.0577\n",
      "Epoch 43/100\n",
      "988/988 [==============================] - 0s 197us/sample - loss: 0.9524 - val_loss: 1.0583\n",
      "Epoch 44/100\n",
      "988/988 [==============================] - 0s 197us/sample - loss: 0.9494 - val_loss: 1.0545\n",
      "Epoch 45/100\n",
      "988/988 [==============================] - 0s 197us/sample - loss: 0.9481 - val_loss: 1.0577\n",
      "Epoch 46/100\n",
      "988/988 [==============================] - 0s 220us/sample - loss: 0.9468 - val_loss: 1.0549\n",
      "Epoch 47/100\n",
      "988/988 [==============================] - 0s 212us/sample - loss: 0.9453 - val_loss: 1.0572\n",
      "Epoch 48/100\n",
      "988/988 [==============================] - 0s 204us/sample - loss: 0.9419 - val_loss: 1.0551\n",
      "Epoch 49/100\n",
      "988/988 [==============================] - 0s 217us/sample - loss: 0.9415 - val_loss: 1.0594\n",
      "Epoch 50/100\n",
      "988/988 [==============================] - 0s 220us/sample - loss: 0.9398 - val_loss: 1.0567\n",
      "Epoch 51/100\n",
      "988/988 [==============================] - 0s 216us/sample - loss: 0.9387 - val_loss: 1.0532\n",
      "Epoch 52/100\n",
      "988/988 [==============================] - 0s 212us/sample - loss: 0.9357 - val_loss: 1.0595\n",
      "Epoch 53/100\n",
      "988/988 [==============================] - 0s 206us/sample - loss: 0.9348 - val_loss: 1.0591\n",
      "Epoch 54/100\n",
      "988/988 [==============================] - 0s 218us/sample - loss: 0.9342 - val_loss: 1.0561\n",
      "Epoch 55/100\n",
      "988/988 [==============================] - 0s 210us/sample - loss: 0.9326 - val_loss: 1.0599\n",
      "Epoch 56/100\n",
      "988/988 [==============================] - 0s 209us/sample - loss: 0.9296 - val_loss: 1.0598\n",
      "Epoch 57/100\n",
      "988/988 [==============================] - 0s 203us/sample - loss: 0.9290 - val_loss: 1.0561\n",
      "Epoch 58/100\n",
      "988/988 [==============================] - 0s 218us/sample - loss: 0.9261 - val_loss: 1.0555\n",
      "Epoch 59/100\n",
      "988/988 [==============================] - 0s 220us/sample - loss: 0.9239 - val_loss: 1.0574\n",
      "Epoch 60/100\n",
      "988/988 [==============================] - 0s 194us/sample - loss: 0.9228 - val_loss: 1.0539\n",
      "Epoch 61/100\n",
      "988/988 [==============================] - 0s 225us/sample - loss: 0.9206 - val_loss: 1.0558\n",
      "Train on 1124 samples, validate on 275 samples\n",
      "Epoch 1/100\n",
      "1124/1124 [==============================] - 1s 843us/sample - loss: 0.7908 - val_loss: 0.7106\n",
      "Epoch 2/100\n",
      "1124/1124 [==============================] - 0s 252us/sample - loss: 0.7638 - val_loss: 0.7115\n",
      "Epoch 3/100\n",
      "1124/1124 [==============================] - 0s 266us/sample - loss: 0.7630 - val_loss: 0.7127\n",
      "Epoch 4/100\n",
      "1124/1124 [==============================] - 0s 295us/sample - loss: 0.7640 - val_loss: 0.7127\n",
      "Epoch 5/100\n",
      "1124/1124 [==============================] - 0s 263us/sample - loss: 0.7615 - val_loss: 0.7119\n",
      "Epoch 6/100\n",
      "1124/1124 [==============================] - 0s 262us/sample - loss: 0.7615 - val_loss: 0.7138\n",
      "Epoch 7/100\n",
      "1124/1124 [==============================] - 0s 278us/sample - loss: 0.7616 - val_loss: 0.7148\n",
      "Epoch 8/100\n",
      "1124/1124 [==============================] - 0s 286us/sample - loss: 0.7612 - val_loss: 0.7135\n",
      "Epoch 9/100\n",
      "1124/1124 [==============================] - 0s 260us/sample - loss: 0.7606 - val_loss: 0.7110\n",
      "Epoch 10/100\n",
      "1124/1124 [==============================] - 0s 242us/sample - loss: 0.7604 - val_loss: 0.7118\n",
      "Epoch 11/100\n",
      "1124/1124 [==============================] - 0s 254us/sample - loss: 0.7594 - val_loss: 0.7112\n",
      "Train on 998 samples, validate on 246 samples\n",
      "Epoch 1/100\n",
      "998/998 [==============================] - 1s 1ms/sample - loss: 1.2187 - val_loss: 1.1705\n",
      "Epoch 2/100\n",
      "998/998 [==============================] - 0s 246us/sample - loss: 1.0766 - val_loss: 1.1285\n",
      "Epoch 3/100\n",
      "998/998 [==============================] - 0s 262us/sample - loss: 1.0523 - val_loss: 1.1150\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998/998 [==============================] - 0s 263us/sample - loss: 1.0435 - val_loss: 1.1104\n",
      "Epoch 5/100\n",
      "998/998 [==============================] - 0s 243us/sample - loss: 1.0377 - val_loss: 1.1031\n",
      "Epoch 6/100\n",
      "998/998 [==============================] - 0s 249us/sample - loss: 1.0345 - val_loss: 1.1010\n",
      "Epoch 7/100\n",
      "998/998 [==============================] - 0s 236us/sample - loss: 1.0296 - val_loss: 1.1017\n",
      "Epoch 8/100\n",
      "998/998 [==============================] - 0s 241us/sample - loss: 1.0259 - val_loss: 1.0998\n",
      "Epoch 9/100\n",
      "998/998 [==============================] - 0s 248us/sample - loss: 1.0231 - val_loss: 1.0997\n",
      "Epoch 10/100\n",
      "998/998 [==============================] - 0s 252us/sample - loss: 1.0190 - val_loss: 1.0992\n",
      "Epoch 11/100\n",
      "998/998 [==============================] - 0s 248us/sample - loss: 1.0165 - val_loss: 1.0963\n",
      "Epoch 12/100\n",
      "998/998 [==============================] - 0s 239us/sample - loss: 1.0143 - val_loss: 1.0970\n",
      "Epoch 13/100\n",
      "998/998 [==============================] - 0s 247us/sample - loss: 1.0102 - val_loss: 1.0993\n",
      "Epoch 14/100\n",
      "998/998 [==============================] - 0s 256us/sample - loss: 1.0083 - val_loss: 1.0973\n",
      "Epoch 15/100\n",
      "998/998 [==============================] - 0s 247us/sample - loss: 1.0045 - val_loss: 1.0969\n",
      "Epoch 16/100\n",
      "998/998 [==============================] - 0s 259us/sample - loss: 1.0033 - val_loss: 1.0972\n",
      "Epoch 17/100\n",
      "998/998 [==============================] - 0s 245us/sample - loss: 1.0004 - val_loss: 1.0967\n",
      "Epoch 18/100\n",
      "998/998 [==============================] - 0s 256us/sample - loss: 0.9968 - val_loss: 1.0954\n",
      "Epoch 19/100\n",
      "998/998 [==============================] - 0s 261us/sample - loss: 0.9940 - val_loss: 1.0980\n",
      "Epoch 20/100\n",
      "998/998 [==============================] - 0s 248us/sample - loss: 0.9940 - val_loss: 1.0953\n",
      "Epoch 21/100\n",
      "998/998 [==============================] - 0s 239us/sample - loss: 0.9894 - val_loss: 1.0971\n",
      "Epoch 22/100\n",
      "998/998 [==============================] - 0s 257us/sample - loss: 0.9874 - val_loss: 1.0975\n",
      "Epoch 23/100\n",
      "998/998 [==============================] - 0s 251us/sample - loss: 0.9841 - val_loss: 1.0979\n",
      "Epoch 24/100\n",
      "998/998 [==============================] - 0s 240us/sample - loss: 0.9822 - val_loss: 1.0970\n",
      "Epoch 25/100\n",
      "998/998 [==============================] - 0s 240us/sample - loss: 0.9792 - val_loss: 1.0967\n",
      "Epoch 26/100\n",
      "998/998 [==============================] - 0s 243us/sample - loss: 0.9785 - val_loss: 1.0974\n",
      "Epoch 27/100\n",
      "998/998 [==============================] - 0s 254us/sample - loss: 0.9749 - val_loss: 1.0998\n",
      "Epoch 28/100\n",
      "998/998 [==============================] - 0s 259us/sample - loss: 0.9746 - val_loss: 1.0958\n",
      "Epoch 29/100\n",
      "998/998 [==============================] - 0s 257us/sample - loss: 0.9716 - val_loss: 1.0980\n",
      "Epoch 30/100\n",
      "998/998 [==============================] - 0s 255us/sample - loss: 0.9680 - val_loss: 1.0970\n",
      "Train on 1115 samples, validate on 284 samples\n",
      "Epoch 1/100\n",
      "1115/1115 [==============================] - 1s 849us/sample - loss: 0.7780 - val_loss: 0.7773\n",
      "Epoch 2/100\n",
      "1115/1115 [==============================] - 0s 233us/sample - loss: 0.7474 - val_loss: 0.7781\n",
      "Epoch 3/100\n",
      "1115/1115 [==============================] - 0s 235us/sample - loss: 0.7465 - val_loss: 0.7775\n",
      "Epoch 4/100\n",
      "1115/1115 [==============================] - 0s 229us/sample - loss: 0.7461 - val_loss: 0.7777\n",
      "Epoch 5/100\n",
      "1115/1115 [==============================] - 0s 233us/sample - loss: 0.7463 - val_loss: 0.7777\n",
      "Epoch 6/100\n",
      "1115/1115 [==============================] - 0s 245us/sample - loss: 0.7457 - val_loss: 0.7775\n",
      "Epoch 7/100\n",
      "1115/1115 [==============================] - 0s 233us/sample - loss: 0.7444 - val_loss: 0.7801\n",
      "Epoch 8/100\n",
      "1115/1115 [==============================] - 0s 231us/sample - loss: 0.7440 - val_loss: 0.7774\n",
      "Epoch 9/100\n",
      "1115/1115 [==============================] - 0s 234us/sample - loss: 0.7450 - val_loss: 0.7768\n",
      "Epoch 10/100\n",
      "1115/1115 [==============================] - 0s 238us/sample - loss: 0.7436 - val_loss: 0.7771\n",
      "Epoch 11/100\n",
      "1115/1115 [==============================] - 0s 225us/sample - loss: 0.7431 - val_loss: 0.7788\n",
      "Epoch 12/100\n",
      "1115/1115 [==============================] - 0s 229us/sample - loss: 0.7430 - val_loss: 0.7762\n",
      "Epoch 13/100\n",
      "1115/1115 [==============================] - 0s 224us/sample - loss: 0.7411 - val_loss: 0.7776\n",
      "Epoch 14/100\n",
      "1115/1115 [==============================] - 0s 228us/sample - loss: 0.7422 - val_loss: 0.7771\n",
      "Epoch 15/100\n",
      "1115/1115 [==============================] - 0s 242us/sample - loss: 0.7408 - val_loss: 0.7781\n",
      "Epoch 16/100\n",
      "1115/1115 [==============================] - 0s 246us/sample - loss: 0.7407 - val_loss: 0.7767\n",
      "Epoch 17/100\n",
      "1115/1115 [==============================] - 0s 240us/sample - loss: 0.7415 - val_loss: 0.7763\n",
      "Epoch 18/100\n",
      "1115/1115 [==============================] - 0s 250us/sample - loss: 0.7406 - val_loss: 0.7786\n",
      "Epoch 19/100\n",
      "1115/1115 [==============================] - 0s 230us/sample - loss: 0.7402 - val_loss: 0.7768\n",
      "Epoch 20/100\n",
      "1115/1115 [==============================] - 0s 232us/sample - loss: 0.7409 - val_loss: 0.7755\n",
      "Epoch 21/100\n",
      "1115/1115 [==============================] - 0s 233us/sample - loss: 0.7405 - val_loss: 0.7760\n",
      "Epoch 22/100\n",
      "1115/1115 [==============================] - 0s 242us/sample - loss: 0.7402 - val_loss: 0.7758\n",
      "Epoch 23/100\n",
      "1115/1115 [==============================] - 0s 242us/sample - loss: 0.7398 - val_loss: 0.7785\n",
      "Epoch 24/100\n",
      "1115/1115 [==============================] - 0s 240us/sample - loss: 0.7397 - val_loss: 0.7751\n",
      "Epoch 25/100\n",
      "1115/1115 [==============================] - 0s 233us/sample - loss: 0.7390 - val_loss: 0.7759\n",
      "Epoch 26/100\n",
      "1115/1115 [==============================] - 0s 231us/sample - loss: 0.7393 - val_loss: 0.7767\n",
      "Epoch 27/100\n",
      "1115/1115 [==============================] - 0s 233us/sample - loss: 0.7386 - val_loss: 0.7759\n",
      "Epoch 28/100\n",
      "1115/1115 [==============================] - 0s 240us/sample - loss: 0.7384 - val_loss: 0.7754\n",
      "Epoch 29/100\n",
      "1115/1115 [==============================] - 0s 336us/sample - loss: 0.7386 - val_loss: 0.7758\n",
      "Epoch 30/100\n",
      "1115/1115 [==============================] - 0s 233us/sample - loss: 0.7380 - val_loss: 0.7751\n",
      "Epoch 31/100\n",
      "1115/1115 [==============================] - 0s 250us/sample - loss: 0.7379 - val_loss: 0.7753\n",
      "Epoch 32/100\n",
      "1115/1115 [==============================] - 0s 252us/sample - loss: 0.7389 - val_loss: 0.7755\n",
      "Epoch 33/100\n",
      "1115/1115 [==============================] - 0s 315us/sample - loss: 0.7380 - val_loss: 0.7772\n",
      "Epoch 34/100\n",
      "1115/1115 [==============================] - 0s 260us/sample - loss: 0.7376 - val_loss: 0.7777\n",
      "Train on 995 samples, validate on 249 samples\n",
      "Epoch 1/100\n",
      "995/995 [==============================] - 1s 1ms/sample - loss: 1.1704 - val_loss: 1.0877\n",
      "Epoch 2/100\n",
      "995/995 [==============================] - 0s 250us/sample - loss: 1.0751 - val_loss: 1.0636\n",
      "Epoch 3/100\n",
      "995/995 [==============================] - 0s 269us/sample - loss: 1.0620 - val_loss: 1.0558\n",
      "Epoch 4/100\n",
      "995/995 [==============================] - 0s 274us/sample - loss: 1.0563 - val_loss: 1.0509\n",
      "Epoch 5/100\n",
      "995/995 [==============================] - 0s 288us/sample - loss: 1.0501 - val_loss: 1.0508\n",
      "Epoch 6/100\n",
      "995/995 [==============================] - 0s 271us/sample - loss: 1.0468 - val_loss: 1.0464\n",
      "Epoch 7/100\n",
      "995/995 [==============================] - 0s 273us/sample - loss: 1.0434 - val_loss: 1.0473\n",
      "Epoch 8/100\n",
      "995/995 [==============================] - 0s 266us/sample - loss: 1.0390 - val_loss: 1.0481\n",
      "Epoch 9/100\n",
      "995/995 [==============================] - 0s 261us/sample - loss: 1.0372 - val_loss: 1.0460\n",
      "Epoch 10/100\n",
      "995/995 [==============================] - 0s 246us/sample - loss: 1.0337 - val_loss: 1.0467\n",
      "Epoch 11/100\n",
      "995/995 [==============================] - 0s 297us/sample - loss: 1.0308 - val_loss: 1.0463\n",
      "Epoch 12/100\n",
      "995/995 [==============================] - 0s 241us/sample - loss: 1.0280 - val_loss: 1.0465\n",
      "Epoch 13/100\n",
      "995/995 [==============================] - 0s 241us/sample - loss: 1.0253 - val_loss: 1.0459\n",
      "Epoch 14/100\n",
      "995/995 [==============================] - 0s 262us/sample - loss: 1.0217 - val_loss: 1.0459\n",
      "Epoch 15/100\n",
      "995/995 [==============================] - 0s 270us/sample - loss: 1.0193 - val_loss: 1.0466\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995/995 [==============================] - 0s 245us/sample - loss: 1.0170 - val_loss: 1.0425\n",
      "Epoch 17/100\n",
      "995/995 [==============================] - 0s 281us/sample - loss: 1.0151 - val_loss: 1.0460\n",
      "Epoch 18/100\n",
      "995/995 [==============================] - 0s 258us/sample - loss: 1.0125 - val_loss: 1.0466\n",
      "Epoch 19/100\n",
      "995/995 [==============================] - 0s 271us/sample - loss: 1.0082 - val_loss: 1.0447\n",
      "Epoch 20/100\n",
      "995/995 [==============================] - 0s 252us/sample - loss: 1.0068 - val_loss: 1.0451\n",
      "Epoch 21/100\n",
      "995/995 [==============================] - 0s 260us/sample - loss: 1.0039 - val_loss: 1.0475\n",
      "Epoch 22/100\n",
      "995/995 [==============================] - 0s 238us/sample - loss: 1.0015 - val_loss: 1.0448\n",
      "Epoch 23/100\n",
      "995/995 [==============================] - 0s 243us/sample - loss: 1.0007 - val_loss: 1.0462\n",
      "Epoch 24/100\n",
      "995/995 [==============================] - 0s 278us/sample - loss: 0.9972 - val_loss: 1.0446\n",
      "Epoch 25/100\n",
      "995/995 [==============================] - 0s 240us/sample - loss: 0.9947 - val_loss: 1.0486\n",
      "Epoch 26/100\n",
      "995/995 [==============================] - 0s 239us/sample - loss: 0.9919 - val_loss: 1.0485\n",
      "Train on 1120 samples, validate on 279 samples\n",
      "Epoch 1/100\n",
      "1120/1120 [==============================] - 1s 848us/sample - loss: 0.7852 - val_loss: 0.7636\n",
      "Epoch 2/100\n",
      "1120/1120 [==============================] - 0s 224us/sample - loss: 0.7527 - val_loss: 0.7632\n",
      "Epoch 3/100\n",
      "1120/1120 [==============================] - 0s 230us/sample - loss: 0.7518 - val_loss: 0.7625\n",
      "Epoch 4/100\n",
      "1120/1120 [==============================] - 0s 239us/sample - loss: 0.7511 - val_loss: 0.7622\n",
      "Epoch 5/100\n",
      "1120/1120 [==============================] - 0s 329us/sample - loss: 0.7497 - val_loss: 0.7621\n",
      "Epoch 6/100\n",
      "1120/1120 [==============================] - 0s 230us/sample - loss: 0.7497 - val_loss: 0.7622\n",
      "Epoch 7/100\n",
      "1120/1120 [==============================] - 0s 218us/sample - loss: 0.7497 - val_loss: 0.7625\n",
      "Epoch 8/100\n",
      "1120/1120 [==============================] - 0s 212us/sample - loss: 0.7480 - val_loss: 0.7616\n",
      "Epoch 9/100\n",
      "1120/1120 [==============================] - 0s 212us/sample - loss: 0.7475 - val_loss: 0.7624\n",
      "Epoch 10/100\n",
      "1120/1120 [==============================] - 0s 272us/sample - loss: 0.7470 - val_loss: 0.7632\n",
      "Epoch 11/100\n",
      "1120/1120 [==============================] - 0s 223us/sample - loss: 0.7474 - val_loss: 0.7629\n",
      "Epoch 12/100\n",
      "1120/1120 [==============================] - 0s 215us/sample - loss: 0.7465 - val_loss: 0.7620\n",
      "Epoch 13/100\n",
      "1120/1120 [==============================] - 0s 232us/sample - loss: 0.7457 - val_loss: 0.7633\n",
      "Epoch 14/100\n",
      "1120/1120 [==============================] - 0s 227us/sample - loss: 0.7450 - val_loss: 0.7648\n",
      "Epoch 15/100\n",
      "1120/1120 [==============================] - 0s 255us/sample - loss: 0.7455 - val_loss: 0.7623\n",
      "Epoch 16/100\n",
      "1120/1120 [==============================] - 0s 277us/sample - loss: 0.7446 - val_loss: 0.7627\n",
      "Epoch 17/100\n",
      "1120/1120 [==============================] - 0s 265us/sample - loss: 0.7440 - val_loss: 0.7616\n",
      "Epoch 18/100\n",
      "1120/1120 [==============================] - 0s 255us/sample - loss: 0.7429 - val_loss: 0.7618\n",
      "Epoch 19/100\n",
      "1120/1120 [==============================] - 0s 222us/sample - loss: 0.7433 - val_loss: 0.7606\n",
      "Epoch 20/100\n",
      "1120/1120 [==============================] - 0s 221us/sample - loss: 0.7432 - val_loss: 0.7610\n",
      "Epoch 21/100\n",
      "1120/1120 [==============================] - 0s 224us/sample - loss: 0.7425 - val_loss: 0.7601\n",
      "Epoch 22/100\n",
      "1120/1120 [==============================] - 0s 238us/sample - loss: 0.7428 - val_loss: 0.7609\n",
      "Epoch 23/100\n",
      "1120/1120 [==============================] - 0s 250us/sample - loss: 0.7426 - val_loss: 0.7606\n",
      "Epoch 24/100\n",
      "1120/1120 [==============================] - 0s 218us/sample - loss: 0.7418 - val_loss: 0.7606\n",
      "Epoch 25/100\n",
      "1120/1120 [==============================] - 0s 216us/sample - loss: 0.7415 - val_loss: 0.7623\n",
      "Epoch 26/100\n",
      "1120/1120 [==============================] - 0s 221us/sample - loss: 0.7415 - val_loss: 0.7603\n",
      "Epoch 27/100\n",
      "1120/1120 [==============================] - 0s 266us/sample - loss: 0.7418 - val_loss: 0.7625\n",
      "Epoch 28/100\n",
      "1120/1120 [==============================] - 0s 271us/sample - loss: 0.7421 - val_loss: 0.7601\n",
      "Epoch 29/100\n",
      "1120/1120 [==============================] - 0s 225us/sample - loss: 0.7407 - val_loss: 0.7612\n",
      "Epoch 30/100\n",
      "1120/1120 [==============================] - 0s 241us/sample - loss: 0.7409 - val_loss: 0.7606\n",
      "Epoch 31/100\n",
      "1120/1120 [==============================] - 0s 273us/sample - loss: 0.7400 - val_loss: 0.7616\n",
      "Train on 991 samples, validate on 253 samples\n",
      "Epoch 1/100\n",
      "991/991 [==============================] - 1s 1ms/sample - loss: 1.1672 - val_loss: 1.0703\n",
      "Epoch 2/100\n",
      "991/991 [==============================] - 0s 234us/sample - loss: 1.0846 - val_loss: 1.0515\n",
      "Epoch 3/100\n",
      "991/991 [==============================] - 0s 233us/sample - loss: 1.0634 - val_loss: 1.0547\n",
      "Epoch 4/100\n",
      "991/991 [==============================] - 0s 237us/sample - loss: 1.0524 - val_loss: 1.0651\n",
      "Epoch 5/100\n",
      "991/991 [==============================] - 0s 233us/sample - loss: 1.0459 - val_loss: 1.0670\n",
      "Epoch 6/100\n",
      "991/991 [==============================] - 0s 229us/sample - loss: 1.0406 - val_loss: 1.0697\n",
      "Epoch 7/100\n",
      "991/991 [==============================] - 0s 228us/sample - loss: 1.0364 - val_loss: 1.0732\n",
      "Epoch 8/100\n",
      "991/991 [==============================] - 0s 225us/sample - loss: 1.0329 - val_loss: 1.0744\n",
      "Epoch 9/100\n",
      "991/991 [==============================] - 0s 285us/sample - loss: 1.0293 - val_loss: 1.0763\n",
      "Epoch 10/100\n",
      "991/991 [==============================] - 0s 255us/sample - loss: 1.0260 - val_loss: 1.0832\n",
      "Epoch 11/100\n",
      "991/991 [==============================] - 0s 249us/sample - loss: 1.0232 - val_loss: 1.0814\n",
      "Epoch 12/100\n",
      "991/991 [==============================] - 0s 238us/sample - loss: 1.0196 - val_loss: 1.0782\n",
      "Train on 1125 samples, validate on 274 samples\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 1s 873us/sample - loss: 0.7930 - val_loss: 0.7912\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 0s 223us/sample - loss: 0.7447 - val_loss: 0.7910\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 0s 223us/sample - loss: 0.7436 - val_loss: 0.7913\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 0s 224us/sample - loss: 0.7429 - val_loss: 0.7916\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 0s 223us/sample - loss: 0.7426 - val_loss: 0.7921\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 0s 230us/sample - loss: 0.7418 - val_loss: 0.7937\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 0s 228us/sample - loss: 0.7414 - val_loss: 0.7954\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 0s 224us/sample - loss: 0.7416 - val_loss: 0.7941\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 0s 223us/sample - loss: 0.7404 - val_loss: 0.7925\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 0s 223us/sample - loss: 0.7395 - val_loss: 0.7934\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 0s 230us/sample - loss: 0.7386 - val_loss: 0.7947\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 0s 263us/sample - loss: 0.7390 - val_loss: 0.7937\n",
      "Train on 1004 samples, validate on 240 samples\n",
      "Epoch 1/100\n",
      "1004/1004 [==============================] - 1s 883us/sample - loss: 1.1904 - val_loss: 1.0657\n",
      "Epoch 2/100\n",
      "1004/1004 [==============================] - 0s 225us/sample - loss: 1.0826 - val_loss: 1.0438\n",
      "Epoch 3/100\n",
      "1004/1004 [==============================] - 0s 225us/sample - loss: 1.0650 - val_loss: 1.0334\n",
      "Epoch 4/100\n",
      "1004/1004 [==============================] - 0s 221us/sample - loss: 1.0572 - val_loss: 1.0326\n",
      "Epoch 5/100\n",
      "1004/1004 [==============================] - 0s 231us/sample - loss: 1.0523 - val_loss: 1.0295\n",
      "Epoch 6/100\n",
      "1004/1004 [==============================] - 0s 224us/sample - loss: 1.0483 - val_loss: 1.0287\n",
      "Epoch 7/100\n",
      "1004/1004 [==============================] - 0s 235us/sample - loss: 1.0445 - val_loss: 1.0293\n",
      "Epoch 8/100\n",
      "1004/1004 [==============================] - 0s 226us/sample - loss: 1.0400 - val_loss: 1.0278\n",
      "Epoch 9/100\n",
      "1004/1004 [==============================] - 0s 219us/sample - loss: 1.0365 - val_loss: 1.0266\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004/1004 [==============================] - 0s 225us/sample - loss: 1.0337 - val_loss: 1.0255\n",
      "Epoch 11/100\n",
      "1004/1004 [==============================] - 0s 224us/sample - loss: 1.0306 - val_loss: 1.0264\n",
      "Epoch 12/100\n",
      "1004/1004 [==============================] - 0s 224us/sample - loss: 1.0271 - val_loss: 1.0234\n",
      "Epoch 13/100\n",
      "1004/1004 [==============================] - 0s 216us/sample - loss: 1.0243 - val_loss: 1.0259\n",
      "Epoch 14/100\n",
      "1004/1004 [==============================] - 0s 225us/sample - loss: 1.0218 - val_loss: 1.0266\n",
      "Epoch 15/100\n",
      "1004/1004 [==============================] - 0s 223us/sample - loss: 1.0193 - val_loss: 1.0246\n",
      "Epoch 16/100\n",
      "1004/1004 [==============================] - 0s 225us/sample - loss: 1.0162 - val_loss: 1.0228\n",
      "Epoch 17/100\n",
      "1004/1004 [==============================] - 0s 218us/sample - loss: 1.0138 - val_loss: 1.0217\n",
      "Epoch 18/100\n",
      "1004/1004 [==============================] - 0s 223us/sample - loss: 1.0119 - val_loss: 1.0212\n",
      "Epoch 19/100\n",
      "1004/1004 [==============================] - 0s 221us/sample - loss: 1.0098 - val_loss: 1.0248\n",
      "Epoch 20/100\n",
      "1004/1004 [==============================] - 0s 224us/sample - loss: 1.0064 - val_loss: 1.0261\n",
      "Epoch 21/100\n",
      "1004/1004 [==============================] - 0s 216us/sample - loss: 1.0041 - val_loss: 1.0218\n",
      "Epoch 22/100\n",
      "1004/1004 [==============================] - 0s 221us/sample - loss: 1.0022 - val_loss: 1.0188\n",
      "Epoch 23/100\n",
      "1004/1004 [==============================] - 0s 221us/sample - loss: 1.0009 - val_loss: 1.0227\n",
      "Epoch 24/100\n",
      "1004/1004 [==============================] - 0s 229us/sample - loss: 0.9979 - val_loss: 1.0175\n",
      "Epoch 25/100\n",
      "1004/1004 [==============================] - 0s 215us/sample - loss: 0.9948 - val_loss: 1.0203\n",
      "Epoch 26/100\n",
      "1004/1004 [==============================] - 0s 215us/sample - loss: 0.9927 - val_loss: 1.0160\n",
      "Epoch 27/100\n",
      "1004/1004 [==============================] - 0s 223us/sample - loss: 0.9919 - val_loss: 1.0163\n",
      "Epoch 28/100\n",
      "1004/1004 [==============================] - 0s 220us/sample - loss: 0.9894 - val_loss: 1.0195\n",
      "Epoch 29/100\n",
      "1004/1004 [==============================] - 0s 224us/sample - loss: 0.9866 - val_loss: 1.0173\n",
      "Epoch 30/100\n",
      "1004/1004 [==============================] - 0s 222us/sample - loss: 0.9846 - val_loss: 1.0217\n",
      "Epoch 31/100\n",
      "1004/1004 [==============================] - 0s 221us/sample - loss: 0.9829 - val_loss: 1.0184\n",
      "Epoch 32/100\n",
      "1004/1004 [==============================] - 0s 214us/sample - loss: 0.9793 - val_loss: 1.0241\n",
      "Epoch 33/100\n",
      "1004/1004 [==============================] - 0s 225us/sample - loss: 0.9792 - val_loss: 1.0182\n",
      "Epoch 34/100\n",
      "1004/1004 [==============================] - 0s 222us/sample - loss: 0.9763 - val_loss: 1.0154\n",
      "Epoch 35/100\n",
      "1004/1004 [==============================] - 0s 217us/sample - loss: 0.9753 - val_loss: 1.0207\n",
      "Epoch 36/100\n",
      "1004/1004 [==============================] - 0s 223us/sample - loss: 0.9721 - val_loss: 1.0151\n",
      "Epoch 37/100\n",
      "1004/1004 [==============================] - 0s 220us/sample - loss: 0.9716 - val_loss: 1.0142\n",
      "Epoch 38/100\n",
      "1004/1004 [==============================] - 0s 215us/sample - loss: 0.9685 - val_loss: 1.0187\n",
      "Epoch 39/100\n",
      "1004/1004 [==============================] - 0s 226us/sample - loss: 0.9667 - val_loss: 1.0163\n",
      "Epoch 40/100\n",
      "1004/1004 [==============================] - 0s 218us/sample - loss: 0.9652 - val_loss: 1.0189\n",
      "Epoch 41/100\n",
      "1004/1004 [==============================] - 0s 217us/sample - loss: 0.9630 - val_loss: 1.0147\n",
      "Epoch 42/100\n",
      "1004/1004 [==============================] - 0s 224us/sample - loss: 0.9626 - val_loss: 1.0148\n",
      "Epoch 43/100\n",
      "1004/1004 [==============================] - 0s 220us/sample - loss: 0.9597 - val_loss: 1.0169\n",
      "Epoch 44/100\n",
      "1004/1004 [==============================] - 0s 214us/sample - loss: 0.9569 - val_loss: 1.0177\n",
      "Epoch 45/100\n",
      "1004/1004 [==============================] - 0s 221us/sample - loss: 0.9556 - val_loss: 1.0169\n",
      "Epoch 46/100\n",
      "1004/1004 [==============================] - 0s 217us/sample - loss: 0.9556 - val_loss: 1.0164\n",
      "Epoch 47/100\n",
      "1004/1004 [==============================] - 0s 225us/sample - loss: 0.9528 - val_loss: 1.0170\n",
      "Train on 1112 samples, validate on 287 samples\n",
      "Epoch 1/100\n",
      "1112/1112 [==============================] - 1s 810us/sample - loss: 0.8255 - val_loss: 0.7330\n",
      "Epoch 2/100\n",
      "1112/1112 [==============================] - 0s 218us/sample - loss: 0.7607 - val_loss: 0.7303\n",
      "Epoch 3/100\n",
      "1112/1112 [==============================] - 0s 221us/sample - loss: 0.7596 - val_loss: 0.7313\n",
      "Epoch 4/100\n",
      "1112/1112 [==============================] - 0s 230us/sample - loss: 0.7597 - val_loss: 0.7258\n",
      "Epoch 5/100\n",
      "1112/1112 [==============================] - 0s 225us/sample - loss: 0.7588 - val_loss: 0.7272\n",
      "Epoch 6/100\n",
      "1112/1112 [==============================] - 0s 222us/sample - loss: 0.7580 - val_loss: 0.7278\n",
      "Epoch 7/100\n",
      "1112/1112 [==============================] - 0s 225us/sample - loss: 0.7568 - val_loss: 0.7298\n",
      "Epoch 8/100\n",
      "1112/1112 [==============================] - 0s 228us/sample - loss: 0.7572 - val_loss: 0.7283\n",
      "Epoch 9/100\n",
      "1112/1112 [==============================] - 0s 222us/sample - loss: 0.7564 - val_loss: 0.7271\n",
      "Epoch 10/100\n",
      "1112/1112 [==============================] - 0s 222us/sample - loss: 0.7557 - val_loss: 0.7271\n",
      "Epoch 11/100\n",
      "1112/1112 [==============================] - 0s 221us/sample - loss: 0.7559 - val_loss: 0.7280\n",
      "Epoch 12/100\n",
      "1112/1112 [==============================] - 0s 239us/sample - loss: 0.7545 - val_loss: 0.7293\n",
      "Epoch 13/100\n",
      "1112/1112 [==============================] - 0s 222us/sample - loss: 0.7539 - val_loss: 0.7243\n",
      "Epoch 14/100\n",
      "1112/1112 [==============================] - 0s 219us/sample - loss: 0.7541 - val_loss: 0.7287\n",
      "Epoch 15/100\n",
      "1112/1112 [==============================] - 0s 224us/sample - loss: 0.7538 - val_loss: 0.7260\n",
      "Epoch 16/100\n",
      "1112/1112 [==============================] - 0s 221us/sample - loss: 0.7528 - val_loss: 0.7289\n",
      "Epoch 17/100\n",
      "1112/1112 [==============================] - 0s 224us/sample - loss: 0.7532 - val_loss: 0.7264\n",
      "Epoch 18/100\n",
      "1112/1112 [==============================] - 0s 222us/sample - loss: 0.7526 - val_loss: 0.7269\n",
      "Epoch 19/100\n",
      "1112/1112 [==============================] - 0s 215us/sample - loss: 0.7515 - val_loss: 0.7280\n",
      "Epoch 20/100\n",
      "1112/1112 [==============================] - 0s 232us/sample - loss: 0.7517 - val_loss: 0.7278\n",
      "Epoch 21/100\n",
      "1112/1112 [==============================] - 0s 220us/sample - loss: 0.7519 - val_loss: 0.7275\n",
      "Epoch 22/100\n",
      "1112/1112 [==============================] - 0s 222us/sample - loss: 0.7508 - val_loss: 0.7245\n",
      "Epoch 23/100\n",
      "1112/1112 [==============================] - 0s 226us/sample - loss: 0.7501 - val_loss: 0.7266\n",
      "Train on 3531 samples, validate on 884 samples\n",
      "Epoch 1/100\n",
      "3531/3531 [==============================] - 1s 370us/sample - loss: 0.6963 - val_loss: 0.6407\n",
      "Epoch 2/100\n",
      "3531/3531 [==============================] - 1s 198us/sample - loss: 0.6398 - val_loss: 0.6345\n",
      "Epoch 3/100\n",
      "3531/3531 [==============================] - 1s 197us/sample - loss: 0.6303 - val_loss: 0.6337\n",
      "Epoch 4/100\n",
      "3531/3531 [==============================] - 1s 197us/sample - loss: 0.6226 - val_loss: 0.6347\n",
      "Epoch 5/100\n",
      "3531/3531 [==============================] - 1s 195us/sample - loss: 0.6166 - val_loss: 0.6314\n",
      "Epoch 6/100\n",
      "3531/3531 [==============================] - 1s 198us/sample - loss: 0.6125 - val_loss: 0.6299\n",
      "Epoch 7/100\n",
      "3531/3531 [==============================] - 1s 197us/sample - loss: 0.6088 - val_loss: 0.6343\n",
      "Epoch 8/100\n",
      "3531/3531 [==============================] - 1s 197us/sample - loss: 0.6053 - val_loss: 0.6290\n",
      "Epoch 9/100\n",
      "3531/3531 [==============================] - 1s 201us/sample - loss: 0.6018 - val_loss: 0.6303\n",
      "Epoch 10/100\n",
      "3531/3531 [==============================] - 1s 199us/sample - loss: 0.5979 - val_loss: 0.6309\n",
      "Epoch 11/100\n",
      "3531/3531 [==============================] - 1s 195us/sample - loss: 0.5948 - val_loss: 0.6291\n",
      "Epoch 12/100\n",
      "3531/3531 [==============================] - 1s 191us/sample - loss: 0.5904 - val_loss: 0.6314\n",
      "Epoch 13/100\n",
      "3531/3531 [==============================] - 1s 190us/sample - loss: 0.5879 - val_loss: 0.6334\n",
      "Epoch 14/100\n",
      "3531/3531 [==============================] - 1s 192us/sample - loss: 0.5842 - val_loss: 0.6316\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3531/3531 [==============================] - 1s 193us/sample - loss: 0.5812 - val_loss: 0.6360\n",
      "Epoch 16/100\n",
      "3531/3531 [==============================] - 1s 191us/sample - loss: 0.5776 - val_loss: 0.6321\n",
      "Epoch 17/100\n",
      "3531/3531 [==============================] - 1s 189us/sample - loss: 0.5755 - val_loss: 0.6344\n",
      "Epoch 18/100\n",
      "3531/3531 [==============================] - 1s 192us/sample - loss: 0.5728 - val_loss: 0.6324\n",
      "Train on 580 samples, validate on 146 samples\n",
      "Epoch 1/100\n",
      "580/580 [==============================] - 1s 2ms/sample - loss: 0.5291 - val_loss: 0.5190\n",
      "Epoch 2/100\n",
      "580/580 [==============================] - 0s 248us/sample - loss: 0.4412 - val_loss: 0.4955\n",
      "Epoch 3/100\n",
      "580/580 [==============================] - 0s 248us/sample - loss: 0.4166 - val_loss: 0.4808\n",
      "Epoch 4/100\n",
      "580/580 [==============================] - 0s 258us/sample - loss: 0.4022 - val_loss: 0.4734\n",
      "Epoch 5/100\n",
      "580/580 [==============================] - 0s 267us/sample - loss: 0.3934 - val_loss: 0.4725\n",
      "Epoch 6/100\n",
      "580/580 [==============================] - 0s 316us/sample - loss: 0.3910 - val_loss: 0.4686\n",
      "Epoch 7/100\n",
      "580/580 [==============================] - 0s 260us/sample - loss: 0.3808 - val_loss: 0.4667\n",
      "Epoch 8/100\n",
      "580/580 [==============================] - 0s 267us/sample - loss: 0.3764 - val_loss: 0.4656\n",
      "Epoch 9/100\n",
      "580/580 [==============================] - 0s 263us/sample - loss: 0.3710 - val_loss: 0.4637\n",
      "Epoch 10/100\n",
      "580/580 [==============================] - 0s 267us/sample - loss: 0.3648 - val_loss: 0.4630\n",
      "Epoch 11/100\n",
      "580/580 [==============================] - 0s 261us/sample - loss: 0.3648 - val_loss: 0.4594\n",
      "Epoch 12/100\n",
      "580/580 [==============================] - 0s 265us/sample - loss: 0.3572 - val_loss: 0.4622\n",
      "Epoch 13/100\n",
      "580/580 [==============================] - 0s 258us/sample - loss: 0.3539 - val_loss: 0.4580\n",
      "Epoch 14/100\n",
      "580/580 [==============================] - 0s 265us/sample - loss: 0.3512 - val_loss: 0.4619\n",
      "Epoch 15/100\n",
      "580/580 [==============================] - 0s 254us/sample - loss: 0.3470 - val_loss: 0.4578\n",
      "Epoch 16/100\n",
      "580/580 [==============================] - 0s 260us/sample - loss: 0.3430 - val_loss: 0.4582\n",
      "Epoch 17/100\n",
      "580/580 [==============================] - 0s 270us/sample - loss: 0.3420 - val_loss: 0.4575\n",
      "Epoch 18/100\n",
      "580/580 [==============================] - 0s 261us/sample - loss: 0.3392 - val_loss: 0.4590\n",
      "Epoch 19/100\n",
      "580/580 [==============================] - 0s 272us/sample - loss: 0.3348 - val_loss: 0.4581\n",
      "Epoch 20/100\n",
      "580/580 [==============================] - 0s 258us/sample - loss: 0.3350 - val_loss: 0.4614\n",
      "Epoch 21/100\n",
      "580/580 [==============================] - 0s 261us/sample - loss: 0.3310 - val_loss: 0.4597\n",
      "Epoch 22/100\n",
      "580/580 [==============================] - 0s 267us/sample - loss: 0.3314 - val_loss: 0.4582\n",
      "Epoch 23/100\n",
      "580/580 [==============================] - 0s 256us/sample - loss: 0.3243 - val_loss: 0.4574\n",
      "Epoch 24/100\n",
      "580/580 [==============================] - 0s 263us/sample - loss: 0.3227 - val_loss: 0.4544\n",
      "Epoch 25/100\n",
      "580/580 [==============================] - 0s 258us/sample - loss: 0.3230 - val_loss: 0.4563\n",
      "Epoch 26/100\n",
      "580/580 [==============================] - 0s 258us/sample - loss: 0.3171 - val_loss: 0.4577\n",
      "Epoch 27/100\n",
      "580/580 [==============================] - 0s 261us/sample - loss: 0.3149 - val_loss: 0.4562\n",
      "Epoch 28/100\n",
      "580/580 [==============================] - 0s 256us/sample - loss: 0.3150 - val_loss: 0.4551\n",
      "Epoch 29/100\n",
      "580/580 [==============================] - 0s 258us/sample - loss: 0.3115 - val_loss: 0.4564\n",
      "Epoch 30/100\n",
      "580/580 [==============================] - 0s 261us/sample - loss: 0.3102 - val_loss: 0.4568\n",
      "Epoch 31/100\n",
      "580/580 [==============================] - 0s 251us/sample - loss: 0.3069 - val_loss: 0.4542\n",
      "Epoch 32/100\n",
      "580/580 [==============================] - 0s 267us/sample - loss: 0.3052 - val_loss: 0.4550\n",
      "Epoch 33/100\n",
      "580/580 [==============================] - 0s 258us/sample - loss: 0.3038 - val_loss: 0.4537\n",
      "Epoch 34/100\n",
      "580/580 [==============================] - 0s 261us/sample - loss: 0.3013 - val_loss: 0.4563\n",
      "Epoch 35/100\n",
      "580/580 [==============================] - 0s 268us/sample - loss: 0.2995 - val_loss: 0.4542\n",
      "Epoch 36/100\n",
      "580/580 [==============================] - 0s 272us/sample - loss: 0.3002 - val_loss: 0.4563\n",
      "Epoch 37/100\n",
      "580/580 [==============================] - 0s 273us/sample - loss: 0.2953 - val_loss: 0.4535\n",
      "Epoch 38/100\n",
      "580/580 [==============================] - 0s 273us/sample - loss: 0.2939 - val_loss: 0.4546\n",
      "Epoch 39/100\n",
      "580/580 [==============================] - 0s 265us/sample - loss: 0.2946 - val_loss: 0.4567\n",
      "Epoch 40/100\n",
      "580/580 [==============================] - 0s 267us/sample - loss: 0.2889 - val_loss: 0.4558\n",
      "Epoch 41/100\n",
      "580/580 [==============================] - 0s 268us/sample - loss: 0.2877 - val_loss: 0.4553\n",
      "Epoch 42/100\n",
      "580/580 [==============================] - 0s 299us/sample - loss: 0.2863 - val_loss: 0.4561\n",
      "Epoch 43/100\n",
      "580/580 [==============================] - 0s 316us/sample - loss: 0.2856 - val_loss: 0.4566\n",
      "Epoch 44/100\n",
      "580/580 [==============================] - 0s 294us/sample - loss: 0.2835 - val_loss: 0.4566\n",
      "Epoch 45/100\n",
      "580/580 [==============================] - 0s 268us/sample - loss: 0.2811 - val_loss: 0.4553\n",
      "Epoch 46/100\n",
      "580/580 [==============================] - 0s 346us/sample - loss: 0.2804 - val_loss: 0.4560\n",
      "Epoch 47/100\n",
      "580/580 [==============================] - 0s 260us/sample - loss: 0.2787 - val_loss: 0.4548\n",
      "Train on 3542 samples, validate on 873 samples\n",
      "Epoch 1/100\n",
      "3542/3542 [==============================] - 2s 438us/sample - loss: 0.6901 - val_loss: 0.6590\n",
      "Epoch 2/100\n",
      "3542/3542 [==============================] - 1s 234us/sample - loss: 0.6400 - val_loss: 0.6480\n",
      "Epoch 3/100\n",
      "3542/3542 [==============================] - 1s 218us/sample - loss: 0.6285 - val_loss: 0.6420\n",
      "Epoch 4/100\n",
      "3542/3542 [==============================] - 1s 219us/sample - loss: 0.6218 - val_loss: 0.6395\n",
      "Epoch 5/100\n",
      "3542/3542 [==============================] - 1s 250us/sample - loss: 0.6135 - val_loss: 0.6398\n",
      "Epoch 6/100\n",
      "3542/3542 [==============================] - 1s 216us/sample - loss: 0.6099 - val_loss: 0.6377\n",
      "Epoch 7/100\n",
      "3542/3542 [==============================] - 1s 213us/sample - loss: 0.6046 - val_loss: 0.6374\n",
      "Epoch 8/100\n",
      "3542/3542 [==============================] - 1s 221us/sample - loss: 0.6008 - val_loss: 0.6365\n",
      "Epoch 9/100\n",
      "3542/3542 [==============================] - 1s 253us/sample - loss: 0.5971 - val_loss: 0.6360\n",
      "Epoch 10/100\n",
      "3542/3542 [==============================] - 1s 209us/sample - loss: 0.5931 - val_loss: 0.6401\n",
      "Epoch 11/100\n",
      "3542/3542 [==============================] - 1s 225us/sample - loss: 0.5904 - val_loss: 0.6356\n",
      "Epoch 12/100\n",
      "3542/3542 [==============================] - 1s 235us/sample - loss: 0.5871 - val_loss: 0.6351\n",
      "Epoch 13/100\n",
      "3542/3542 [==============================] - 1s 240us/sample - loss: 0.5834 - val_loss: 0.6360\n",
      "Epoch 14/100\n",
      "3542/3542 [==============================] - 1s 245us/sample - loss: 0.5800 - val_loss: 0.6351\n",
      "Epoch 15/100\n",
      "3542/3542 [==============================] - 1s 230us/sample - loss: 0.5770 - val_loss: 0.6424\n",
      "Epoch 16/100\n",
      "3542/3542 [==============================] - 1s 220us/sample - loss: 0.5728 - val_loss: 0.6382\n",
      "Epoch 17/100\n",
      "3542/3542 [==============================] - 1s 212us/sample - loss: 0.5710 - val_loss: 0.6357\n",
      "Epoch 18/100\n",
      "3542/3542 [==============================] - 1s 207us/sample - loss: 0.5676 - val_loss: 0.6375\n",
      "Epoch 19/100\n",
      "3542/3542 [==============================] - 1s 215us/sample - loss: 0.5650 - val_loss: 0.6385\n",
      "Epoch 20/100\n",
      "3542/3542 [==============================] - 1s 215us/sample - loss: 0.5619 - val_loss: 0.6374\n",
      "Epoch 21/100\n",
      "3542/3542 [==============================] - 1s 213us/sample - loss: 0.5593 - val_loss: 0.6381\n",
      "Epoch 22/100\n",
      "3542/3542 [==============================] - 1s 215us/sample - loss: 0.5576 - val_loss: 0.6381\n",
      "Train on 570 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "570/570 [==============================] - 1s 2ms/sample - loss: 0.5504 - val_loss: 0.4536\n",
      "Epoch 2/100\n",
      "570/570 [==============================] - 0s 257us/sample - loss: 0.4534 - val_loss: 0.4329\n",
      "Epoch 3/100\n",
      "570/570 [==============================] - 0s 282us/sample - loss: 0.4254 - val_loss: 0.4274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "570/570 [==============================] - 0s 271us/sample - loss: 0.4112 - val_loss: 0.4257\n",
      "Epoch 5/100\n",
      "570/570 [==============================] - 0s 294us/sample - loss: 0.4016 - val_loss: 0.4245\n",
      "Epoch 6/100\n",
      "570/570 [==============================] - 0s 276us/sample - loss: 0.3927 - val_loss: 0.4248\n",
      "Epoch 7/100\n",
      "570/570 [==============================] - 0s 268us/sample - loss: 0.3877 - val_loss: 0.4260\n",
      "Epoch 8/100\n",
      "570/570 [==============================] - 0s 268us/sample - loss: 0.3824 - val_loss: 0.4267\n",
      "Epoch 9/100\n",
      "570/570 [==============================] - 0s 269us/sample - loss: 0.3783 - val_loss: 0.4270\n",
      "Epoch 10/100\n",
      "570/570 [==============================] - 0s 268us/sample - loss: 0.3749 - val_loss: 0.4272\n",
      "Epoch 11/100\n",
      "570/570 [==============================] - 0s 266us/sample - loss: 0.3713 - val_loss: 0.4269\n",
      "Epoch 12/100\n",
      "570/570 [==============================] - 0s 261us/sample - loss: 0.3668 - val_loss: 0.4265\n",
      "Epoch 13/100\n",
      "570/570 [==============================] - 0s 262us/sample - loss: 0.3633 - val_loss: 0.4269\n",
      "Epoch 14/100\n",
      "570/570 [==============================] - 0s 264us/sample - loss: 0.3641 - val_loss: 0.4273\n",
      "Epoch 15/100\n",
      "570/570 [==============================] - 0s 271us/sample - loss: 0.3551 - val_loss: 0.4279\n",
      "Train on 3535 samples, validate on 880 samples\n",
      "Epoch 1/100\n",
      "3535/3535 [==============================] - 1s 378us/sample - loss: 0.6759 - val_loss: 0.6494\n",
      "Epoch 2/100\n",
      "3535/3535 [==============================] - 1s 207us/sample - loss: 0.6330 - val_loss: 0.6465\n",
      "Epoch 3/100\n",
      "3535/3535 [==============================] - 1s 214us/sample - loss: 0.6238 - val_loss: 0.6431\n",
      "Epoch 4/100\n",
      "3535/3535 [==============================] - 1s 209us/sample - loss: 0.6166 - val_loss: 0.6421\n",
      "Epoch 5/100\n",
      "3535/3535 [==============================] - 1s 205us/sample - loss: 0.6113 - val_loss: 0.6418\n",
      "Epoch 6/100\n",
      "3535/3535 [==============================] - 1s 212us/sample - loss: 0.6062 - val_loss: 0.6421\n",
      "Epoch 7/100\n",
      "3535/3535 [==============================] - 1s 208us/sample - loss: 0.6012 - val_loss: 0.6434\n",
      "Epoch 8/100\n",
      "3535/3535 [==============================] - 1s 209us/sample - loss: 0.5980 - val_loss: 0.6418\n",
      "Epoch 9/100\n",
      "3535/3535 [==============================] - 1s 205us/sample - loss: 0.5951 - val_loss: 0.6423\n",
      "Epoch 10/100\n",
      "3535/3535 [==============================] - 1s 205us/sample - loss: 0.5902 - val_loss: 0.6423\n",
      "Epoch 11/100\n",
      "3535/3535 [==============================] - 1s 204us/sample - loss: 0.5879 - val_loss: 0.6463\n",
      "Epoch 12/100\n",
      "3535/3535 [==============================] - 1s 208us/sample - loss: 0.5837 - val_loss: 0.6450\n",
      "Epoch 13/100\n",
      "3535/3535 [==============================] - 1s 206us/sample - loss: 0.5803 - val_loss: 0.6449\n",
      "Epoch 14/100\n",
      "3535/3535 [==============================] - 1s 214us/sample - loss: 0.5762 - val_loss: 0.6459\n",
      "Epoch 15/100\n",
      "3535/3535 [==============================] - 1s 203us/sample - loss: 0.5734 - val_loss: 0.6438\n",
      "Train on 577 samples, validate on 149 samples\n",
      "Epoch 1/100\n",
      "577/577 [==============================] - 1s 2ms/sample - loss: 0.5194 - val_loss: 0.4804\n",
      "Epoch 2/100\n",
      "577/577 [==============================] - 0s 266us/sample - loss: 0.4591 - val_loss: 0.4526\n",
      "Epoch 3/100\n",
      "577/577 [==============================] - 0s 368us/sample - loss: 0.4334 - val_loss: 0.4389\n",
      "Epoch 4/100\n",
      "577/577 [==============================] - 0s 271us/sample - loss: 0.4198 - val_loss: 0.4345\n",
      "Epoch 5/100\n",
      "577/577 [==============================] - 0s 271us/sample - loss: 0.4103 - val_loss: 0.4266\n",
      "Epoch 6/100\n",
      "577/577 [==============================] - 0s 296us/sample - loss: 0.4034 - val_loss: 0.4234\n",
      "Epoch 7/100\n",
      "577/577 [==============================] - 0s 277us/sample - loss: 0.3975 - val_loss: 0.4199\n",
      "Epoch 8/100\n",
      "577/577 [==============================] - 0s 268us/sample - loss: 0.3916 - val_loss: 0.4192\n",
      "Epoch 9/100\n",
      "577/577 [==============================] - 0s 306us/sample - loss: 0.3841 - val_loss: 0.4162\n",
      "Epoch 10/100\n",
      "577/577 [==============================] - 0s 271us/sample - loss: 0.3830 - val_loss: 0.4142\n",
      "Epoch 11/100\n",
      "577/577 [==============================] - 0s 289us/sample - loss: 0.3779 - val_loss: 0.4176\n",
      "Epoch 12/100\n",
      "577/577 [==============================] - 0s 301us/sample - loss: 0.3735 - val_loss: 0.4139\n",
      "Epoch 13/100\n",
      "577/577 [==============================] - 0s 278us/sample - loss: 0.3699 - val_loss: 0.4124\n",
      "Epoch 14/100\n",
      "577/577 [==============================] - 0s 273us/sample - loss: 0.3685 - val_loss: 0.4136\n",
      "Epoch 15/100\n",
      "577/577 [==============================] - 0s 302us/sample - loss: 0.3641 - val_loss: 0.4135\n",
      "Epoch 16/100\n",
      "577/577 [==============================] - 0s 275us/sample - loss: 0.3618 - val_loss: 0.4113\n",
      "Epoch 17/100\n",
      "577/577 [==============================] - 0s 268us/sample - loss: 0.3568 - val_loss: 0.4126\n",
      "Epoch 18/100\n",
      "577/577 [==============================] - 0s 273us/sample - loss: 0.3545 - val_loss: 0.4110\n",
      "Epoch 19/100\n",
      "577/577 [==============================] - 0s 313us/sample - loss: 0.3513 - val_loss: 0.4125\n",
      "Epoch 20/100\n",
      "577/577 [==============================] - 0s 275us/sample - loss: 0.3505 - val_loss: 0.4115\n",
      "Epoch 21/100\n",
      "577/577 [==============================] - 0s 270us/sample - loss: 0.3466 - val_loss: 0.4151\n",
      "Epoch 22/100\n",
      "577/577 [==============================] - 0s 287us/sample - loss: 0.3469 - val_loss: 0.4118\n",
      "Epoch 23/100\n",
      "577/577 [==============================] - 0s 304us/sample - loss: 0.3422 - val_loss: 0.4107\n",
      "Epoch 24/100\n",
      "577/577 [==============================] - 0s 304us/sample - loss: 0.3418 - val_loss: 0.4110\n",
      "Epoch 25/100\n",
      "577/577 [==============================] - 0s 296us/sample - loss: 0.3360 - val_loss: 0.4111\n",
      "Epoch 26/100\n",
      "577/577 [==============================] - 0s 271us/sample - loss: 0.3347 - val_loss: 0.4127\n",
      "Epoch 27/100\n",
      "577/577 [==============================] - 0s 268us/sample - loss: 0.3327 - val_loss: 0.4143\n",
      "Epoch 28/100\n",
      "577/577 [==============================] - 0s 301us/sample - loss: 0.3322 - val_loss: 0.4126\n",
      "Epoch 29/100\n",
      "577/577 [==============================] - 0s 273us/sample - loss: 0.3267 - val_loss: 0.4127\n",
      "Epoch 30/100\n",
      "577/577 [==============================] - 0s 275us/sample - loss: 0.3257 - val_loss: 0.4148\n",
      "Epoch 31/100\n",
      "577/577 [==============================] - 0s 277us/sample - loss: 0.3258 - val_loss: 0.4116\n",
      "Epoch 32/100\n",
      "577/577 [==============================] - 0s 277us/sample - loss: 0.3245 - val_loss: 0.4109\n",
      "Epoch 33/100\n",
      "577/577 [==============================] - 0s 277us/sample - loss: 0.3193 - val_loss: 0.4136\n",
      "Train on 3515 samples, validate on 900 samples\n",
      "Epoch 1/100\n",
      "3515/3515 [==============================] - 1s 400us/sample - loss: 0.6854 - val_loss: 0.6387\n",
      "Epoch 2/100\n",
      "3515/3515 [==============================] - 1s 214us/sample - loss: 0.6399 - val_loss: 0.6330\n",
      "Epoch 3/100\n",
      "3515/3515 [==============================] - 1s 208us/sample - loss: 0.6300 - val_loss: 0.6303\n",
      "Epoch 4/100\n",
      "3515/3515 [==============================] - 1s 216us/sample - loss: 0.6232 - val_loss: 0.6280\n",
      "Epoch 5/100\n",
      "3515/3515 [==============================] - 1s 212us/sample - loss: 0.6188 - val_loss: 0.6232\n",
      "Epoch 6/100\n",
      "3515/3515 [==============================] - 1s 211us/sample - loss: 0.6120 - val_loss: 0.6203\n",
      "Epoch 7/100\n",
      "3515/3515 [==============================] - 1s 232us/sample - loss: 0.6077 - val_loss: 0.6229\n",
      "Epoch 8/100\n",
      "3515/3515 [==============================] - 1s 221us/sample - loss: 0.6044 - val_loss: 0.6238\n",
      "Epoch 9/100\n",
      "3515/3515 [==============================] - 1s 248us/sample - loss: 0.6006 - val_loss: 0.6203\n",
      "Epoch 10/100\n",
      "3515/3515 [==============================] - 1s 228us/sample - loss: 0.5963 - val_loss: 0.6221\n",
      "Epoch 11/100\n",
      "3515/3515 [==============================] - 1s 236us/sample - loss: 0.5942 - val_loss: 0.6247\n",
      "Epoch 12/100\n",
      "3515/3515 [==============================] - 1s 222us/sample - loss: 0.5894 - val_loss: 0.6220\n",
      "Epoch 13/100\n",
      "3515/3515 [==============================] - 1s 218us/sample - loss: 0.5864 - val_loss: 0.6185\n",
      "Epoch 14/100\n",
      "3515/3515 [==============================] - 1s 219us/sample - loss: 0.5832 - val_loss: 0.6241\n",
      "Epoch 15/100\n",
      "3515/3515 [==============================] - 1s 210us/sample - loss: 0.5798 - val_loss: 0.6188\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3515/3515 [==============================] - 1s 216us/sample - loss: 0.5777 - val_loss: 0.6217\n",
      "Epoch 17/100\n",
      "3515/3515 [==============================] - 1s 222us/sample - loss: 0.5742 - val_loss: 0.6224\n",
      "Epoch 18/100\n",
      "3515/3515 [==============================] - 1s 209us/sample - loss: 0.5712 - val_loss: 0.6217\n",
      "Epoch 19/100\n",
      "3515/3515 [==============================] - 1s 211us/sample - loss: 0.5674 - val_loss: 0.6250\n",
      "Epoch 20/100\n",
      "3515/3515 [==============================] - 1s 222us/sample - loss: 0.5652 - val_loss: 0.6226\n",
      "Epoch 21/100\n",
      "3515/3515 [==============================] - 1s 220us/sample - loss: 0.5620 - val_loss: 0.6208\n",
      "Epoch 22/100\n",
      "3515/3515 [==============================] - 1s 228us/sample - loss: 0.5587 - val_loss: 0.6257\n",
      "Epoch 23/100\n",
      "3515/3515 [==============================] - 1s 235us/sample - loss: 0.5578 - val_loss: 0.6271\n",
      "Train on 599 samples, validate on 127 samples\n",
      "Epoch 1/100\n",
      "599/599 [==============================] - 1s 2ms/sample - loss: 0.5322 - val_loss: 0.4658\n",
      "Epoch 2/100\n",
      "599/599 [==============================] - 0s 263us/sample - loss: 0.4499 - val_loss: 0.4362\n",
      "Epoch 3/100\n",
      "599/599 [==============================] - 0s 275us/sample - loss: 0.4268 - val_loss: 0.4235\n",
      "Epoch 4/100\n",
      "599/599 [==============================] - 0s 270us/sample - loss: 0.4153 - val_loss: 0.4237\n",
      "Epoch 5/100\n",
      "599/599 [==============================] - 0s 276us/sample - loss: 0.4050 - val_loss: 0.4216\n",
      "Epoch 6/100\n",
      "599/599 [==============================] - 0s 286us/sample - loss: 0.4023 - val_loss: 0.4177\n",
      "Epoch 7/100\n",
      "599/599 [==============================] - 0s 278us/sample - loss: 0.3947 - val_loss: 0.4167\n",
      "Epoch 8/100\n",
      "599/599 [==============================] - 0s 290us/sample - loss: 0.3905 - val_loss: 0.4154\n",
      "Epoch 9/100\n",
      "599/599 [==============================] - 0s 278us/sample - loss: 0.3849 - val_loss: 0.4208\n",
      "Epoch 10/100\n",
      "599/599 [==============================] - 0s 261us/sample - loss: 0.3820 - val_loss: 0.4101\n",
      "Epoch 11/100\n",
      "599/599 [==============================] - 0s 248us/sample - loss: 0.3782 - val_loss: 0.4177\n",
      "Epoch 12/100\n",
      "599/599 [==============================] - 0s 246us/sample - loss: 0.3759 - val_loss: 0.4130\n",
      "Epoch 13/100\n",
      "599/599 [==============================] - 0s 255us/sample - loss: 0.3721 - val_loss: 0.4179\n",
      "Epoch 14/100\n",
      "599/599 [==============================] - 0s 256us/sample - loss: 0.3681 - val_loss: 0.4132\n",
      "Epoch 15/100\n",
      "599/599 [==============================] - 0s 313us/sample - loss: 0.3642 - val_loss: 0.4158\n",
      "Epoch 16/100\n",
      "599/599 [==============================] - 0s 288us/sample - loss: 0.3610 - val_loss: 0.4084\n",
      "Epoch 17/100\n",
      "599/599 [==============================] - 0s 291us/sample - loss: 0.3583 - val_loss: 0.4162\n",
      "Epoch 18/100\n",
      "599/599 [==============================] - 0s 255us/sample - loss: 0.3547 - val_loss: 0.4133\n",
      "Epoch 19/100\n",
      "599/599 [==============================] - 0s 275us/sample - loss: 0.3524 - val_loss: 0.4150\n",
      "Epoch 20/100\n",
      "599/599 [==============================] - 0s 290us/sample - loss: 0.3502 - val_loss: 0.4120\n",
      "Epoch 21/100\n",
      "599/599 [==============================] - 0s 298us/sample - loss: 0.3475 - val_loss: 0.4118\n",
      "Epoch 22/100\n",
      "599/599 [==============================] - 0s 286us/sample - loss: 0.3453 - val_loss: 0.4159\n",
      "Epoch 23/100\n",
      "599/599 [==============================] - 0s 321us/sample - loss: 0.3431 - val_loss: 0.4178\n",
      "Epoch 24/100\n",
      "599/599 [==============================] - 0s 255us/sample - loss: 0.3414 - val_loss: 0.4136\n",
      "Epoch 25/100\n",
      "599/599 [==============================] - 0s 263us/sample - loss: 0.3441 - val_loss: 0.4139\n",
      "Epoch 26/100\n",
      "599/599 [==============================] - 0s 281us/sample - loss: 0.3363 - val_loss: 0.4194\n",
      "Train on 3537 samples, validate on 878 samples\n",
      "Epoch 1/100\n",
      "3537/3537 [==============================] - 2s 432us/sample - loss: 0.6739 - val_loss: 0.6568\n",
      "Epoch 2/100\n",
      "3537/3537 [==============================] - 1s 202us/sample - loss: 0.6319 - val_loss: 0.6513\n",
      "Epoch 3/100\n",
      "3537/3537 [==============================] - 1s 201us/sample - loss: 0.6217 - val_loss: 0.6511\n",
      "Epoch 4/100\n",
      "3537/3537 [==============================] - 1s 200us/sample - loss: 0.6163 - val_loss: 0.6559\n",
      "Epoch 5/100\n",
      "3537/3537 [==============================] - 1s 204us/sample - loss: 0.6115 - val_loss: 0.6476\n",
      "Epoch 6/100\n",
      "3537/3537 [==============================] - 1s 204us/sample - loss: 0.6055 - val_loss: 0.6514\n",
      "Epoch 7/100\n",
      "3537/3537 [==============================] - 1s 200us/sample - loss: 0.6018 - val_loss: 0.6505\n",
      "Epoch 8/100\n",
      "3537/3537 [==============================] - 1s 200us/sample - loss: 0.5971 - val_loss: 0.6520\n",
      "Epoch 9/100\n",
      "3537/3537 [==============================] - 1s 202us/sample - loss: 0.5942 - val_loss: 0.6513\n",
      "Epoch 10/100\n",
      "3537/3537 [==============================] - 1s 203us/sample - loss: 0.5886 - val_loss: 0.6504\n",
      "Epoch 11/100\n",
      "3537/3537 [==============================] - 1s 202us/sample - loss: 0.5867 - val_loss: 0.6500\n",
      "Epoch 12/100\n",
      "3537/3537 [==============================] - 1s 203us/sample - loss: 0.5830 - val_loss: 0.6484\n",
      "Epoch 13/100\n",
      "3537/3537 [==============================] - 1s 205us/sample - loss: 0.5781 - val_loss: 0.6514\n",
      "Epoch 14/100\n",
      "3537/3537 [==============================] - 1s 200us/sample - loss: 0.5763 - val_loss: 0.6543\n",
      "Epoch 15/100\n",
      "3537/3537 [==============================] - 1s 208us/sample - loss: 0.5725 - val_loss: 0.6529\n",
      "Train on 578 samples, validate on 148 samples\n",
      "Epoch 1/100\n",
      "578/578 [==============================] - 1s 2ms/sample - loss: 0.5434 - val_loss: 0.4791\n",
      "Epoch 2/100\n",
      "578/578 [==============================] - 0s 254us/sample - loss: 0.4586 - val_loss: 0.4456\n",
      "Epoch 3/100\n",
      "578/578 [==============================] - 0s 271us/sample - loss: 0.4339 - val_loss: 0.4259\n",
      "Epoch 4/100\n",
      "578/578 [==============================] - 0s 267us/sample - loss: 0.4193 - val_loss: 0.4190\n",
      "Epoch 5/100\n",
      "578/578 [==============================] - 0s 267us/sample - loss: 0.4108 - val_loss: 0.4106\n",
      "Epoch 6/100\n",
      "578/578 [==============================] - 0s 273us/sample - loss: 0.4021 - val_loss: 0.4097\n",
      "Epoch 7/100\n",
      "578/578 [==============================] - 0s 274us/sample - loss: 0.3969 - val_loss: 0.4062\n",
      "Epoch 8/100\n",
      "578/578 [==============================] - 0s 276us/sample - loss: 0.3913 - val_loss: 0.4129\n",
      "Epoch 9/100\n",
      "578/578 [==============================] - 0s 276us/sample - loss: 0.3878 - val_loss: 0.4075\n",
      "Epoch 10/100\n",
      "578/578 [==============================] - 0s 261us/sample - loss: 0.3828 - val_loss: 0.4084\n",
      "Epoch 11/100\n",
      "578/578 [==============================] - 0s 267us/sample - loss: 0.3791 - val_loss: 0.4084\n",
      "Epoch 12/100\n",
      "578/578 [==============================] - 0s 266us/sample - loss: 0.3751 - val_loss: 0.4046\n",
      "Epoch 13/100\n",
      "578/578 [==============================] - 0s 266us/sample - loss: 0.3710 - val_loss: 0.4028\n",
      "Epoch 14/100\n",
      "578/578 [==============================] - 0s 267us/sample - loss: 0.3689 - val_loss: 0.4037\n",
      "Epoch 15/100\n",
      "578/578 [==============================] - 0s 274us/sample - loss: 0.3637 - val_loss: 0.4063\n",
      "Epoch 16/100\n",
      "578/578 [==============================] - 0s 264us/sample - loss: 0.3654 - val_loss: 0.4068\n",
      "Epoch 17/100\n",
      "578/578 [==============================] - 0s 264us/sample - loss: 0.3586 - val_loss: 0.4071\n",
      "Epoch 18/100\n",
      "578/578 [==============================] - 0s 255us/sample - loss: 0.3579 - val_loss: 0.4044\n",
      "Epoch 19/100\n",
      "578/578 [==============================] - 0s 259us/sample - loss: 0.3540 - val_loss: 0.4048\n",
      "Epoch 20/100\n",
      "578/578 [==============================] - 0s 271us/sample - loss: 0.3501 - val_loss: 0.4030\n",
      "Epoch 21/100\n",
      "578/578 [==============================] - 0s 271us/sample - loss: 0.3476 - val_loss: 0.4054\n",
      "Epoch 22/100\n",
      "578/578 [==============================] - 0s 264us/sample - loss: 0.3450 - val_loss: 0.4081\n",
      "Epoch 23/100\n",
      "578/578 [==============================] - 0s 271us/sample - loss: 0.3422 - val_loss: 0.4034\n"
     ]
    }
   ],
   "source": [
    "metrics = full_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gene': {'overall': {'mae': 0.7299490896746337,\n",
       "   'rmse': 1.2918968704150449,\n",
       "   'ndcg': 0.44835543717483367},\n",
       "  'annual': {'mae': array([0.41098335, 0.57326106, 0.75468637, 0.88329084, 1.02752384]),\n",
       "   'rmse': array([0.74612466, 0.97067574, 1.33166402, 1.48635163, 1.66849718]),\n",
       "   'ndcg': array([0.46505046, 0.36096419, 0.14908492, 0.19261638, 0.15743147])}},\n",
       " 'transplant': {'overall': {'mae': 0.7718043551135649,\n",
       "   'rmse': 1.2752554128409044,\n",
       "   'ndcg': 0.48122490028670706},\n",
       "  'annual': {'mae': array([0.75218725, 0.77410503, 0.74279975, 0.7759474 , 0.81398235]),\n",
       "   'rmse': array([1.30078556, 1.29846621, 1.21739863, 1.22831554, 1.31962679]),\n",
       "   'ndcg': array([0.09773368, 0.07247887, 0.02053076, 0.10604713, 0.11611737])}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gene': {'overall': {'mae': 0.7297824076242991,\n",
       "   'rmse': 1.288492394560198,\n",
       "   'ndcg': 0.450425276583966,\n",
       "   'mape': 4.379720797710389,\n",
       "   'r2': 0.24096271379741033,\n",
       "   'pearson': 0.5239841606169792,\n",
       "   'acc': 0.33765443023983865},\n",
       "  'annual': {'mae': array([0.41629491, 0.57294854, 0.75242516, 0.88069069, 1.02655274]),\n",
       "   'rmse': array([0.75623629, 0.96455199, 1.31755807, 1.48652634, 1.66621578]),\n",
       "   'ndcg': array([0.42948659, 0.36199947, 0.15691518, 0.21310819, 0.14353297]),\n",
       "   'mape': array([3.27338697, 2.92294838, 3.34444352, 6.13713268, 6.22069244]),\n",
       "   'r2': array([0.42536017, 0.28595323, 0.18519127, 0.05494907, 0.02053747]),\n",
       "   'pearson': array([0.66756681, 0.55964269, 0.47305132, 0.33346943, 0.2686703 ]),\n",
       "   'acc': array([0.57891309, 0.20543948, 0.25955221, 0.3371119 , 0.30725548])}},\n",
       " 'transplant': {'overall': {'mae': 0.7741190799377897,\n",
       "   'rmse': 1.2768263814311376,\n",
       "   'ndcg': 0.521502225186101,\n",
       "   'mape': 3.5752431968110856,\n",
       "   'r2': 0.4178778432693182,\n",
       "   'pearson': 0.6561407872776719,\n",
       "   'acc': 0.3288899995545448},\n",
       "  'annual': {'mae': array([0.75810398, 0.77755318, 0.74153353, 0.77196721, 0.8214375 ]),\n",
       "   'rmse': array([1.30168783, 1.30867047, 1.21911946, 1.21964258, 1.32129062]),\n",
       "   'ndcg': array([0.03279925, 0.06055282, 0.02106838, 0.08558031, 0.14537103]),\n",
       "   'mape': array([3.172992  , 3.58421186, 3.25485806, 4.72289323, 3.14126083]),\n",
       "   'r2': array([0.42892717, 0.4091857 , 0.40697638, 0.44880369, 0.40009249]),\n",
       "   'pearson': array([0.66510822, 0.6508333 , 0.64805261, 0.67886051, 0.64439019]),\n",
       "   'acc': array([0.34565412, 0.33086168, 0.35500877, 0.31784123, 0.2950842 ])}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
