{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "## 仅供交叉验证 Encoder-Decoder with LSTM cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from utils import *\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "n_input = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the gene_editing array: (2643, 17, 10)\n",
      "Shape of the transplant array: (5141, 17, 10)\n"
     ]
    }
   ],
   "source": [
    "# gene_arr_path = r'../output/gene_editing/es_with_decay.array'\n",
    "# transplant_arr_path = r'../output/transplant/es_with_decay.array'\n",
    "\n",
    "# gene_arr = pickle.load(open(gene_arr_path, mode='rb'))\n",
    "# transplant_arr = pickle.load(open(transplant_arr_path, mode='rb'))\n",
    "\n",
    "# print('Shape of the gene_editing array:',gene_arr.shape)\n",
    "# print('Shape of the transplant array:',transplant_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 截断数据\n",
    "2019年为无效数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the gene_editing array: (2643, 16, 10)\n",
      "Shape of the transplant array: (5141, 16, 10)\n"
     ]
    }
   ],
   "source": [
    "# gene_arr = gene_arr[:, :-1, :]\n",
    "# transplant_arr = transplant_arr[:, :-1, :]\n",
    "\n",
    "# print('Shape of the gene_editing array:',gene_arr.shape)\n",
    "# print('Shape of the transplant array:',transplant_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 规范数据并获取5折交叉检验所需的训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler, data = scale_data(transplant_arr, 'standard')\n",
    "\n",
    "# # 用预测第二年的类别变量作为分成Kfold的依据，不支持浮点数\n",
    "# X, y, y_cat = data[:, :n_input, :], data[:, n_input:, -2],transplant_arr[:, n_input, -1]\n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return keras.backend.sqrt(keras.backend.mean(keras.backend.square(y_pred - y_true), axis=-1)) \n",
    "\n",
    "# def build_encoder_decoder_model(lstm_units, dense_units, lr=1e-4):\n",
    "#     model = keras.models.Sequential()\n",
    "#     model.add(LSTM(lstm_units, activation='tanh', input_shape=(11, 10), return_sequences=True))\n",
    "#     model.add(LSTM(lstm_units, activation='tanh'))\n",
    "#     model.add(RepeatVector(5))\n",
    "#     model.add(LSTM(lstm_units, activation='tanh', return_sequences=True))\n",
    "#     model.add(LSTM(lstm_units, activation='tanh', return_sequences=True))\n",
    "#     model.add(TimeDistributed(Dense(dense_units, activation='relu')))\n",
    "#     model.add(TimeDistributed(Dense(1)))\n",
    "    \n",
    "#     optimizer=keras.optimizers.Adam(learning_rate=lr)\n",
    "#     model.compile(loss=root_mean_squared_error, optimizer=optimizer)\n",
    "#     return model\n",
    "\n",
    "def build_encoder_decoder_model(n_layers=2, n_units=256, lr=1e-4):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(LSTM(n_units, activation='tanh', input_shape=(11, 10), return_sequences=True))\n",
    "    if n_layers > 2:\n",
    "        for i in range(n_layers):\n",
    "            model.add(LSTM(n_units, activation='tanh', return_sequences=True))\n",
    "    model.add(LSTM(lstm_units, activation='tanh'))\n",
    "    model.add(RepeatVector(5))\n",
    "#     model.add(LSTM(lstm_units, activation='tanh', return_sequences=True))\n",
    "#     model.add(LSTM(lstm_units, activation='tanh', return_sequences=True))\n",
    "    for i in range(n_layers):\n",
    "        model.add(LSTM(n_units, activation='tanh', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_units, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    \n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(loss=root_mean_squared_error, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进行训练和评估\n",
    "使用EarlyStopping和Checkpoint做训练停止方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, y, y_cat, kfold, scaler, n_layers, n_units):\n",
    "    overall_metrics = {\n",
    "        'mae':[],\n",
    "        'rmse':[],\n",
    "        'ndcg':[],\n",
    "        'mape':[],\n",
    "        'r2':[],\n",
    "        'pearson':[],\n",
    "        'acc':[]\n",
    "    }\n",
    "\n",
    "    annual_metrics = {\n",
    "        'mae':[],\n",
    "        'rmse':[],\n",
    "        'ndcg':[],\n",
    "        'mape':[],\n",
    "        'r2':[],\n",
    "        'pearson':[],\n",
    "        'acc':[]\n",
    "    }\n",
    "\n",
    "    tests = []\n",
    "    preds = []\n",
    "\n",
    "    for train, test in kfold.split(X, y_cat):\n",
    "        model = build_encoder_decoder_model(n_layers, n_units, 1e-4)\n",
    "        history = model.fit(X[train], y[train], epochs=100, batch_size=16, verbose=1, validation_data=(X[test], y[test]),\n",
    "                           callbacks=[\n",
    "                               EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto', restore_best_weights=True)\n",
    "                           ])\n",
    "\n",
    "        y_test = y[test]\n",
    "        y_pred = model.predict(X[test]).reshape(y[test].shape)\n",
    "\n",
    "        tests.append(y_test)\n",
    "        preds.append(y_pred)\n",
    "\n",
    "        metrics = ['mae', 'rmse','ndcg', 'mape', 'r2', 'pearson', 'acc']\n",
    "        for m in metrics:\n",
    "            overall, annual = eval_model(m, y_test, y_pred, scaler)\n",
    "            overall_metrics[m].append(overall)\n",
    "            annual_metrics[m].append(annual)\n",
    "            \n",
    "    return overall_metrics, annual_metrics, tests, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline(n_layers, n_units):\n",
    "    gene_arr_path = r'../output/gene_editing/es_with_decay.array'\n",
    "    transplant_arr_path = r'../output/transplant/es_with_decay.array'\n",
    "\n",
    "    gene_arr = pickle.load(open(gene_arr_path, mode='rb'))\n",
    "    transplant_arr = pickle.load(open(transplant_arr_path, mode='rb'))\n",
    "    \n",
    "    gene_arr = gene_arr[:, :-1, :]\n",
    "    transplant_arr = transplant_arr[:, :-1, :]\n",
    "\n",
    "    print('Shape of the gene_editing array:',gene_arr.shape)\n",
    "    print('Shape of the transplant array:',transplant_arr.shape)\n",
    "    \n",
    "    metrics = {\n",
    "        'gene':{\n",
    "            'overall':{},\n",
    "            'annual':{}\n",
    "        },\n",
    "        'transplant':{\n",
    "            'overall':{},\n",
    "            'annual':{}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for name, dataset in zip(['gene', 'transplant'], [gene_arr, transplant_arr]):\n",
    "        scaler, data = scale_data(dataset, 'standard')\n",
    "\n",
    "        # 用预测第二年的类别变量作为分成Kfold的依据，不支持浮点数\n",
    "        X, y, y_cat = data[:, :n_input, :], data[:, n_input:, -2], dataset[:, n_input, -1]\n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        overall_metrics, annual_metrics, tests, preds = cross_validation(X, y, y_cat, kfold, scaler, n_layers, n_units)\n",
    "        pickle.dump(tests, open('rnn_tests_{}.list'.format(name), 'wb'))\n",
    "        pickle.dump(preds, open('rnn_preds_{}.list'.format(name), 'wb'))\n",
    "\n",
    "        for metric, value in overall_metrics.items():\n",
    "            metrics[name]['overall'][metric] = np.mean(value)\n",
    "        \n",
    "        for metric, value in annual_metrics.items():\n",
    "            metrics[name]['annual'][metric] = np.mean(np.array(value), axis=0)\n",
    "    \n",
    "    pickle.dump(metrics, open('rnn_metrics.dict', 'wb'))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "para_tuning_metrics = {}\n",
    "for n_layers in [1, 2, 3, 4, 5]:\n",
    "    for n_units in [32, 64, 128, 256, 512]:\n",
    "        print(n_layers, n_units)\n",
    "        para_tuning_metrics[(n_layers, n_units)] = full_pipeline(n_layers, n_units)\n",
    "        print(para_tuning_metrics[(n_layers, n_units)])\n",
    "#         print('gene_mae', para_tuning_metrics[(n_layers, n_units)]['gene']['overall']['mae'])\n",
    "#         print('gene_rmse', para_tuning_metrics[(n_layers, n_units)]['gene']['overall']['rmse'])\n",
    "#         print('transplant_mae', para_tuning_metrics[(n_layers, n_units)]['transplant']['overall']['mae'])\n",
    "#         print('transplant_rmse', para_tuning_metrics[(n_layers, n_units)]['transplant']['overall']['rmse'])\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = full_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the gene_editing array: (2643, 16, 10)\n",
      "Shape of the transplant array: (5141, 16, 10)\n",
      "Train on 2112 samples, validate on 531 samples\n",
      "Epoch 1/100\n",
      "2112/2112 [==============================] - 6s 3ms/sample - loss: 0.9963 - val_loss: 0.9591\n",
      "Epoch 2/100\n",
      "2112/2112 [==============================] - 1s 462us/sample - loss: 0.9647 - val_loss: 0.9391\n",
      "Epoch 3/100\n",
      "2112/2112 [==============================] - 2s 716us/sample - loss: 0.9444 - val_loss: 0.9160\n",
      "Epoch 4/100\n",
      "2112/2112 [==============================] - 2s 734us/sample - loss: 0.9242 - val_loss: 0.9097\n",
      "Epoch 5/100\n",
      "2112/2112 [==============================] - 2s 734us/sample - loss: 0.9152 - val_loss: 0.9010\n",
      "Epoch 6/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.9078 - val_loss: 0.8973\n",
      "Epoch 7/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.9047 - val_loss: 0.9043\n",
      "Epoch 8/100\n",
      "2112/2112 [==============================] - 2s 982us/sample - loss: 0.9022 - val_loss: 0.8973\n",
      "Epoch 9/100\n",
      "2112/2112 [==============================] - 2s 844us/sample - loss: 0.9012 - val_loss: 0.8931\n",
      "Epoch 10/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8991 - val_loss: 0.8902\n",
      "Epoch 11/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.9006 - val_loss: 0.8890\n",
      "Epoch 12/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8977 - val_loss: 0.8892\n",
      "Epoch 13/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8969 - val_loss: 0.8908\n",
      "Epoch 14/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8975 - val_loss: 0.8863\n",
      "Epoch 15/100\n",
      "2112/2112 [==============================] - 2s 1ms/sample - loss: 0.8963 - val_loss: 0.8898\n",
      "Epoch 16/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8972 - val_loss: 0.8864\n",
      "Epoch 17/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8968 - val_loss: 0.8882\n",
      "Epoch 18/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8957 - val_loss: 0.8855\n",
      "Epoch 19/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8958 - val_loss: 0.8862\n",
      "Epoch 20/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8957 - val_loss: 0.8868\n",
      "Epoch 21/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8947 - val_loss: 0.8855\n",
      "Epoch 22/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8951 - val_loss: 0.8905\n",
      "Epoch 23/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8946 - val_loss: 0.8850\n",
      "Epoch 24/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8932 - val_loss: 0.8862\n",
      "Epoch 25/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8934 - val_loss: 0.8837\n",
      "Epoch 26/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8935 - val_loss: 0.8845\n",
      "Epoch 27/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8934 - val_loss: 0.8864\n",
      "Epoch 28/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8940 - val_loss: 0.8839\n",
      "Epoch 29/100\n",
      "2112/2112 [==============================] - 2s 762us/sample - loss: 0.8926 - val_loss: 0.8854\n",
      "Epoch 30/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8923 - val_loss: 0.8844\n",
      "Epoch 31/100\n",
      "2112/2112 [==============================] - 2s 1ms/sample - loss: 0.8917 - val_loss: 0.8839\n",
      "Epoch 32/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8919 - val_loss: 0.8864\n",
      "Epoch 33/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8918 - val_loss: 0.8839\n",
      "Epoch 34/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8925 - val_loss: 0.8825\n",
      "Epoch 35/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8917 - val_loss: 0.8878\n",
      "Epoch 36/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8902 - val_loss: 0.8841\n",
      "Epoch 37/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8901 - val_loss: 0.8838\n",
      "Epoch 38/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8894 - val_loss: 0.8864\n",
      "Epoch 39/100\n",
      "2112/2112 [==============================] - 2s 1ms/sample - loss: 0.8904 - val_loss: 0.8848\n",
      "Epoch 40/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8902 - val_loss: 0.8887\n",
      "Epoch 41/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8901 - val_loss: 0.8836\n",
      "Epoch 42/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8898 - val_loss: 0.8869\n",
      "Epoch 43/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8892 - val_loss: 0.8883\n",
      "Epoch 44/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8890 - val_loss: 0.8821\n",
      "Epoch 45/100\n",
      "2112/2112 [==============================] - 2s 1ms/sample - loss: 0.8897 - val_loss: 0.8833\n",
      "Epoch 46/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8878 - val_loss: 0.8837\n",
      "Epoch 47/100\n",
      "2112/2112 [==============================] - 2s 907us/sample - loss: 0.8880 - val_loss: 0.8848\n",
      "Epoch 48/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8894 - val_loss: 0.8832\n",
      "Epoch 49/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8855 - val_loss: 0.8870\n",
      "Epoch 50/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8872 - val_loss: 0.8833\n",
      "Epoch 51/100\n",
      "2112/2112 [==============================] - 2s 1ms/sample - loss: 0.8881 - val_loss: 0.8885\n",
      "Epoch 52/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8867 - val_loss: 0.8832\n",
      "Epoch 53/100\n",
      "2112/2112 [==============================] - 3s 2ms/sample - loss: 0.8854 - val_loss: 0.8846\n",
      "Epoch 54/100\n",
      "2112/2112 [==============================] - 3s 1ms/sample - loss: 0.8860 - val_loss: 0.8836\n",
      "Train on 2113 samples, validate on 530 samples\n",
      "Epoch 1/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.9966 - val_loss: 1.0122\n",
      "Epoch 2/100\n",
      "2113/2113 [==============================] - 1s 343us/sample - loss: 0.9611 - val_loss: 0.9915\n",
      "Epoch 3/100\n",
      "2113/2113 [==============================] - 1s 694us/sample - loss: 0.9426 - val_loss: 0.9846\n",
      "Epoch 4/100\n",
      "2113/2113 [==============================] - 2s 1ms/sample - loss: 0.9240 - val_loss: 0.9475\n",
      "Epoch 5/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.9108 - val_loss: 0.9358\n",
      "Epoch 6/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.9018 - val_loss: 0.9341\n",
      "Epoch 7/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8974 - val_loss: 0.9291\n",
      "Epoch 8/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8957 - val_loss: 0.9334\n",
      "Epoch 9/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8947 - val_loss: 0.9262\n",
      "Epoch 10/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8934 - val_loss: 0.9199\n",
      "Epoch 11/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8913 - val_loss: 0.9236\n",
      "Epoch 12/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8888 - val_loss: 0.9197\n",
      "Epoch 13/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8891 - val_loss: 0.9185\n",
      "Epoch 14/100\n",
      "2113/2113 [==============================] - 3s 1ms/sample - loss: 0.8895 - val_loss: 0.9199\n",
      "Epoch 15/100\n",
      "2113/2113 [==============================] - 2s 937us/sample - loss: 0.8901 - val_loss: 0.9188\n",
      "Epoch 16/100\n",
      "2113/2113 [==============================] - 3s 1ms/sample - loss: 0.8886 - val_loss: 0.9181\n",
      "Epoch 17/100\n",
      "2113/2113 [==============================] - 3s 1ms/sample - loss: 0.8889 - val_loss: 0.9192\n",
      "Epoch 18/100\n",
      "2113/2113 [==============================] - 3s 2ms/sample - loss: 0.8874 - val_loss: 0.9160\n",
      "Epoch 19/100\n",
      "2113/2113 [==============================] - 3s 1ms/sample - loss: 0.8874 - val_loss: 0.9240\n",
      "Epoch 20/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8867 - val_loss: 0.9180\n",
      "Epoch 21/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8855 - val_loss: 0.9173\n",
      "Epoch 22/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8864 - val_loss: 0.9178\n",
      "Epoch 23/100\n",
      "2113/2113 [==============================] - 3s 2ms/sample - loss: 0.8857 - val_loss: 0.9171\n",
      "Epoch 24/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8858 - val_loss: 0.9155\n",
      "Epoch 25/100\n",
      "2113/2113 [==============================] - 2s 803us/sample - loss: 0.8862 - val_loss: 0.9155\n",
      "Epoch 26/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8855 - val_loss: 0.9190\n",
      "Epoch 27/100\n",
      "2113/2113 [==============================] - 3s 1ms/sample - loss: 0.8845 - val_loss: 0.9169\n",
      "Epoch 28/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8841 - val_loss: 0.9155\n",
      "Epoch 29/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8837 - val_loss: 0.9170\n",
      "Epoch 30/100\n",
      "2113/2113 [==============================] - 3s 2ms/sample - loss: 0.8840 - val_loss: 0.9194\n",
      "Epoch 31/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8834 - val_loss: 0.9166\n",
      "Epoch 32/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8831 - val_loss: 0.9176\n",
      "Epoch 33/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8842 - val_loss: 0.9160\n",
      "Epoch 34/100\n",
      "2113/2113 [==============================] - 4s 2ms/sample - loss: 0.8827 - val_loss: 0.9168\n",
      "Train on 2115 samples, validate on 528 samples\n",
      "Epoch 1/100\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 1.0044 - val_loss: 0.9668\n",
      "Epoch 2/100\n",
      "2115/2115 [==============================] - 1s 370us/sample - loss: 0.9655 - val_loss: 0.9563\n",
      "Epoch 3/100\n",
      "2115/2115 [==============================] - 1s 675us/sample - loss: 0.9499 - val_loss: 0.9384\n",
      "Epoch 4/100\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 0.9245 - val_loss: 0.9299\n",
      "Epoch 5/100\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.9160 - val_loss: 0.9064\n",
      "Epoch 6/100\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.9088 - val_loss: 0.9072\n",
      "Epoch 7/100\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.9039 - val_loss: 0.9029\n",
      "Epoch 8/100\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.9024 - val_loss: 0.8961\n",
      "Epoch 9/100\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 0.8984 - val_loss: 0.8972\n",
      "Epoch 10/100\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 0.8983 - val_loss: 0.8973\n",
      "Epoch 11/100\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 0.8966 - val_loss: 0.9059\n",
      "Epoch 12/100\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.8975 - val_loss: 0.8969\n",
      "Epoch 13/100\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.8959 - val_loss: 0.8917\n",
      "Epoch 14/100\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.8947 - val_loss: 0.8919\n",
      "Epoch 15/100\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 0.8948 - val_loss: 0.8970\n",
      "Epoch 16/100\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.8945 - val_loss: 0.9015\n",
      "Epoch 17/100\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.8946 - val_loss: 0.8986\n",
      "Epoch 18/100\n",
      "2115/2115 [==============================] - 1s 613us/sample - loss: 0.8936 - val_loss: 0.8986\n",
      "Epoch 19/100\n",
      "2115/2115 [==============================] - 2s 942us/sample - loss: 0.8940 - val_loss: 0.8933\n",
      "Epoch 20/100\n",
      "2115/2115 [==============================] - 3s 1ms/sample - loss: 0.8920 - val_loss: 0.8982\n",
      "Epoch 21/100\n",
      "2115/2115 [==============================] - 3s 2ms/sample - loss: 0.8933 - val_loss: 0.8964\n",
      "Epoch 22/100\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.8931 - val_loss: 0.8922\n",
      "Epoch 23/100\n",
      "2115/2115 [==============================] - 4s 2ms/sample - loss: 0.8927 - val_loss: 0.8918\n",
      "Train on 2116 samples, validate on 527 samples\n",
      "Epoch 1/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 1.0011 - val_loss: 0.9872\n",
      "Epoch 2/100\n",
      "2116/2116 [==============================] - 1s 502us/sample - loss: 0.9621 - val_loss: 0.9744\n",
      "Epoch 3/100\n",
      "2116/2116 [==============================] - 1s 577us/sample - loss: 0.9502 - val_loss: 0.9500\n",
      "Epoch 4/100\n",
      "2116/2116 [==============================] - 2s 793us/sample - loss: 0.9306 - val_loss: 0.9268\n",
      "Epoch 5/100\n",
      "2116/2116 [==============================] - 3s 2ms/sample - loss: 0.9129 - val_loss: 0.9222\n",
      "Epoch 6/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.9050 - val_loss: 0.9138\n",
      "Epoch 7/100\n",
      "2116/2116 [==============================] - 2s 794us/sample - loss: 0.9007 - val_loss: 0.9119\n",
      "Epoch 8/100\n",
      "2116/2116 [==============================] - 3s 2ms/sample - loss: 0.8992 - val_loss: 0.9136\n",
      "Epoch 9/100\n",
      "2116/2116 [==============================] - 3s 1ms/sample - loss: 0.8936 - val_loss: 0.9172\n",
      "Epoch 10/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8923 - val_loss: 0.9175\n",
      "Epoch 11/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8930 - val_loss: 0.9146\n",
      "Epoch 12/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8922 - val_loss: 0.9121\n",
      "Epoch 13/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8933 - val_loss: 0.9124\n",
      "Epoch 14/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8903 - val_loss: 0.9156\n",
      "Epoch 15/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8907 - val_loss: 0.9114\n",
      "Epoch 16/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8899 - val_loss: 0.9124\n",
      "Epoch 17/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8886 - val_loss: 0.9141\n",
      "Epoch 18/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8898 - val_loss: 0.9156\n",
      "Epoch 19/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8899 - val_loss: 0.9157\n",
      "Epoch 20/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8891 - val_loss: 0.9146\n",
      "Epoch 21/100\n",
      "2116/2116 [==============================] - 3s 2ms/sample - loss: 0.8879 - val_loss: 0.9136\n",
      "Epoch 22/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8870 - val_loss: 0.9130\n",
      "Epoch 23/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8862 - val_loss: 0.9205\n",
      "Epoch 24/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8868 - val_loss: 0.9110\n",
      "Epoch 25/100\n",
      "2116/2116 [==============================] - 3s 1ms/sample - loss: 0.8861 - val_loss: 0.9149\n",
      "Epoch 26/100\n",
      "2116/2116 [==============================] - 3s 1ms/sample - loss: 0.8867 - val_loss: 0.9137\n",
      "Epoch 27/100\n",
      "2116/2116 [==============================] - 3s 2ms/sample - loss: 0.8852 - val_loss: 0.9154\n",
      "Epoch 28/100\n",
      "2116/2116 [==============================] - 3s 1ms/sample - loss: 0.8846 - val_loss: 0.9102\n",
      "Epoch 29/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8852 - val_loss: 0.9238\n",
      "Epoch 30/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8866 - val_loss: 0.9160\n",
      "Epoch 31/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8852 - val_loss: 0.9131\n",
      "Epoch 32/100\n",
      "2116/2116 [==============================] - 2s 835us/sample - loss: 0.8839 - val_loss: 0.9223\n",
      "Epoch 33/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8836 - val_loss: 0.9233\n",
      "Epoch 34/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8830 - val_loss: 0.9252\n",
      "Epoch 35/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8849 - val_loss: 0.9188\n",
      "Epoch 36/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8840 - val_loss: 0.9260\n",
      "Epoch 37/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8824 - val_loss: 0.9191\n",
      "Epoch 38/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8821 - val_loss: 0.9175\n",
      "Train on 2116 samples, validate on 527 samples\n",
      "Epoch 1/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 1.0077 - val_loss: 0.9262\n",
      "Epoch 2/100\n",
      "2116/2116 [==============================] - 1s 506us/sample - loss: 0.9667 - val_loss: 0.9197\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2116/2116 [==============================] - 2s 721us/sample - loss: 0.9447 - val_loss: 0.8915\n",
      "Epoch 4/100\n",
      "2116/2116 [==============================] - 1s 695us/sample - loss: 0.9269 - val_loss: 0.8864\n",
      "Epoch 5/100\n",
      "2116/2116 [==============================] - 2s 1ms/sample - loss: 0.9178 - val_loss: 0.8729\n",
      "Epoch 6/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.9134 - val_loss: 0.8718\n",
      "Epoch 7/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.9099 - val_loss: 0.8674\n",
      "Epoch 8/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.9098 - val_loss: 0.8678\n",
      "Epoch 9/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.9080 - val_loss: 0.8760\n",
      "Epoch 10/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.9062 - val_loss: 0.8654\n",
      "Epoch 11/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.9032 - val_loss: 0.9013\n",
      "Epoch 12/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.9035 - val_loss: 0.8695\n",
      "Epoch 13/100\n",
      "2116/2116 [==============================] - 3s 1ms/sample - loss: 0.9036 - val_loss: 0.8637\n",
      "Epoch 14/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.9016 - val_loss: 0.8642\n",
      "Epoch 15/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.9017 - val_loss: 0.8632\n",
      "Epoch 16/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.9008 - val_loss: 0.8645\n",
      "Epoch 17/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.9025 - val_loss: 0.8644\n",
      "Epoch 18/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.9023 - val_loss: 0.8662\n",
      "Epoch 19/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.9005 - val_loss: 0.8643\n",
      "Epoch 20/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8988 - val_loss: 0.8637\n",
      "Epoch 21/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8989 - val_loss: 0.8646\n",
      "Epoch 22/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8997 - val_loss: 0.8630\n",
      "Epoch 23/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8990 - val_loss: 0.8740\n",
      "Epoch 24/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8988 - val_loss: 0.8634\n",
      "Epoch 25/100\n",
      "2116/2116 [==============================] - 2s 1ms/sample - loss: 0.8982 - val_loss: 0.8638\n",
      "Epoch 26/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8984 - val_loss: 0.8636\n",
      "Epoch 27/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8995 - val_loss: 0.8664\n",
      "Epoch 28/100\n",
      "2116/2116 [==============================] - 3s 1ms/sample - loss: 0.8969 - val_loss: 0.8688\n",
      "Epoch 29/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8970 - val_loss: 0.8625\n",
      "Epoch 30/100\n",
      "2116/2116 [==============================] - 1s 524us/sample - loss: 0.8972 - val_loss: 0.8628\n",
      "Epoch 31/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8968 - val_loss: 0.8652\n",
      "Epoch 32/100\n",
      "2116/2116 [==============================] - 3s 1ms/sample - loss: 0.8970 - val_loss: 0.8629\n",
      "Epoch 33/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8961 - val_loss: 0.8616\n",
      "Epoch 34/100\n",
      "2116/2116 [==============================] - 3s 1ms/sample - loss: 0.8962 - val_loss: 0.8670\n",
      "Epoch 35/100\n",
      "2116/2116 [==============================] - 3s 2ms/sample - loss: 0.8997 - val_loss: 0.8656\n",
      "Epoch 36/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8961 - val_loss: 0.8678\n",
      "Epoch 37/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8959 - val_loss: 0.8630\n",
      "Epoch 38/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8957 - val_loss: 0.8645\n",
      "Epoch 39/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8950 - val_loss: 0.8620\n",
      "Epoch 40/100\n",
      "2116/2116 [==============================] - 4s 2ms/sample - loss: 0.8949 - val_loss: 0.8634\n",
      "Epoch 41/100\n",
      "2116/2116 [==============================] - 3s 2ms/sample - loss: 0.8944 - val_loss: 0.8619\n",
      "Epoch 42/100\n",
      "2116/2116 [==============================] - 3s 2ms/sample - loss: 0.8949 - val_loss: 0.8642\n",
      "Epoch 43/100\n",
      "2116/2116 [==============================] - 3s 2ms/sample - loss: 0.8953 - val_loss: 0.8642\n",
      "Train on 4111 samples, validate on 1030 samples\n",
      "Epoch 1/100\n",
      "4111/4111 [==============================] - 5s 1ms/sample - loss: 0.6558 - val_loss: 0.6197\n",
      "Epoch 2/100\n",
      "4111/4111 [==============================] - 5s 1ms/sample - loss: 0.6087 - val_loss: 0.6100\n",
      "Epoch 3/100\n",
      "4111/4111 [==============================] - 4s 907us/sample - loss: 0.6028 - val_loss: 0.6024\n",
      "Epoch 4/100\n",
      "4111/4111 [==============================] - 5s 1ms/sample - loss: 0.5989 - val_loss: 0.5962\n",
      "Epoch 5/100\n",
      "4111/4111 [==============================] - 4s 929us/sample - loss: 0.5968 - val_loss: 0.5982\n",
      "Epoch 6/100\n",
      "4111/4111 [==============================] - 6s 1ms/sample - loss: 0.5958 - val_loss: 0.5931\n",
      "Epoch 7/100\n",
      "4111/4111 [==============================] - 6s 1ms/sample - loss: 0.5938 - val_loss: 0.5934\n",
      "Epoch 8/100\n",
      "4111/4111 [==============================] - 7s 2ms/sample - loss: 0.5933 - val_loss: 0.5914\n",
      "Epoch 9/100\n",
      "4111/4111 [==============================] - 5s 1ms/sample - loss: 0.5926 - val_loss: 0.5918\n",
      "Epoch 10/100\n",
      "4111/4111 [==============================] - 7s 2ms/sample - loss: 0.5916 - val_loss: 0.5910\n",
      "Epoch 11/100\n",
      "4111/4111 [==============================] - 7s 2ms/sample - loss: 0.5912 - val_loss: 0.5904\n",
      "Epoch 12/100\n",
      "4111/4111 [==============================] - 5s 1ms/sample - loss: 0.5911 - val_loss: 0.5900\n",
      "Epoch 13/100\n",
      "4111/4111 [==============================] - 6s 2ms/sample - loss: 0.5908 - val_loss: 0.5893\n",
      "Epoch 14/100\n",
      "4111/4111 [==============================] - 2s 585us/sample - loss: 0.5902 - val_loss: 0.5890\n",
      "Epoch 15/100\n",
      "4111/4111 [==============================] - 7s 2ms/sample - loss: 0.5902 - val_loss: 0.5883\n",
      "Epoch 16/100\n",
      "4111/4111 [==============================] - 7s 2ms/sample - loss: 0.5894 - val_loss: 0.5889\n",
      "Epoch 17/100\n",
      "4111/4111 [==============================] - 6s 1ms/sample - loss: 0.5892 - val_loss: 0.5894\n",
      "Epoch 18/100\n",
      "4111/4111 [==============================] - 7s 2ms/sample - loss: 0.5881 - val_loss: 0.5897\n",
      "Epoch 19/100\n",
      "4111/4111 [==============================] - 6s 2ms/sample - loss: 0.5882 - val_loss: 0.5872\n",
      "Epoch 20/100\n",
      "4111/4111 [==============================] - 7s 2ms/sample - loss: 0.5877 - val_loss: 0.5889\n",
      "Epoch 21/100\n",
      "4111/4111 [==============================] - 5s 1ms/sample - loss: 0.5866 - val_loss: 0.5908\n",
      "Epoch 22/100\n",
      "4111/4111 [==============================] - 7s 2ms/sample - loss: 0.5869 - val_loss: 0.5880\n",
      "Epoch 23/100\n",
      "4111/4111 [==============================] - 3s 712us/sample - loss: 0.5862 - val_loss: 0.5875\n",
      "Epoch 24/100\n",
      "4111/4111 [==============================] - 6s 1ms/sample - loss: 0.5857 - val_loss: 0.5863\n",
      "Epoch 25/100\n",
      "4111/4111 [==============================] - 7s 2ms/sample - loss: 0.5851 - val_loss: 0.5859\n",
      "Epoch 26/100\n",
      "4111/4111 [==============================] - 5s 1ms/sample - loss: 0.5844 - val_loss: 0.5911\n",
      "Epoch 27/100\n",
      "4111/4111 [==============================] - 5s 1ms/sample - loss: 0.5847 - val_loss: 0.5882\n",
      "Epoch 28/100\n",
      "4111/4111 [==============================] - 6s 1ms/sample - loss: 0.5841 - val_loss: 0.5873\n",
      "Epoch 29/100\n",
      "4111/4111 [==============================] - 6s 1ms/sample - loss: 0.5833 - val_loss: 0.5884\n",
      "Epoch 30/100\n",
      "4111/4111 [==============================] - 6s 1ms/sample - loss: 0.5829 - val_loss: 0.5879\n",
      "Epoch 31/100\n",
      "4111/4111 [==============================] - 5s 1ms/sample - loss: 0.5825 - val_loss: 0.5900\n",
      "Epoch 32/100\n",
      "4111/4111 [==============================] - 6s 1ms/sample - loss: 0.5831 - val_loss: 0.5889\n",
      "Epoch 33/100\n",
      "4111/4111 [==============================] - 7s 2ms/sample - loss: 0.5817 - val_loss: 0.5881\n",
      "Epoch 34/100\n",
      "4111/4111 [==============================] - 7s 2ms/sample - loss: 0.5819 - val_loss: 0.5892\n",
      "Epoch 35/100\n",
      "4111/4111 [==============================] - 3s 643us/sample - loss: 0.5814 - val_loss: 0.5895\n",
      "Train on 4112 samples, validate on 1029 samples\n",
      "Epoch 1/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.6565 - val_loss: 0.6270\n",
      "Epoch 2/100\n",
      "4112/4112 [==============================] - 4s 1ms/sample - loss: 0.6073 - val_loss: 0.6060\n",
      "Epoch 3/100\n",
      "4112/4112 [==============================] - 3s 609us/sample - loss: 0.6011 - val_loss: 0.6029\n",
      "Epoch 4/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5979 - val_loss: 0.6017\n",
      "Epoch 5/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5954 - val_loss: 0.6057\n",
      "Epoch 6/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5945 - val_loss: 0.5989\n",
      "Epoch 7/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5928 - val_loss: 0.5992\n",
      "Epoch 8/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5927 - val_loss: 0.5983\n",
      "Epoch 9/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5912 - val_loss: 0.5950\n",
      "Epoch 10/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5907 - val_loss: 0.5976\n",
      "Epoch 11/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5901 - val_loss: 0.6003\n",
      "Epoch 12/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5887 - val_loss: 0.5941\n",
      "Epoch 13/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5887 - val_loss: 0.5968\n",
      "Epoch 14/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5890 - val_loss: 0.5954\n",
      "Epoch 15/100\n",
      "4112/4112 [==============================] - 4s 999us/sample - loss: 0.5881 - val_loss: 0.5955\n",
      "Epoch 16/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5881 - val_loss: 0.5968\n",
      "Epoch 17/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5872 - val_loss: 0.5951\n",
      "Epoch 18/100\n",
      "4112/4112 [==============================] - 4s 956us/sample - loss: 0.5873 - val_loss: 0.5943\n",
      "Epoch 19/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5866 - val_loss: 0.5945\n",
      "Epoch 20/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5863 - val_loss: 0.5930\n",
      "Epoch 21/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5861 - val_loss: 0.5937\n",
      "Epoch 22/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5849 - val_loss: 0.5948\n",
      "Epoch 23/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5848 - val_loss: 0.6060\n",
      "Epoch 24/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5850 - val_loss: 0.5939\n",
      "Epoch 25/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5851 - val_loss: 0.5939\n",
      "Epoch 26/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5838 - val_loss: 0.5924\n",
      "Epoch 27/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5842 - val_loss: 0.5915\n",
      "Epoch 28/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5833 - val_loss: 0.5926\n",
      "Epoch 29/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5831 - val_loss: 0.5921\n",
      "Epoch 30/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5823 - val_loss: 0.5920\n",
      "Epoch 31/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5821 - val_loss: 0.5933\n",
      "Epoch 32/100\n",
      "4112/4112 [==============================] - 4s 1ms/sample - loss: 0.5819 - val_loss: 0.5910\n",
      "Epoch 33/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5808 - val_loss: 0.5901\n",
      "Epoch 34/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5800 - val_loss: 0.5920\n",
      "Epoch 35/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5798 - val_loss: 0.5928\n",
      "Epoch 36/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5795 - val_loss: 0.5907\n",
      "Epoch 37/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5793 - val_loss: 0.5930\n",
      "Epoch 38/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5780 - val_loss: 0.5930\n",
      "Epoch 39/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5778 - val_loss: 0.5911\n",
      "Epoch 40/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5778 - val_loss: 0.5951\n",
      "Epoch 41/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5771 - val_loss: 0.5902\n",
      "Epoch 42/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5764 - val_loss: 0.5938\n",
      "Epoch 43/100\n",
      "4112/4112 [==============================] - 3s 820us/sample - loss: 0.5761 - val_loss: 0.5918\n",
      "Train on 4112 samples, validate on 1029 samples\n",
      "Epoch 1/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.6544 - val_loss: 0.6174\n",
      "Epoch 2/100\n",
      "4112/4112 [==============================] - 4s 1ms/sample - loss: 0.6089 - val_loss: 0.6065\n",
      "Epoch 3/100\n",
      "4112/4112 [==============================] - 4s 875us/sample - loss: 0.6012 - val_loss: 0.6074\n",
      "Epoch 4/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5987 - val_loss: 0.6006\n",
      "Epoch 5/100\n",
      "4112/4112 [==============================] - 4s 1ms/sample - loss: 0.5962 - val_loss: 0.5987\n",
      "Epoch 6/100\n",
      "4112/4112 [==============================] - 4s 891us/sample - loss: 0.5941 - val_loss: 0.6058\n",
      "Epoch 7/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5933 - val_loss: 0.6001\n",
      "Epoch 8/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5923 - val_loss: 0.5971\n",
      "Epoch 9/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5918 - val_loss: 0.5987\n",
      "Epoch 10/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5912 - val_loss: 0.5957\n",
      "Epoch 11/100\n",
      "4112/4112 [==============================] - 3s 736us/sample - loss: 0.5910 - val_loss: 0.5996\n",
      "Epoch 12/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5897 - val_loss: 0.5957\n",
      "Epoch 13/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5891 - val_loss: 0.5964\n",
      "Epoch 14/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5888 - val_loss: 0.5931\n",
      "Epoch 15/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5880 - val_loss: 0.5937\n",
      "Epoch 16/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5883 - val_loss: 0.5929\n",
      "Epoch 17/100\n",
      "4112/4112 [==============================] - 7s 2ms/sample - loss: 0.5879 - val_loss: 0.5973\n",
      "Epoch 18/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5871 - val_loss: 0.5948\n",
      "Epoch 19/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5872 - val_loss: 0.5938\n",
      "Epoch 20/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5860 - val_loss: 0.5923\n",
      "Epoch 21/100\n",
      "4112/4112 [==============================] - 7s 2ms/sample - loss: 0.5860 - val_loss: 0.5926\n",
      "Epoch 22/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5859 - val_loss: 0.5931\n",
      "Epoch 23/100\n",
      "4112/4112 [==============================] - 3s 770us/sample - loss: 0.5843 - val_loss: 0.5958\n",
      "Epoch 24/100\n",
      "4112/4112 [==============================] - 7s 2ms/sample - loss: 0.5841 - val_loss: 0.5919\n",
      "Epoch 25/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5827 - val_loss: 0.5927\n",
      "Epoch 26/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5827 - val_loss: 0.5949\n",
      "Epoch 27/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5830 - val_loss: 0.5957\n",
      "Epoch 28/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5825 - val_loss: 0.5930\n",
      "Epoch 29/100\n",
      "4112/4112 [==============================] - 4s 1ms/sample - loss: 0.5818 - val_loss: 0.5943\n",
      "Epoch 30/100\n",
      "4112/4112 [==============================] - 7s 2ms/sample - loss: 0.5812 - val_loss: 0.5931\n",
      "Epoch 31/100\n",
      "4112/4112 [==============================] - 7s 2ms/sample - loss: 0.5808 - val_loss: 0.5920\n",
      "Epoch 32/100\n",
      "4112/4112 [==============================] - 6s 2ms/sample - loss: 0.5793 - val_loss: 0.5935\n",
      "Epoch 33/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5796 - val_loss: 0.5926\n",
      "Epoch 34/100\n",
      "4112/4112 [==============================] - 7s 2ms/sample - loss: 0.5788 - val_loss: 0.5913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5790 - val_loss: 0.5930\n",
      "Epoch 36/100\n",
      "4112/4112 [==============================] - 7s 2ms/sample - loss: 0.5785 - val_loss: 0.5940\n",
      "Epoch 37/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5785 - val_loss: 0.5959\n",
      "Epoch 38/100\n",
      "4112/4112 [==============================] - 7s 2ms/sample - loss: 0.5774 - val_loss: 0.5910\n",
      "Epoch 39/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5770 - val_loss: 0.5917\n",
      "Epoch 40/100\n",
      "4112/4112 [==============================] - 7s 2ms/sample - loss: 0.5772 - val_loss: 0.5939\n",
      "Epoch 41/100\n",
      "4112/4112 [==============================] - 7s 2ms/sample - loss: 0.5762 - val_loss: 0.5929\n",
      "Epoch 42/100\n",
      "4112/4112 [==============================] - 7s 2ms/sample - loss: 0.5762 - val_loss: 0.5937\n",
      "Epoch 43/100\n",
      "4112/4112 [==============================] - 7s 2ms/sample - loss: 0.5753 - val_loss: 0.5977\n",
      "Epoch 44/100\n",
      "4112/4112 [==============================] - 4s 957us/sample - loss: 0.5753 - val_loss: 0.5950\n",
      "Epoch 45/100\n",
      "4112/4112 [==============================] - 6s 1ms/sample - loss: 0.5746 - val_loss: 0.5933\n",
      "Epoch 46/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5746 - val_loss: 0.5947\n",
      "Epoch 47/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5741 - val_loss: 0.5923\n",
      "Epoch 48/100\n",
      "4112/4112 [==============================] - 5s 1ms/sample - loss: 0.5732 - val_loss: 0.5960\n",
      "Train on 4114 samples, validate on 1027 samples\n",
      "Epoch 1/100\n",
      "4114/4114 [==============================] - 5s 1ms/sample - loss: 0.6568 - val_loss: 0.6010\n",
      "Epoch 2/100\n",
      "4114/4114 [==============================] - 6s 1ms/sample - loss: 0.6128 - val_loss: 0.5931\n",
      "Epoch 3/100\n",
      "4114/4114 [==============================] - 2s 507us/sample - loss: 0.6053 - val_loss: 0.5916\n",
      "Epoch 4/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.6031 - val_loss: 0.5912\n",
      "Epoch 5/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.6002 - val_loss: 0.5852\n",
      "Epoch 6/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5986 - val_loss: 0.5811\n",
      "Epoch 7/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5967 - val_loss: 0.5834\n",
      "Epoch 8/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5960 - val_loss: 0.5812\n",
      "Epoch 9/100\n",
      "4114/4114 [==============================] - 6s 2ms/sample - loss: 0.5953 - val_loss: 0.5818\n",
      "Epoch 10/100\n",
      "4114/4114 [==============================] - 6s 1ms/sample - loss: 0.5946 - val_loss: 0.5788\n",
      "Epoch 11/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5940 - val_loss: 0.5806\n",
      "Epoch 12/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5930 - val_loss: 0.5823\n",
      "Epoch 13/100\n",
      "4114/4114 [==============================] - 5s 1ms/sample - loss: 0.5931 - val_loss: 0.5810\n",
      "Epoch 14/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5928 - val_loss: 0.5778\n",
      "Epoch 15/100\n",
      "4114/4114 [==============================] - 5s 1ms/sample - loss: 0.5930 - val_loss: 0.5822\n",
      "Epoch 16/100\n",
      "4114/4114 [==============================] - 5s 1ms/sample - loss: 0.5920 - val_loss: 0.5777\n",
      "Epoch 17/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5916 - val_loss: 0.5772\n",
      "Epoch 18/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5914 - val_loss: 0.5765\n",
      "Epoch 19/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5907 - val_loss: 0.5871\n",
      "Epoch 20/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5906 - val_loss: 0.5812\n",
      "Epoch 21/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5903 - val_loss: 0.5810\n",
      "Epoch 22/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5891 - val_loss: 0.5763\n",
      "Epoch 23/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5905 - val_loss: 0.5765\n",
      "Epoch 24/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5897 - val_loss: 0.5803\n",
      "Epoch 25/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5891 - val_loss: 0.5767\n",
      "Epoch 26/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5888 - val_loss: 0.5765\n",
      "Epoch 27/100\n",
      "4114/4114 [==============================] - 4s 1ms/sample - loss: 0.5878 - val_loss: 0.5798\n",
      "Epoch 28/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5885 - val_loss: 0.5780\n",
      "Epoch 29/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5872 - val_loss: 0.5764\n",
      "Epoch 30/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5875 - val_loss: 0.5776\n",
      "Epoch 31/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5870 - val_loss: 0.5763\n",
      "Epoch 32/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5857 - val_loss: 0.5757\n",
      "Epoch 33/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5849 - val_loss: 0.5775\n",
      "Epoch 34/100\n",
      "4114/4114 [==============================] - 4s 877us/sample - loss: 0.5853 - val_loss: 0.5772\n",
      "Epoch 35/100\n",
      "4114/4114 [==============================] - 4s 1ms/sample - loss: 0.5846 - val_loss: 0.5753\n",
      "Epoch 36/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5846 - val_loss: 0.5746\n",
      "Epoch 37/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5842 - val_loss: 0.5754\n",
      "Epoch 38/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5838 - val_loss: 0.5794\n",
      "Epoch 39/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5843 - val_loss: 0.5762\n",
      "Epoch 40/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5827 - val_loss: 0.5797\n",
      "Epoch 41/100\n",
      "4114/4114 [==============================] - 6s 1ms/sample - loss: 0.5818 - val_loss: 0.5757\n",
      "Epoch 42/100\n",
      "4114/4114 [==============================] - 6s 1ms/sample - loss: 0.5811 - val_loss: 0.5748\n",
      "Epoch 43/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5812 - val_loss: 0.5780\n",
      "Epoch 44/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5812 - val_loss: 0.5774\n",
      "Epoch 45/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5809 - val_loss: 0.5784\n",
      "Epoch 46/100\n",
      "4114/4114 [==============================] - 7s 2ms/sample - loss: 0.5793 - val_loss: 0.5767\n",
      "Train on 4115 samples, validate on 1026 samples\n",
      "Epoch 1/100\n",
      "4115/4115 [==============================] - 5s 1ms/sample - loss: 0.6534 - val_loss: 0.6216\n",
      "Epoch 2/100\n",
      "4115/4115 [==============================] - 5s 1ms/sample - loss: 0.6075 - val_loss: 0.6130\n",
      "Epoch 3/100\n",
      "4115/4115 [==============================] - 4s 931us/sample - loss: 0.6002 - val_loss: 0.6086\n",
      "Epoch 4/100\n",
      "4115/4115 [==============================] - 5s 1ms/sample - loss: 0.5969 - val_loss: 0.6069\n",
      "Epoch 5/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5953 - val_loss: 0.6042\n",
      "Epoch 6/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5933 - val_loss: 0.6066\n",
      "Epoch 7/100\n",
      "4115/4115 [==============================] - 5s 1ms/sample - loss: 0.5926 - val_loss: 0.6036\n",
      "Epoch 8/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5904 - val_loss: 0.6029\n",
      "Epoch 9/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5901 - val_loss: 0.6006\n",
      "Epoch 10/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5894 - val_loss: 0.6004\n",
      "Epoch 11/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5884 - val_loss: 0.6028\n",
      "Epoch 12/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5894 - val_loss: 0.5996\n",
      "Epoch 13/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5881 - val_loss: 0.6040\n",
      "Epoch 14/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5882 - val_loss: 0.6014\n",
      "Epoch 15/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5877 - val_loss: 0.5979\n",
      "Epoch 16/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5862 - val_loss: 0.6015\n",
      "Epoch 17/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5870 - val_loss: 0.5985\n",
      "Epoch 18/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5852 - val_loss: 0.5974\n",
      "Epoch 19/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5867 - val_loss: 0.5981\n",
      "Epoch 20/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5850 - val_loss: 0.5980\n",
      "Epoch 21/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5841 - val_loss: 0.5982\n",
      "Epoch 22/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5838 - val_loss: 0.5977\n",
      "Epoch 23/100\n",
      "4115/4115 [==============================] - 4s 962us/sample - loss: 0.5844 - val_loss: 0.5961\n",
      "Epoch 24/100\n",
      "4115/4115 [==============================] - 5s 1ms/sample - loss: 0.5838 - val_loss: 0.5970\n",
      "Epoch 25/100\n",
      "4115/4115 [==============================] - 6s 1ms/sample - loss: 0.5830 - val_loss: 0.5972\n",
      "Epoch 26/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5818 - val_loss: 0.5969\n",
      "Epoch 27/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5827 - val_loss: 0.5972\n",
      "Epoch 28/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5817 - val_loss: 0.5963\n",
      "Epoch 29/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5823 - val_loss: 0.5990\n",
      "Epoch 30/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5806 - val_loss: 0.5986\n",
      "Epoch 31/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5802 - val_loss: 0.5997\n",
      "Epoch 32/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5801 - val_loss: 0.5999\n",
      "Epoch 33/100\n",
      "4115/4115 [==============================] - 7s 2ms/sample - loss: 0.5800 - val_loss: 0.5985\n"
     ]
    }
   ],
   "source": [
    "metrics = full_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gene': {'overall': {'mae': 0.7297401469016269,\n",
       "   'rmse': 1.2887244638659925,\n",
       "   'ndcg': 0.3803953501729045},\n",
       "  'annual': {'mae': array([0.41587097, 0.57677975, 0.75007012, 0.88360723, 1.02237268]),\n",
       "   'rmse': array([0.77792397, 0.97254351, 1.31705204, 1.47657129, 1.66178059]),\n",
       "   'ndcg': array([0.44694829, 0.37630686, 0.15230446, 0.19535201, 0.14445967])}},\n",
       " 'transplant': {'overall': {'mae': 0.7538141078186955,\n",
       "   'rmse': 1.251139174988568,\n",
       "   'ndcg': 0.5317447321152349},\n",
       "  'annual': {'mae': array([0.74064418, 0.7623244 , 0.72633263, 0.74707724, 0.79269209]),\n",
       "   'rmse': array([1.27620115, 1.28425156, 1.18747271, 1.19815046, 1.29499351]),\n",
       "   'ndcg': array([0.04100715, 0.01954889, 0.02220831, 0.07470384, 0.05093919])}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gene': {'overall': {'mae': 0.7297492556384867,\n",
       "   'rmse': 1.2889003524345672,\n",
       "   'ndcg': 0.3803953363115765,\n",
       "   'mape': 4.244950962090654,\n",
       "   'r2': 0.24038236527618642,\n",
       "   'pearson': 0.5237988055359878,\n",
       "   'acc': 0.3445377320027842},\n",
       "  'annual': {'mae': array([0.4158578 , 0.57681987, 0.75021887, 0.88353171, 1.02231803]),\n",
       "   'rmse': array([0.77802427, 0.97265524, 1.317182  , 1.47681347, 1.66203587]),\n",
       "   'ndcg': array([0.44694329, 0.37630686, 0.15396231, 0.19492758, 0.14446005]),\n",
       "   'mape': array([3.06064781, 2.80838312, 3.11369291, 5.9569929 , 6.28503807]),\n",
       "   'r2': array([0.39500869, 0.27431165, 0.18671522, 0.06620267, 0.02536364]),\n",
       "   'pearson': array([0.65211583, 0.56291987, 0.4766435 , 0.33350701, 0.27608457]),\n",
       "   'acc': array([0.62432858, 0.22443223, 0.24055186, 0.32722977, 0.30614623])}},\n",
       " 'transplant': {'overall': {'mae': 0.7544008497719823,\n",
       "   'rmse': 1.2510707017068214,\n",
       "   'ndcg': 0.47544825701727483,\n",
       "   'mape': 3.5521715821966304,\n",
       "   'r2': 0.44112280139615495,\n",
       "   'pearson': 0.6730829642395529,\n",
       "   'acc': 0.3519104878150792},\n",
       "  'annual': {'mae': array([0.74045377, 0.76279451, 0.72669407, 0.74744887, 0.79461302]),\n",
       "   'rmse': array([1.27602792, 1.28421426, 1.18679974, 1.196882  , 1.29664065]),\n",
       "   'ndcg': array([0.03518812, 0.0199885 , 0.02203662, 0.07389319, 0.05173773]),\n",
       "   'mape': array([3.35352693, 3.88806556, 3.04675044, 4.01985103, 3.45266395]),\n",
       "   'r2': array([0.45127266, 0.43103192, 0.4381013 , 0.46930308, 0.42248466]),\n",
       "   'pearson': array([0.67871188, 0.66569851, 0.66883044, 0.69603513, 0.66263721]),\n",
       "   'acc': array([0.35964623, 0.34758472, 0.36160728, 0.34914664, 0.34156757])}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}