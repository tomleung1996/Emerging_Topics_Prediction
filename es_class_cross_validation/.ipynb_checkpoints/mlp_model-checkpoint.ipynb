{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "## 仅供交叉验证 前馈神经网络（NNAR）-按总量分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from utils import *\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "n_input = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the gene_editing array: (2643, 17, 10)\n",
      "Shape of the transplant array: (5141, 17, 10)\n"
     ]
    }
   ],
   "source": [
    "# gene_arr_path = r'../output/gene_editing/es_with_decay.array'\n",
    "# transplant_arr_path = r'../output/transplant/es_with_decay.array'\n",
    "\n",
    "# gene_arr = pickle.load(open(gene_arr_path, mode='rb'))\n",
    "# transplant_arr = pickle.load(open(transplant_arr_path, mode='rb'))\n",
    "\n",
    "# print('Shape of the gene_editing array:',gene_arr.shape)\n",
    "# print('Shape of the transplant array:',transplant_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 截断数据\n",
    "2019年为无效数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the gene_editing array: (2643, 16, 10)\n",
      "Shape of the transplant array: (5141, 16, 10)\n"
     ]
    }
   ],
   "source": [
    "# gene_arr = gene_arr[:, :-1, :]\n",
    "# transplant_arr = transplant_arr[:, :-1, :]\n",
    "\n",
    "# print('Shape of the gene_editing array:',gene_arr.shape)\n",
    "# print('Shape of the transplant array:',transplant_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 规范数据并获取5折交叉检验所需的训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler, data = scale_data(transplant_arr, 'standard')\n",
    "\n",
    "# # 用预测第二年的类别变量作为分成Kfold的依据，不支持浮点数\n",
    "# X, y, y_cat = data[:, :n_input, :], data[:, n_input:, -2],transplant_arr[:, n_input, -1]\n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按总量切分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_by_es(data, targets):\n",
    "    total_es = np.sum(data[:, :11, -2], axis=1)\n",
    "    sorted_index = np.argsort(total_es)\n",
    "    group_size = len(total_es) // 3\n",
    "    \n",
    "    data1, target1 = data[sorted_index[:group_size]], targets[sorted_index[:group_size]]\n",
    "    data2, target2 = data[sorted_index[group_size:2*group_size]], targets[sorted_index[group_size:2*group_size]]\n",
    "    data3, target3 = data[sorted_index[2*group_size:]], targets[sorted_index[2*group_size:]]\n",
    "    \n",
    "    return data1, target1, data2, target2, data3, target3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return keras.backend.sqrt(keras.backend.mean(keras.backend.square(y_pred - y_true), axis=-1)) \n",
    "\n",
    "def build_direct_dnn_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(5))\n",
    "    \n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(loss=root_mean_squared_error, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进行训练和评估\n",
    "使用EarlyStopping和Checkpoint做训练停止方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, y, y_cat, kfold, scaler):\n",
    "    overall_metrics = {\n",
    "        'mae':[],\n",
    "        'rmse':[],\n",
    "        'ndcg':[],\n",
    "        'mape':[],\n",
    "        'r2':[],\n",
    "        'pearson':[],\n",
    "        'acc':[]\n",
    "    }\n",
    "\n",
    "    annual_metrics = {\n",
    "        'mae':[],\n",
    "        'rmse':[],\n",
    "        'ndcg':[],\n",
    "        'mape':[],\n",
    "        'r2':[],\n",
    "        'pearson':[],\n",
    "        'acc':[]\n",
    "    }\n",
    "    \n",
    "    for train, test in kfold.split(X, y_cat):\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        models = []\n",
    "        \n",
    "        # 按总量划分数据集\n",
    "        X_train1, y_train1, X_train2, y_train2, X_train3, y_train3 = split_data_by_es(X_train, y_train)\n",
    "        train_xs = [X_train1, X_train2, X_train3]\n",
    "        train_ys = [y_train1, y_train2, y_train3]\n",
    "        \n",
    "        X_test1, y_test1, X_test2, y_test2, X_test3, y_test3 = split_data_by_es(X_test, y_test)\n",
    "        test_xs = [X_test1, X_test2, X_test3]\n",
    "        test_ys = [y_test1, y_test2, y_test3]\n",
    "        i_s = [1, 2, 3]\n",
    "        \n",
    "        # 训练\n",
    "        for i in range(len(i_s)):\n",
    "            model = build_direct_dnn_model()\n",
    "            history = model.fit(train_xs[i], train_ys[i], epochs=100, batch_size=16, verbose=1, validation_data=(test_xs[i], test_ys[i]),\n",
    "                           callbacks=[\n",
    "                               EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto', restore_best_weights=True)\n",
    "                           ])\n",
    "            models.append(model)\n",
    "        \n",
    "        # 预测\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "        for i in range(len(i_s)):\n",
    "            y_test.append(test_ys[i])\n",
    "            y_pred.append(models[i].predict(test_xs[i]).reshape(test_ys[i].shape))\n",
    "        \n",
    "        y_test = np.concatenate(y_test)\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "\n",
    "        metrics = ['mae', 'rmse','ndcg', 'mape', 'r2', 'pearson', 'acc']\n",
    "        for m in metrics:\n",
    "            overall, annual = eval_model(m, y_test, y_pred, scaler)\n",
    "            overall_metrics[m].append(overall)\n",
    "            annual_metrics[m].append(annual)\n",
    "    \n",
    "    return overall_metrics, annual_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline():\n",
    "    gene_arr_path = r'../output/gene_editing/es_with_decay.array'\n",
    "    transplant_arr_path = r'../output/transplant/es_with_decay.array'\n",
    "\n",
    "    gene_arr = pickle.load(open(gene_arr_path, mode='rb'))\n",
    "    transplant_arr = pickle.load(open(transplant_arr_path, mode='rb'))\n",
    "    \n",
    "    gene_arr = gene_arr[:, :-1, :]\n",
    "    transplant_arr = transplant_arr[:, :-1, :]\n",
    "\n",
    "    print('Shape of the gene_editing array:',gene_arr.shape)\n",
    "    print('Shape of the transplant array:',transplant_arr.shape)\n",
    "    \n",
    "    metrics = {\n",
    "        'gene':{\n",
    "            'overall':{},\n",
    "            'annual':{}\n",
    "        },\n",
    "        'transplant':{\n",
    "            'overall':{},\n",
    "            'annual':{}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for name, dataset in zip(['gene', 'transplant'], [gene_arr, transplant_arr]):\n",
    "        scaler, data = scale_data(dataset, 'standard')\n",
    "\n",
    "        # 用预测第二年的类别变量作为分成Kfold的依据，不支持浮点数\n",
    "        X, y, y_cat = data[:, :n_input, :], data[:, n_input:, -2], dataset[:, n_input, -1]\n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        overall_metrics, annual_metrics = cross_validation(X, y, y_cat, kfold, scaler)\n",
    "        \n",
    "        for metric, value in overall_metrics.items():\n",
    "            metrics[name]['overall'][metric] = np.mean(value)\n",
    "        \n",
    "        for metric, value in annual_metrics.items():\n",
    "            metrics[name]['annual'][metric] = np.mean(np.array(value), axis=0)\n",
    "    \n",
    "    pickle.dump(metrics, open('mlp_metrics.dict', 'wb'))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the gene_editing array: (2643, 16, 10)\n",
      "Shape of the transplant array: (5141, 16, 10)\n",
      "Train on 704 samples, validate on 177 samples\n",
      "Epoch 1/100\n",
      "704/704 [==============================] - 1s 1ms/sample - loss: 0.8506 - val_loss: 0.6647\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 0s 200us/sample - loss: 0.7784 - val_loss: 0.6654\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 0s 282us/sample - loss: 0.7773 - val_loss: 0.6652\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 0s 212us/sample - loss: 0.7770 - val_loss: 0.6676\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 0s 200us/sample - loss: 0.7779 - val_loss: 0.6654\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 0s 194us/sample - loss: 0.7772 - val_loss: 0.6656\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 0s 221us/sample - loss: 0.7773 - val_loss: 0.6654\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 0s 203us/sample - loss: 0.7775 - val_loss: 0.6658\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 0s 196us/sample - loss: 0.7776 - val_loss: 0.6652\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 0s 207us/sample - loss: 0.7775 - val_loss: 0.6658\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 0s 203us/sample - loss: 0.7775 - val_loss: 0.6651\n",
      "Train on 704 samples, validate on 177 samples\n",
      "Epoch 1/100\n",
      "704/704 [==============================] - 1s 1ms/sample - loss: 0.8433 - val_loss: 0.8429\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 0s 196us/sample - loss: 0.8004 - val_loss: 0.8360\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 0s 195us/sample - loss: 0.7952 - val_loss: 0.8358\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 0s 203us/sample - loss: 0.7929 - val_loss: 0.8334\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 0s 224us/sample - loss: 0.7916 - val_loss: 0.8312\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 0s 244us/sample - loss: 0.7915 - val_loss: 0.8314\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 0s 207us/sample - loss: 0.7918 - val_loss: 0.8317\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 0s 200us/sample - loss: 0.7906 - val_loss: 0.8314\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 0s 201us/sample - loss: 0.7897 - val_loss: 0.8329\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 0s 197us/sample - loss: 0.7901 - val_loss: 0.8323\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 0s 200us/sample - loss: 0.7891 - val_loss: 0.8329\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 0s 194us/sample - loss: 0.7902 - val_loss: 0.8325\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 0s 205us/sample - loss: 0.7899 - val_loss: 0.8341\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 0s 200us/sample - loss: 0.7889 - val_loss: 0.8331\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 0s 201us/sample - loss: 0.7890 - val_loss: 0.8325\n",
      "Train on 704 samples, validate on 177 samples\n",
      "Epoch 1/100\n",
      "704/704 [==============================] - 1s 1ms/sample - loss: 1.3707 - val_loss: 1.2702\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 0s 198us/sample - loss: 1.1883 - val_loss: 1.1814\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 0s 200us/sample - loss: 1.1484 - val_loss: 1.1632\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 0s 210us/sample - loss: 1.1313 - val_loss: 1.1555\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 0s 203us/sample - loss: 1.1219 - val_loss: 1.1528\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 0s 200us/sample - loss: 1.1140 - val_loss: 1.1524\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 0s 204us/sample - loss: 1.1076 - val_loss: 1.1513\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 0s 207us/sample - loss: 1.1029 - val_loss: 1.1485\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 0s 200us/sample - loss: 1.0980 - val_loss: 1.1484\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 0s 201us/sample - loss: 1.0932 - val_loss: 1.1495\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 0s 205us/sample - loss: 1.0880 - val_loss: 1.1481\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 0s 200us/sample - loss: 1.0836 - val_loss: 1.1481\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 0s 201us/sample - loss: 1.0806 - val_loss: 1.1481\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 0s 208us/sample - loss: 1.0758 - val_loss: 1.1472\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 0s 201us/sample - loss: 1.0730 - val_loss: 1.1473\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 0s 217us/sample - loss: 1.0682 - val_loss: 1.1475\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 0s 242us/sample - loss: 1.0668 - val_loss: 1.1468\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 0s 210us/sample - loss: 1.0629 - val_loss: 1.1483\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 0s 201us/sample - loss: 1.0594 - val_loss: 1.1482\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 0s 210us/sample - loss: 1.0556 - val_loss: 1.1479\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 0s 205us/sample - loss: 1.0514 - val_loss: 1.1467\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 0s 204us/sample - loss: 1.0492 - val_loss: 1.1483\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 0s 214us/sample - loss: 1.0464 - val_loss: 1.1467\n",
      "Epoch 24/100\n",
      "704/704 [==============================] - 0s 235us/sample - loss: 1.0432 - val_loss: 1.1485\n",
      "Epoch 25/100\n",
      "704/704 [==============================] - 0s 205us/sample - loss: 1.0396 - val_loss: 1.1493\n",
      "Epoch 26/100\n",
      "704/704 [==============================] - 0s 205us/sample - loss: 1.0393 - val_loss: 1.1459\n",
      "Epoch 27/100\n",
      "704/704 [==============================] - 0s 205us/sample - loss: 1.0346 - val_loss: 1.1468\n",
      "Epoch 28/100\n",
      "704/704 [==============================] - 0s 204us/sample - loss: 1.0321 - val_loss: 1.1466\n",
      "Epoch 29/100\n",
      "704/704 [==============================] - 0s 204us/sample - loss: 1.0286 - val_loss: 1.1460\n",
      "Epoch 30/100\n",
      "704/704 [==============================] - 0s 211us/sample - loss: 1.0254 - val_loss: 1.1470\n",
      "Epoch 31/100\n",
      "704/704 [==============================] - 0s 208us/sample - loss: 1.0242 - val_loss: 1.1487\n",
      "Epoch 32/100\n",
      "704/704 [==============================] - 0s 198us/sample - loss: 1.0199 - val_loss: 1.1461\n",
      "Epoch 33/100\n",
      "704/704 [==============================] - 0s 207us/sample - loss: 1.0170 - val_loss: 1.1465\n",
      "Epoch 34/100\n",
      "704/704 [==============================] - 0s 207us/sample - loss: 1.0154 - val_loss: 1.1455\n",
      "Epoch 35/100\n",
      "704/704 [==============================] - 0s 215us/sample - loss: 1.0126 - val_loss: 1.1469\n",
      "Epoch 36/100\n",
      "704/704 [==============================] - 0s 217us/sample - loss: 1.0107 - val_loss: 1.1455\n",
      "Epoch 37/100\n",
      "704/704 [==============================] - 0s 235us/sample - loss: 1.0077 - val_loss: 1.1473\n",
      "Epoch 38/100\n",
      "704/704 [==============================] - 0s 248us/sample - loss: 1.0046 - val_loss: 1.1451\n",
      "Epoch 39/100\n",
      "704/704 [==============================] - 0s 221us/sample - loss: 1.0016 - val_loss: 1.1467\n",
      "Epoch 40/100\n",
      "704/704 [==============================] - 0s 222us/sample - loss: 0.9999 - val_loss: 1.1487\n",
      "Epoch 41/100\n",
      "704/704 [==============================] - 0s 210us/sample - loss: 0.9979 - val_loss: 1.1457\n",
      "Epoch 42/100\n",
      "704/704 [==============================] - 0s 205us/sample - loss: 0.9944 - val_loss: 1.1449\n",
      "Epoch 43/100\n",
      "704/704 [==============================] - 0s 207us/sample - loss: 0.9917 - val_loss: 1.1471\n",
      "Epoch 44/100\n",
      "704/704 [==============================] - 0s 210us/sample - loss: 0.9899 - val_loss: 1.1457\n",
      "Epoch 45/100\n",
      "704/704 [==============================] - 0s 204us/sample - loss: 0.9882 - val_loss: 1.1459\n",
      "Epoch 46/100\n",
      "704/704 [==============================] - 0s 204us/sample - loss: 0.9854 - val_loss: 1.1496\n",
      "Epoch 47/100\n",
      "704/704 [==============================] - 0s 204us/sample - loss: 0.9837 - val_loss: 1.1520\n",
      "Epoch 48/100\n",
      "704/704 [==============================] - 0s 241us/sample - loss: 0.9800 - val_loss: 1.1465\n",
      "Epoch 49/100\n",
      "704/704 [==============================] - 0s 281us/sample - loss: 0.9776 - val_loss: 1.1478\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 0s 218us/sample - loss: 0.9785 - val_loss: 1.1479\n",
      "Epoch 51/100\n",
      "704/704 [==============================] - 0s 198us/sample - loss: 0.9729 - val_loss: 1.1493\n",
      "Epoch 52/100\n",
      "704/704 [==============================] - 0s 221us/sample - loss: 0.9725 - val_loss: 1.1466\n",
      "Train on 704 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "704/704 [==============================] - 1s 1ms/sample - loss: 0.7999 - val_loss: 0.7526\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 0s 224us/sample - loss: 0.7516 - val_loss: 0.7492\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 0s 232us/sample - loss: 0.7514 - val_loss: 0.7487\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 0s 241us/sample - loss: 0.7516 - val_loss: 0.7497\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 0s 238us/sample - loss: 0.7517 - val_loss: 0.7498\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 0s 262us/sample - loss: 0.7525 - val_loss: 0.7470\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 0s 239us/sample - loss: 0.7526 - val_loss: 0.7484\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 0s 252us/sample - loss: 0.7515 - val_loss: 0.7483\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 0s 242us/sample - loss: 0.7512 - val_loss: 0.7485\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 0s 238us/sample - loss: 0.7518 - val_loss: 0.7506\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 0s 238us/sample - loss: 0.7519 - val_loss: 0.7485\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 0s 234us/sample - loss: 0.7522 - val_loss: 0.7492\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 0s 237us/sample - loss: 0.7516 - val_loss: 0.7476\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 0s 238us/sample - loss: 0.7520 - val_loss: 0.7513\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 0s 255us/sample - loss: 0.7516 - val_loss: 0.7479\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 0s 247us/sample - loss: 0.7520 - val_loss: 0.7496\n",
      "Train on 704 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "704/704 [==============================] - 1s 1ms/sample - loss: 0.8518 - val_loss: 0.8426\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 0s 231us/sample - loss: 0.8024 - val_loss: 0.8421\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 0s 237us/sample - loss: 0.7980 - val_loss: 0.8384\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 0s 237us/sample - loss: 0.7956 - val_loss: 0.8376\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 0s 232us/sample - loss: 0.7944 - val_loss: 0.8399\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 0s 231us/sample - loss: 0.7935 - val_loss: 0.8380\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 0s 239us/sample - loss: 0.7942 - val_loss: 0.8404\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 0s 235us/sample - loss: 0.7934 - val_loss: 0.8383\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 0s 237us/sample - loss: 0.7928 - val_loss: 0.8391\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - 0s 256us/sample - loss: 0.7924 - val_loss: 0.8385\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - 0s 245us/sample - loss: 0.7926 - val_loss: 0.8381\n",
      "Epoch 12/100\n",
      "704/704 [==============================] - 0s 232us/sample - loss: 0.7925 - val_loss: 0.8388\n",
      "Epoch 13/100\n",
      "704/704 [==============================] - 0s 246us/sample - loss: 0.7918 - val_loss: 0.8367\n",
      "Epoch 14/100\n",
      "704/704 [==============================] - 0s 313us/sample - loss: 0.7919 - val_loss: 0.8415\n",
      "Epoch 15/100\n",
      "704/704 [==============================] - 0s 263us/sample - loss: 0.7920 - val_loss: 0.8374\n",
      "Epoch 16/100\n",
      "704/704 [==============================] - 0s 252us/sample - loss: 0.7927 - val_loss: 0.8399\n",
      "Epoch 17/100\n",
      "704/704 [==============================] - 0s 247us/sample - loss: 0.7912 - val_loss: 0.8426\n",
      "Epoch 18/100\n",
      "704/704 [==============================] - 0s 249us/sample - loss: 0.7921 - val_loss: 0.8380\n",
      "Epoch 19/100\n",
      "704/704 [==============================] - 0s 252us/sample - loss: 0.7913 - val_loss: 0.8399\n",
      "Epoch 20/100\n",
      "704/704 [==============================] - 0s 238us/sample - loss: 0.7922 - val_loss: 0.8408\n",
      "Epoch 21/100\n",
      "704/704 [==============================] - 0s 239us/sample - loss: 0.7915 - val_loss: 0.8398\n",
      "Epoch 22/100\n",
      "704/704 [==============================] - 0s 237us/sample - loss: 0.7917 - val_loss: 0.8407\n",
      "Epoch 23/100\n",
      "704/704 [==============================] - 0s 239us/sample - loss: 0.7914 - val_loss: 0.8407\n",
      "Train on 705 samples, validate on 178 samples\n",
      "Epoch 1/100\n",
      "705/705 [==============================] - 1s 1ms/sample - loss: 1.3057 - val_loss: 1.2852\n",
      "Epoch 2/100\n",
      "705/705 [==============================] - 0s 265us/sample - loss: 1.1654 - val_loss: 1.2292\n",
      "Epoch 3/100\n",
      "705/705 [==============================] - 0s 260us/sample - loss: 1.1301 - val_loss: 1.2099\n",
      "Epoch 4/100\n",
      "705/705 [==============================] - 0s 265us/sample - loss: 1.1156 - val_loss: 1.2006\n",
      "Epoch 5/100\n",
      "705/705 [==============================] - 0s 283us/sample - loss: 1.1068 - val_loss: 1.1980\n",
      "Epoch 6/100\n",
      "705/705 [==============================] - 0s 274us/sample - loss: 1.1005 - val_loss: 1.1940\n",
      "Epoch 7/100\n",
      "705/705 [==============================] - 0s 276us/sample - loss: 1.0963 - val_loss: 1.1930\n",
      "Epoch 8/100\n",
      "705/705 [==============================] - 0s 279us/sample - loss: 1.0907 - val_loss: 1.1919\n",
      "Epoch 9/100\n",
      "705/705 [==============================] - 0s 282us/sample - loss: 1.0855 - val_loss: 1.1910\n",
      "Epoch 10/100\n",
      "705/705 [==============================] - 0s 266us/sample - loss: 1.0816 - val_loss: 1.1916\n",
      "Epoch 11/100\n",
      "705/705 [==============================] - 0s 260us/sample - loss: 1.0772 - val_loss: 1.1910\n",
      "Epoch 12/100\n",
      "705/705 [==============================] - 0s 289us/sample - loss: 1.0738 - val_loss: 1.1903\n",
      "Epoch 13/100\n",
      "705/705 [==============================] - 0s 283us/sample - loss: 1.0702 - val_loss: 1.1906\n",
      "Epoch 14/100\n",
      "705/705 [==============================] - 0s 262us/sample - loss: 1.0682 - val_loss: 1.1910\n",
      "Epoch 15/100\n",
      "705/705 [==============================] - 0s 259us/sample - loss: 1.0619 - val_loss: 1.1912\n",
      "Epoch 16/100\n",
      "705/705 [==============================] - 0s 256us/sample - loss: 1.0605 - val_loss: 1.1913\n",
      "Epoch 17/100\n",
      "705/705 [==============================] - 0s 310us/sample - loss: 1.0556 - val_loss: 1.1897\n",
      "Epoch 18/100\n",
      "705/705 [==============================] - 0s 304us/sample - loss: 1.0517 - val_loss: 1.1936\n",
      "Epoch 19/100\n",
      "705/705 [==============================] - 0s 307us/sample - loss: 1.0491 - val_loss: 1.1930\n",
      "Epoch 20/100\n",
      "705/705 [==============================] - 0s 280us/sample - loss: 1.0458 - val_loss: 1.1926\n",
      "Epoch 21/100\n",
      "705/705 [==============================] - 0s 263us/sample - loss: 1.0414 - val_loss: 1.1922\n",
      "Epoch 22/100\n",
      "705/705 [==============================] - 0s 270us/sample - loss: 1.0379 - val_loss: 1.1931\n",
      "Epoch 23/100\n",
      "705/705 [==============================] - 0s 283us/sample - loss: 1.0357 - val_loss: 1.1918\n",
      "Epoch 24/100\n",
      "705/705 [==============================] - 0s 287us/sample - loss: 1.0324 - val_loss: 1.1941\n",
      "Epoch 25/100\n",
      "705/705 [==============================] - 0s 273us/sample - loss: 1.0304 - val_loss: 1.1931\n",
      "Epoch 26/100\n",
      "705/705 [==============================] - 0s 274us/sample - loss: 1.0322 - val_loss: 1.1954\n",
      "Epoch 27/100\n",
      "705/705 [==============================] - 0s 293us/sample - loss: 1.0264 - val_loss: 1.1916\n",
      "Train on 705 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "705/705 [==============================] - 1s 2ms/sample - loss: 0.8083 - val_loss: 0.7645\n",
      "Epoch 2/100\n",
      "705/705 [==============================] - 0s 284us/sample - loss: 0.7690 - val_loss: 0.7631\n",
      "Epoch 3/100\n",
      "705/705 [==============================] - 0s 310us/sample - loss: 0.7695 - val_loss: 0.7658\n",
      "Epoch 4/100\n",
      "705/705 [==============================] - 0s 256us/sample - loss: 0.7687 - val_loss: 0.7627\n",
      "Epoch 5/100\n",
      "705/705 [==============================] - 0s 246us/sample - loss: 0.7694 - val_loss: 0.7645\n",
      "Epoch 6/100\n",
      "705/705 [==============================] - 0s 243us/sample - loss: 0.7689 - val_loss: 0.7635\n",
      "Epoch 7/100\n",
      "705/705 [==============================] - 0s 307us/sample - loss: 0.7686 - val_loss: 0.7628\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 0s 274us/sample - loss: 0.7685 - val_loss: 0.7640\n",
      "Epoch 9/100\n",
      "705/705 [==============================] - 0s 280us/sample - loss: 0.7684 - val_loss: 0.7627\n",
      "Epoch 10/100\n",
      "705/705 [==============================] - 0s 260us/sample - loss: 0.7698 - val_loss: 0.7632\n",
      "Epoch 11/100\n",
      "705/705 [==============================] - 0s 289us/sample - loss: 0.7683 - val_loss: 0.7640\n",
      "Epoch 12/100\n",
      "705/705 [==============================] - 0s 270us/sample - loss: 0.7689 - val_loss: 0.7641\n",
      "Epoch 13/100\n",
      "705/705 [==============================] - 0s 341us/sample - loss: 0.7688 - val_loss: 0.7642\n",
      "Epoch 14/100\n",
      "705/705 [==============================] - 0s 249us/sample - loss: 0.7696 - val_loss: 0.7648\n",
      "Epoch 15/100\n",
      "705/705 [==============================] - 0s 262us/sample - loss: 0.7695 - val_loss: 0.7633\n",
      "Epoch 16/100\n",
      "705/705 [==============================] - 0s 306us/sample - loss: 0.7698 - val_loss: 0.7632\n",
      "Epoch 17/100\n",
      "705/705 [==============================] - 0s 255us/sample - loss: 0.7691 - val_loss: 0.7640\n",
      "Epoch 18/100\n",
      "705/705 [==============================] - 0s 283us/sample - loss: 0.7686 - val_loss: 0.7643\n",
      "Epoch 19/100\n",
      "705/705 [==============================] - 0s 259us/sample - loss: 0.7687 - val_loss: 0.7630\n",
      "Train on 705 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "705/705 [==============================] - 1s 1ms/sample - loss: 0.8564 - val_loss: 0.8137\n",
      "Epoch 2/100\n",
      "705/705 [==============================] - 0s 298us/sample - loss: 0.7878 - val_loss: 0.8069\n",
      "Epoch 3/100\n",
      "705/705 [==============================] - 0s 246us/sample - loss: 0.7842 - val_loss: 0.8061\n",
      "Epoch 4/100\n",
      "705/705 [==============================] - 0s 263us/sample - loss: 0.7824 - val_loss: 0.8048\n",
      "Epoch 5/100\n",
      "705/705 [==============================] - 0s 269us/sample - loss: 0.7817 - val_loss: 0.8042\n",
      "Epoch 6/100\n",
      "705/705 [==============================] - 0s 246us/sample - loss: 0.7808 - val_loss: 0.8050\n",
      "Epoch 7/100\n",
      "705/705 [==============================] - 0s 293us/sample - loss: 0.7816 - val_loss: 0.8049\n",
      "Epoch 8/100\n",
      "705/705 [==============================] - 0s 270us/sample - loss: 0.7810 - val_loss: 0.8046\n",
      "Epoch 9/100\n",
      "705/705 [==============================] - 0s 246us/sample - loss: 0.7807 - val_loss: 0.8040\n",
      "Epoch 10/100\n",
      "705/705 [==============================] - 0s 252us/sample - loss: 0.7798 - val_loss: 0.8043\n",
      "Epoch 11/100\n",
      "705/705 [==============================] - 0s 243us/sample - loss: 0.7799 - val_loss: 0.8048\n",
      "Epoch 12/100\n",
      "705/705 [==============================] - 0s 232us/sample - loss: 0.7810 - val_loss: 0.8050\n",
      "Epoch 13/100\n",
      "705/705 [==============================] - 0s 239us/sample - loss: 0.7805 - val_loss: 0.8052\n",
      "Epoch 14/100\n",
      "705/705 [==============================] - 0s 222us/sample - loss: 0.7796 - val_loss: 0.8055\n",
      "Epoch 15/100\n",
      "705/705 [==============================] - 0s 232us/sample - loss: 0.7804 - val_loss: 0.8057\n",
      "Epoch 16/100\n",
      "705/705 [==============================] - 0s 262us/sample - loss: 0.7798 - val_loss: 0.8047\n",
      "Epoch 17/100\n",
      "705/705 [==============================] - 0s 272us/sample - loss: 0.7802 - val_loss: 0.8051\n",
      "Epoch 18/100\n",
      "705/705 [==============================] - 0s 263us/sample - loss: 0.7794 - val_loss: 0.8051\n",
      "Epoch 19/100\n",
      "705/705 [==============================] - 0s 263us/sample - loss: 0.7791 - val_loss: 0.8043\n",
      "Train on 705 samples, validate on 176 samples\n",
      "Epoch 1/100\n",
      "705/705 [==============================] - 1s 1ms/sample - loss: 1.3322 - val_loss: 1.1987\n",
      "Epoch 2/100\n",
      "705/705 [==============================] - 0s 279us/sample - loss: 1.1817 - val_loss: 1.1443\n",
      "Epoch 3/100\n",
      "705/705 [==============================] - 0s 341us/sample - loss: 1.1464 - val_loss: 1.1275\n",
      "Epoch 4/100\n",
      "705/705 [==============================] - 0s 286us/sample - loss: 1.1337 - val_loss: 1.1227\n",
      "Epoch 5/100\n",
      "705/705 [==============================] - 0s 324us/sample - loss: 1.1246 - val_loss: 1.1224\n",
      "Epoch 6/100\n",
      "705/705 [==============================] - 0s 273us/sample - loss: 1.1191 - val_loss: 1.1218\n",
      "Epoch 7/100\n",
      "705/705 [==============================] - 0s 298us/sample - loss: 1.1123 - val_loss: 1.1187\n",
      "Epoch 8/100\n",
      "705/705 [==============================] - 0s 266us/sample - loss: 1.1065 - val_loss: 1.1219\n",
      "Epoch 9/100\n",
      "705/705 [==============================] - 0s 270us/sample - loss: 1.1025 - val_loss: 1.1196\n",
      "Epoch 10/100\n",
      "705/705 [==============================] - 0s 263us/sample - loss: 1.0966 - val_loss: 1.1217\n",
      "Epoch 11/100\n",
      "705/705 [==============================] - 0s 276us/sample - loss: 1.0920 - val_loss: 1.1179\n",
      "Epoch 12/100\n",
      "705/705 [==============================] - 0s 260us/sample - loss: 1.0865 - val_loss: 1.1186\n",
      "Epoch 13/100\n",
      "705/705 [==============================] - 0s 267us/sample - loss: 1.0828 - val_loss: 1.1203\n",
      "Epoch 14/100\n",
      "705/705 [==============================] - 0s 263us/sample - loss: 1.0797 - val_loss: 1.1175\n",
      "Epoch 15/100\n",
      "705/705 [==============================] - 0s 253us/sample - loss: 1.0765 - val_loss: 1.1199\n",
      "Epoch 16/100\n",
      "705/705 [==============================] - 0s 255us/sample - loss: 1.0720 - val_loss: 1.1164\n",
      "Epoch 17/100\n",
      "705/705 [==============================] - 0s 282us/sample - loss: 1.0673 - val_loss: 1.1192\n",
      "Epoch 18/100\n",
      "705/705 [==============================] - 0s 270us/sample - loss: 1.0644 - val_loss: 1.1171\n",
      "Epoch 19/100\n",
      "705/705 [==============================] - 0s 269us/sample - loss: 1.0645 - val_loss: 1.1216\n",
      "Epoch 20/100\n",
      "705/705 [==============================] - 0s 269us/sample - loss: 1.0581 - val_loss: 1.1142\n",
      "Epoch 21/100\n",
      "705/705 [==============================] - 0s 277us/sample - loss: 1.0540 - val_loss: 1.1162\n",
      "Epoch 22/100\n",
      "705/705 [==============================] - 0s 297us/sample - loss: 1.0521 - val_loss: 1.1171\n",
      "Epoch 23/100\n",
      "705/705 [==============================] - 0s 298us/sample - loss: 1.0478 - val_loss: 1.1183\n",
      "Epoch 24/100\n",
      "705/705 [==============================] - 0s 260us/sample - loss: 1.0447 - val_loss: 1.1144\n",
      "Epoch 25/100\n",
      "705/705 [==============================] - 0s 287us/sample - loss: 1.0410 - val_loss: 1.1138\n",
      "Epoch 26/100\n",
      "705/705 [==============================] - 0s 249us/sample - loss: 1.0519 - val_loss: 1.1153\n",
      "Epoch 27/100\n",
      "705/705 [==============================] - 0s 260us/sample - loss: 1.0376 - val_loss: 1.1182\n",
      "Epoch 28/100\n",
      "705/705 [==============================] - 0s 364us/sample - loss: 1.0339 - val_loss: 1.1164\n",
      "Epoch 29/100\n",
      "705/705 [==============================] - 0s 263us/sample - loss: 1.0299 - val_loss: 1.1174\n",
      "Epoch 30/100\n",
      "705/705 [==============================] - 0s 260us/sample - loss: 1.0280 - val_loss: 1.1169\n",
      "Epoch 31/100\n",
      "705/705 [==============================] - 0s 249us/sample - loss: 1.0264 - val_loss: 1.1140\n",
      "Epoch 32/100\n",
      "705/705 [==============================] - 0s 274us/sample - loss: 1.0238 - val_loss: 1.1173\n",
      "Epoch 33/100\n",
      "705/705 [==============================] - 0s 274us/sample - loss: 1.0198 - val_loss: 1.1154\n",
      "Epoch 34/100\n",
      "705/705 [==============================] - 0s 290us/sample - loss: 1.0173 - val_loss: 1.1162\n",
      "Epoch 35/100\n",
      "705/705 [==============================] - 0s 300us/sample - loss: 1.0141 - val_loss: 1.1153\n",
      "Train on 705 samples, validate on 175 samples\n",
      "Epoch 1/100\n",
      "705/705 [==============================] - 1s 1ms/sample - loss: 0.8376 - val_loss: 0.8165\n",
      "Epoch 2/100\n",
      "705/705 [==============================] - 0s 250us/sample - loss: 0.7371 - val_loss: 0.8109\n",
      "Epoch 3/100\n",
      "705/705 [==============================] - 0s 257us/sample - loss: 0.7381 - val_loss: 0.8104\n",
      "Epoch 4/100\n",
      "705/705 [==============================] - 0s 265us/sample - loss: 0.7375 - val_loss: 0.8106\n",
      "Epoch 5/100\n",
      "705/705 [==============================] - 0s 274us/sample - loss: 0.7368 - val_loss: 0.8103\n",
      "Epoch 6/100\n",
      "705/705 [==============================] - 0s 252us/sample - loss: 0.7370 - val_loss: 0.8105\n",
      "Epoch 7/100\n",
      "705/705 [==============================] - 0s 267us/sample - loss: 0.7375 - val_loss: 0.8101\n",
      "Epoch 8/100\n",
      "705/705 [==============================] - 0s 267us/sample - loss: 0.7384 - val_loss: 0.8105\n",
      "Epoch 9/100\n",
      "705/705 [==============================] - 0s 266us/sample - loss: 0.7367 - val_loss: 0.8119\n",
      "Epoch 10/100\n",
      "705/705 [==============================] - 0s 262us/sample - loss: 0.7379 - val_loss: 0.8118\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 0s 253us/sample - loss: 0.7376 - val_loss: 0.8101\n",
      "Epoch 12/100\n",
      "705/705 [==============================] - 0s 273us/sample - loss: 0.7378 - val_loss: 0.8111\n",
      "Epoch 13/100\n",
      "705/705 [==============================] - 0s 286us/sample - loss: 0.7371 - val_loss: 0.8099\n",
      "Epoch 14/100\n",
      "705/705 [==============================] - 0s 291us/sample - loss: 0.7372 - val_loss: 0.8101\n",
      "Epoch 15/100\n",
      "705/705 [==============================] - 0s 286us/sample - loss: 0.7372 - val_loss: 0.8113\n",
      "Epoch 16/100\n",
      "705/705 [==============================] - 0s 260us/sample - loss: 0.7373 - val_loss: 0.8113\n",
      "Epoch 17/100\n",
      "705/705 [==============================] - 0s 259us/sample - loss: 0.7368 - val_loss: 0.8109\n",
      "Epoch 18/100\n",
      "705/705 [==============================] - 0s 252us/sample - loss: 0.7378 - val_loss: 0.8107\n",
      "Epoch 19/100\n",
      "705/705 [==============================] - 0s 253us/sample - loss: 0.7377 - val_loss: 0.8099\n",
      "Epoch 20/100\n",
      "705/705 [==============================] - 0s 282us/sample - loss: 0.7372 - val_loss: 0.8108\n",
      "Epoch 21/100\n",
      "705/705 [==============================] - 0s 280us/sample - loss: 0.7374 - val_loss: 0.8111\n",
      "Epoch 22/100\n",
      "705/705 [==============================] - 0s 334us/sample - loss: 0.7372 - val_loss: 0.8104\n",
      "Epoch 23/100\n",
      "705/705 [==============================] - 0s 290us/sample - loss: 0.7379 - val_loss: 0.8111\n",
      "Train on 705 samples, validate on 175 samples\n",
      "Epoch 1/100\n",
      "705/705 [==============================] - 1s 1ms/sample - loss: 0.8594 - val_loss: 0.8254\n",
      "Epoch 2/100\n",
      "705/705 [==============================] - 0s 257us/sample - loss: 0.8049 - val_loss: 0.8179\n",
      "Epoch 3/100\n",
      "705/705 [==============================] - 0s 293us/sample - loss: 0.7999 - val_loss: 0.8150\n",
      "Epoch 4/100\n",
      "705/705 [==============================] - 0s 262us/sample - loss: 0.7973 - val_loss: 0.8128\n",
      "Epoch 5/100\n",
      "705/705 [==============================] - 0s 262us/sample - loss: 0.7962 - val_loss: 0.8126\n",
      "Epoch 6/100\n",
      "705/705 [==============================] - 0s 262us/sample - loss: 0.7946 - val_loss: 0.8109\n",
      "Epoch 7/100\n",
      "705/705 [==============================] - 0s 263us/sample - loss: 0.7942 - val_loss: 0.8113\n",
      "Epoch 8/100\n",
      "705/705 [==============================] - 0s 284us/sample - loss: 0.7942 - val_loss: 0.8123\n",
      "Epoch 9/100\n",
      "705/705 [==============================] - 0s 262us/sample - loss: 0.7933 - val_loss: 0.8115\n",
      "Epoch 10/100\n",
      "705/705 [==============================] - 0s 262us/sample - loss: 0.7936 - val_loss: 0.8115\n",
      "Epoch 11/100\n",
      "705/705 [==============================] - 0s 286us/sample - loss: 0.7937 - val_loss: 0.8118\n",
      "Epoch 12/100\n",
      "705/705 [==============================] - 0s 265us/sample - loss: 0.7941 - val_loss: 0.8118\n",
      "Epoch 13/100\n",
      "705/705 [==============================] - 0s 294us/sample - loss: 0.7931 - val_loss: 0.8117\n",
      "Epoch 14/100\n",
      "705/705 [==============================] - 0s 291us/sample - loss: 0.7925 - val_loss: 0.8119\n",
      "Epoch 15/100\n",
      "705/705 [==============================] - 0s 269us/sample - loss: 0.7928 - val_loss: 0.8119\n",
      "Epoch 16/100\n",
      "705/705 [==============================] - 0s 266us/sample - loss: 0.7924 - val_loss: 0.8128\n",
      "Train on 706 samples, validate on 177 samples\n",
      "Epoch 1/100\n",
      "706/706 [==============================] - 1s 2ms/sample - loss: 1.3263 - val_loss: 1.1733\n",
      "Epoch 2/100\n",
      "706/706 [==============================] - 0s 247us/sample - loss: 1.1849 - val_loss: 1.1498\n",
      "Epoch 3/100\n",
      "706/706 [==============================] - 0s 280us/sample - loss: 1.1507 - val_loss: 1.1537\n",
      "Epoch 4/100\n",
      "706/706 [==============================] - 0s 267us/sample - loss: 1.1371 - val_loss: 1.1626\n",
      "Epoch 5/100\n",
      "706/706 [==============================] - 0s 263us/sample - loss: 1.1263 - val_loss: 1.1641\n",
      "Epoch 6/100\n",
      "706/706 [==============================] - 0s 285us/sample - loss: 1.1196 - val_loss: 1.1673\n",
      "Epoch 7/100\n",
      "706/706 [==============================] - 0s 264us/sample - loss: 1.1139 - val_loss: 1.1798\n",
      "Epoch 8/100\n",
      "706/706 [==============================] - 0s 270us/sample - loss: 1.1102 - val_loss: 1.1757\n",
      "Epoch 9/100\n",
      "706/706 [==============================] - 0s 278us/sample - loss: 1.1045 - val_loss: 1.1781\n",
      "Epoch 10/100\n",
      "706/706 [==============================] - 0s 261us/sample - loss: 1.0987 - val_loss: 1.1740\n",
      "Epoch 11/100\n",
      "706/706 [==============================] - 0s 281us/sample - loss: 1.0964 - val_loss: 1.1739\n",
      "Epoch 12/100\n",
      "706/706 [==============================] - 0s 280us/sample - loss: 1.0924 - val_loss: 1.1801\n",
      "Train on 705 samples, validate on 175 samples\n",
      "Epoch 1/100\n",
      "705/705 [==============================] - 1s 1ms/sample - loss: 0.8179 - val_loss: 0.6901\n",
      "Epoch 2/100\n",
      "705/705 [==============================] - 0s 250us/sample - loss: 0.7752 - val_loss: 0.6885\n",
      "Epoch 3/100\n",
      "705/705 [==============================] - 0s 276us/sample - loss: 0.7755 - val_loss: 0.6896\n",
      "Epoch 4/100\n",
      "705/705 [==============================] - 0s 267us/sample - loss: 0.7754 - val_loss: 0.6897\n",
      "Epoch 5/100\n",
      "705/705 [==============================] - 0s 267us/sample - loss: 0.7762 - val_loss: 0.6916\n",
      "Epoch 6/100\n",
      "705/705 [==============================] - 0s 272us/sample - loss: 0.7750 - val_loss: 0.6923\n",
      "Epoch 7/100\n",
      "705/705 [==============================] - 0s 283us/sample - loss: 0.7759 - val_loss: 0.6922\n",
      "Epoch 8/100\n",
      "705/705 [==============================] - 0s 257us/sample - loss: 0.7755 - val_loss: 0.6924\n",
      "Epoch 9/100\n",
      "705/705 [==============================] - 0s 276us/sample - loss: 0.7748 - val_loss: 0.6884\n",
      "Epoch 10/100\n",
      "705/705 [==============================] - 0s 286us/sample - loss: 0.7760 - val_loss: 0.6904\n",
      "Epoch 11/100\n",
      "705/705 [==============================] - 0s 266us/sample - loss: 0.7753 - val_loss: 0.6897\n",
      "Epoch 12/100\n",
      "705/705 [==============================] - 0s 277us/sample - loss: 0.7750 - val_loss: 0.6911\n",
      "Epoch 13/100\n",
      "705/705 [==============================] - 0s 273us/sample - loss: 0.7749 - val_loss: 0.6895\n",
      "Epoch 14/100\n",
      "705/705 [==============================] - 0s 265us/sample - loss: 0.7756 - val_loss: 0.6898\n",
      "Epoch 15/100\n",
      "705/705 [==============================] - 0s 284us/sample - loss: 0.7759 - val_loss: 0.6918\n",
      "Epoch 16/100\n",
      "705/705 [==============================] - 0s 269us/sample - loss: 0.7757 - val_loss: 0.6903\n",
      "Epoch 17/100\n",
      "705/705 [==============================] - 0s 289us/sample - loss: 0.7746 - val_loss: 0.6901\n",
      "Epoch 18/100\n",
      "705/705 [==============================] - 0s 270us/sample - loss: 0.7753 - val_loss: 0.6907\n",
      "Epoch 19/100\n",
      "705/705 [==============================] - 0s 267us/sample - loss: 0.7749 - val_loss: 0.6905\n",
      "Train on 705 samples, validate on 175 samples\n",
      "Epoch 1/100\n",
      "705/705 [==============================] - 1s 1ms/sample - loss: 0.8996 - val_loss: 0.8155\n",
      "Epoch 2/100\n",
      "705/705 [==============================] - 0s 274us/sample - loss: 0.8063 - val_loss: 0.8121\n",
      "Epoch 3/100\n",
      "705/705 [==============================] - 0s 296us/sample - loss: 0.8007 - val_loss: 0.8130\n",
      "Epoch 4/100\n",
      "705/705 [==============================] - 0s 313us/sample - loss: 0.7976 - val_loss: 0.8140\n",
      "Epoch 5/100\n",
      "705/705 [==============================] - 0s 372us/sample - loss: 0.7953 - val_loss: 0.8128\n",
      "Epoch 6/100\n",
      "705/705 [==============================] - 0s 255us/sample - loss: 0.7947 - val_loss: 0.8155\n",
      "Epoch 7/100\n",
      "705/705 [==============================] - 0s 239us/sample - loss: 0.7951 - val_loss: 0.8132\n",
      "Epoch 8/100\n",
      "705/705 [==============================] - 0s 291us/sample - loss: 0.7936 - val_loss: 0.8161\n",
      "Epoch 9/100\n",
      "705/705 [==============================] - 0s 250us/sample - loss: 0.7932 - val_loss: 0.8188\n",
      "Epoch 10/100\n",
      "705/705 [==============================] - 0s 280us/sample - loss: 0.7926 - val_loss: 0.8201\n",
      "Epoch 11/100\n",
      "705/705 [==============================] - 0s 262us/sample - loss: 0.7934 - val_loss: 0.8194\n",
      "Epoch 12/100\n",
      "705/705 [==============================] - 0s 296us/sample - loss: 0.7925 - val_loss: 0.8157\n",
      "Train on 706 samples, validate on 177 samples\n",
      "Epoch 1/100\n",
      "706/706 [==============================] - 1s 2ms/sample - loss: 1.3119 - val_loss: 1.1486\n",
      "Epoch 2/100\n",
      "706/706 [==============================] - 0s 225us/sample - loss: 1.1852 - val_loss: 1.1150\n",
      "Epoch 3/100\n",
      "706/706 [==============================] - 0s 243us/sample - loss: 1.1515 - val_loss: 1.0996\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 0s 261us/sample - loss: 1.1391 - val_loss: 1.0922\n",
      "Epoch 5/100\n",
      "706/706 [==============================] - 0s 301us/sample - loss: 1.1292 - val_loss: 1.0894\n",
      "Epoch 6/100\n",
      "706/706 [==============================] - 0s 253us/sample - loss: 1.1213 - val_loss: 1.0865\n",
      "Epoch 7/100\n",
      "706/706 [==============================] - 0s 259us/sample - loss: 1.1159 - val_loss: 1.0844\n",
      "Epoch 8/100\n",
      "706/706 [==============================] - 0s 259us/sample - loss: 1.1113 - val_loss: 1.0831\n",
      "Epoch 9/100\n",
      "706/706 [==============================] - 0s 285us/sample - loss: 1.1065 - val_loss: 1.0823\n",
      "Epoch 10/100\n",
      "706/706 [==============================] - 0s 254us/sample - loss: 1.1025 - val_loss: 1.0819\n",
      "Epoch 11/100\n",
      "706/706 [==============================] - 0s 254us/sample - loss: 1.0991 - val_loss: 1.0806\n",
      "Epoch 12/100\n",
      "706/706 [==============================] - 0s 305us/sample - loss: 1.0950 - val_loss: 1.0809\n",
      "Epoch 13/100\n",
      "706/706 [==============================] - 0s 297us/sample - loss: 1.0919 - val_loss: 1.0797\n",
      "Epoch 14/100\n",
      "706/706 [==============================] - 0s 329us/sample - loss: 1.0878 - val_loss: 1.0797\n",
      "Epoch 15/100\n",
      "706/706 [==============================] - 0s 277us/sample - loss: 1.0844 - val_loss: 1.0787\n",
      "Epoch 16/100\n",
      "706/706 [==============================] - 0s 291us/sample - loss: 1.0824 - val_loss: 1.0787\n",
      "Epoch 17/100\n",
      "706/706 [==============================] - 0s 348us/sample - loss: 1.0785 - val_loss: 1.0783\n",
      "Epoch 18/100\n",
      "706/706 [==============================] - 0s 302us/sample - loss: 1.0772 - val_loss: 1.0789\n",
      "Epoch 19/100\n",
      "706/706 [==============================] - 0s 331us/sample - loss: 1.0727 - val_loss: 1.0777\n",
      "Epoch 20/100\n",
      "706/706 [==============================] - 0s 259us/sample - loss: 1.0695 - val_loss: 1.0778\n",
      "Epoch 21/100\n",
      "706/706 [==============================] - 0s 250us/sample - loss: 1.0666 - val_loss: 1.0773\n",
      "Epoch 22/100\n",
      "706/706 [==============================] - 0s 253us/sample - loss: 1.0645 - val_loss: 1.0767\n",
      "Epoch 23/100\n",
      "706/706 [==============================] - 0s 256us/sample - loss: 1.0610 - val_loss: 1.0762\n",
      "Epoch 24/100\n",
      "706/706 [==============================] - 0s 261us/sample - loss: 1.0586 - val_loss: 1.0757\n",
      "Epoch 25/100\n",
      "706/706 [==============================] - 0s 253us/sample - loss: 1.0546 - val_loss: 1.0747\n",
      "Epoch 26/100\n",
      "706/706 [==============================] - ETA: 0s - loss: 1.083 - 0s 256us/sample - loss: 1.0540 - val_loss: 1.0741\n",
      "Epoch 27/100\n",
      "706/706 [==============================] - 0s 264us/sample - loss: 1.0516 - val_loss: 1.0750\n",
      "Epoch 28/100\n",
      "706/706 [==============================] - 0s 253us/sample - loss: 1.0484 - val_loss: 1.0746\n",
      "Epoch 29/100\n",
      "706/706 [==============================] - 0s 257us/sample - loss: 1.0448 - val_loss: 1.0728\n",
      "Epoch 30/100\n",
      "706/706 [==============================] - 0s 254us/sample - loss: 1.0410 - val_loss: 1.0739\n",
      "Epoch 31/100\n",
      "706/706 [==============================] - 0s 256us/sample - loss: 1.0399 - val_loss: 1.0747\n",
      "Epoch 32/100\n",
      "706/706 [==============================] - 0s 253us/sample - loss: 1.0367 - val_loss: 1.0736\n",
      "Epoch 33/100\n",
      "706/706 [==============================] - 0s 251us/sample - loss: 1.0334 - val_loss: 1.0734\n",
      "Epoch 34/100\n",
      "706/706 [==============================] - 0s 250us/sample - loss: 1.0296 - val_loss: 1.0740\n",
      "Epoch 35/100\n",
      "706/706 [==============================] - 0s 261us/sample - loss: 1.0275 - val_loss: 1.0723\n",
      "Epoch 36/100\n",
      "706/706 [==============================] - 0s 249us/sample - loss: 1.0247 - val_loss: 1.0714\n",
      "Epoch 37/100\n",
      "706/706 [==============================] - 0s 251us/sample - loss: 1.0227 - val_loss: 1.0717\n",
      "Epoch 38/100\n",
      "706/706 [==============================] - 0s 263us/sample - loss: 1.0199 - val_loss: 1.0710\n",
      "Epoch 39/100\n",
      "706/706 [==============================] - 0s 254us/sample - loss: 1.0160 - val_loss: 1.0713\n",
      "Epoch 40/100\n",
      "706/706 [==============================] - 0s 257us/sample - loss: 1.0131 - val_loss: 1.0697\n",
      "Epoch 41/100\n",
      "706/706 [==============================] - 0s 254us/sample - loss: 1.0108 - val_loss: 1.0721\n",
      "Epoch 42/100\n",
      "706/706 [==============================] - 0s 254us/sample - loss: 1.0081 - val_loss: 1.0696\n",
      "Epoch 43/100\n",
      "706/706 [==============================] - 0s 254us/sample - loss: 1.0083 - val_loss: 1.0725\n",
      "Epoch 44/100\n",
      "706/706 [==============================] - 0s 254us/sample - loss: 1.0055 - val_loss: 1.0713\n",
      "Epoch 45/100\n",
      "706/706 [==============================] - 0s 253us/sample - loss: 1.0005 - val_loss: 1.0710\n",
      "Epoch 46/100\n",
      "706/706 [==============================] - 0s 256us/sample - loss: 0.9983 - val_loss: 1.0716\n",
      "Epoch 47/100\n",
      "706/706 [==============================] - 0s 254us/sample - loss: 0.9947 - val_loss: 1.0712\n",
      "Epoch 48/100\n",
      "706/706 [==============================] - 0s 261us/sample - loss: 0.9934 - val_loss: 1.0712\n",
      "Epoch 49/100\n",
      "706/706 [==============================] - 0s 251us/sample - loss: 0.9900 - val_loss: 1.0716\n",
      "Epoch 50/100\n",
      "706/706 [==============================] - 0s 250us/sample - loss: 0.9902 - val_loss: 1.0716\n",
      "Epoch 51/100\n",
      "706/706 [==============================] - 0s 257us/sample - loss: 0.9851 - val_loss: 1.0686\n",
      "Epoch 52/100\n",
      "706/706 [==============================] - 0s 257us/sample - loss: 0.9842 - val_loss: 1.0714\n",
      "Epoch 53/100\n",
      "706/706 [==============================] - 0s 253us/sample - loss: 0.9816 - val_loss: 1.0705\n",
      "Epoch 54/100\n",
      "706/706 [==============================] - 0s 259us/sample - loss: 0.9773 - val_loss: 1.0714\n",
      "Epoch 55/100\n",
      "706/706 [==============================] - 0s 256us/sample - loss: 0.9754 - val_loss: 1.0716\n",
      "Epoch 56/100\n",
      "706/706 [==============================] - 0s 266us/sample - loss: 0.9714 - val_loss: 1.0710\n",
      "Epoch 57/100\n",
      "706/706 [==============================] - 0s 253us/sample - loss: 0.9720 - val_loss: 1.0707\n",
      "Epoch 58/100\n",
      "706/706 [==============================] - 0s 256us/sample - loss: 0.9675 - val_loss: 1.0691\n",
      "Epoch 59/100\n",
      "706/706 [==============================] - 0s 259us/sample - loss: 0.9666 - val_loss: 1.0707\n",
      "Epoch 60/100\n",
      "706/706 [==============================] - 0s 257us/sample - loss: 0.9630 - val_loss: 1.0718\n",
      "Epoch 61/100\n",
      "706/706 [==============================] - 0s 264us/sample - loss: 0.9744 - val_loss: 1.0710\n",
      "Train on 1370 samples, validate on 343 samples\n",
      "Epoch 1/100\n",
      "1370/1370 [==============================] - 1s 717us/sample - loss: 0.4149 - val_loss: 0.4132\n",
      "Epoch 2/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3952 - val_loss: 0.4097\n",
      "Epoch 3/100\n",
      "1370/1370 [==============================] - 0s 226us/sample - loss: 0.3915 - val_loss: 0.4080\n",
      "Epoch 4/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3880 - val_loss: 0.4061\n",
      "Epoch 5/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3863 - val_loss: 0.4075\n",
      "Epoch 6/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3840 - val_loss: 0.4060\n",
      "Epoch 7/100\n",
      "1370/1370 [==============================] - 0s 222us/sample - loss: 0.3823 - val_loss: 0.4056\n",
      "Epoch 8/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3802 - val_loss: 0.4085\n",
      "Epoch 9/100\n",
      "1370/1370 [==============================] - 0s 222us/sample - loss: 0.3791 - val_loss: 0.4043\n",
      "Epoch 10/100\n",
      "1370/1370 [==============================] - 0s 219us/sample - loss: 0.3767 - val_loss: 0.4033\n",
      "Epoch 11/100\n",
      "1370/1370 [==============================] - 0s 219us/sample - loss: 0.3749 - val_loss: 0.4074\n",
      "Epoch 12/100\n",
      "1370/1370 [==============================] - 0s 219us/sample - loss: 0.3744 - val_loss: 0.4037\n",
      "Epoch 13/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3730 - val_loss: 0.4037\n",
      "Epoch 14/100\n",
      "1370/1370 [==============================] - 0s 222us/sample - loss: 0.3714 - val_loss: 0.4052\n",
      "Epoch 15/100\n",
      "1370/1370 [==============================] - 0s 219us/sample - loss: 0.3702 - val_loss: 0.4054\n",
      "Epoch 16/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3689 - val_loss: 0.4041\n",
      "Epoch 17/100\n",
      "1370/1370 [==============================] - 0s 222us/sample - loss: 0.3675 - val_loss: 0.4046\n",
      "Epoch 18/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3663 - val_loss: 0.4036\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1370/1370 [==============================] - 0s 222us/sample - loss: 0.3660 - val_loss: 0.4039\n",
      "Epoch 20/100\n",
      "1370/1370 [==============================] - 0s 219us/sample - loss: 0.3640 - val_loss: 0.4032\n",
      "Epoch 21/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.3628 - val_loss: 0.4031\n",
      "Epoch 22/100\n",
      "1370/1370 [==============================] - 0s 215us/sample - loss: 0.3620 - val_loss: 0.4042\n",
      "Epoch 23/100\n",
      "1370/1370 [==============================] - 0s 218us/sample - loss: 0.3614 - val_loss: 0.4033\n",
      "Epoch 24/100\n",
      "1370/1370 [==============================] - 0s 219us/sample - loss: 0.3606 - val_loss: 0.4022\n",
      "Epoch 25/100\n",
      "1370/1370 [==============================] - 0s 219us/sample - loss: 0.3583 - val_loss: 0.4037\n",
      "Epoch 26/100\n",
      "1370/1370 [==============================] - 0s 225us/sample - loss: 0.3584 - val_loss: 0.4037\n",
      "Epoch 27/100\n",
      "1370/1370 [==============================] - 0s 218us/sample - loss: 0.3572 - val_loss: 0.4034\n",
      "Epoch 28/100\n",
      "1370/1370 [==============================] - 0s 226us/sample - loss: 0.3560 - val_loss: 0.4058\n",
      "Epoch 29/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3547 - val_loss: 0.4055\n",
      "Epoch 30/100\n",
      "1370/1370 [==============================] - 0s 254us/sample - loss: 0.3542 - val_loss: 0.4066\n",
      "Epoch 31/100\n",
      "1370/1370 [==============================] - 0s 224us/sample - loss: 0.3528 - val_loss: 0.4046\n",
      "Epoch 32/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3527 - val_loss: 0.4037\n",
      "Epoch 33/100\n",
      "1370/1370 [==============================] - 0s 216us/sample - loss: 0.3513 - val_loss: 0.4055\n",
      "Epoch 34/100\n",
      "1370/1370 [==============================] - 0s 235us/sample - loss: 0.3504 - val_loss: 0.4052\n",
      "Train on 1370 samples, validate on 343 samples\n",
      "Epoch 1/100\n",
      "1370/1370 [==============================] - 1s 718us/sample - loss: 0.4744 - val_loss: 0.4211\n",
      "Epoch 2/100\n",
      "1370/1370 [==============================] - 0s 222us/sample - loss: 0.4418 - val_loss: 0.4141\n",
      "Epoch 3/100\n",
      "1370/1370 [==============================] - 0s 232us/sample - loss: 0.4324 - val_loss: 0.4125\n",
      "Epoch 4/100\n",
      "1370/1370 [==============================] - 0s 234us/sample - loss: 0.4257 - val_loss: 0.4130\n",
      "Epoch 5/100\n",
      "1370/1370 [==============================] - 0s 224us/sample - loss: 0.4207 - val_loss: 0.4125\n",
      "Epoch 6/100\n",
      "1370/1370 [==============================] - 0s 225us/sample - loss: 0.4162 - val_loss: 0.4127\n",
      "Epoch 7/100\n",
      "1370/1370 [==============================] - 0s 224us/sample - loss: 0.4117 - val_loss: 0.4121\n",
      "Epoch 8/100\n",
      "1370/1370 [==============================] - 0s 228us/sample - loss: 0.4075 - val_loss: 0.4120\n",
      "Epoch 9/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.4039 - val_loss: 0.4121\n",
      "Epoch 10/100\n",
      "1370/1370 [==============================] - 0s 224us/sample - loss: 0.4010 - val_loss: 0.4158\n",
      "Epoch 11/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.3972 - val_loss: 0.4133\n",
      "Epoch 12/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3937 - val_loss: 0.4129\n",
      "Epoch 13/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3905 - val_loss: 0.4133\n",
      "Epoch 14/100\n",
      "1370/1370 [==============================] - 0s 225us/sample - loss: 0.3869 - val_loss: 0.4128\n",
      "Epoch 15/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3835 - val_loss: 0.4138\n",
      "Epoch 16/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3805 - val_loss: 0.4148\n",
      "Epoch 17/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3774 - val_loss: 0.4150\n",
      "Epoch 18/100\n",
      "1370/1370 [==============================] - 0s 225us/sample - loss: 0.3741 - val_loss: 0.4152\n",
      "Train on 1371 samples, validate on 344 samples\n",
      "Epoch 1/100\n",
      "1371/1371 [==============================] - 1s 871us/sample - loss: 1.1161 - val_loss: 1.0086\n",
      "Epoch 2/100\n",
      "1371/1371 [==============================] - 0s 220us/sample - loss: 0.9913 - val_loss: 0.9931\n",
      "Epoch 3/100\n",
      "1371/1371 [==============================] - 0s 228us/sample - loss: 0.9643 - val_loss: 0.9878\n",
      "Epoch 4/100\n",
      "1371/1371 [==============================] - 0s 227us/sample - loss: 0.9492 - val_loss: 0.9809\n",
      "Epoch 5/100\n",
      "1371/1371 [==============================] - 0s 225us/sample - loss: 0.9352 - val_loss: 0.9797\n",
      "Epoch 6/100\n",
      "1371/1371 [==============================] - 0s 224us/sample - loss: 0.9269 - val_loss: 0.9804\n",
      "Epoch 7/100\n",
      "1371/1371 [==============================] - 0s 221us/sample - loss: 0.9195 - val_loss: 0.9790\n",
      "Epoch 8/100\n",
      "1371/1371 [==============================] - 0s 222us/sample - loss: 0.9114 - val_loss: 0.9787\n",
      "Epoch 9/100\n",
      "1371/1371 [==============================] - 0s 224us/sample - loss: 0.9033 - val_loss: 0.9793\n",
      "Epoch 10/100\n",
      "1371/1371 [==============================] - 0s 222us/sample - loss: 0.9000 - val_loss: 0.9788\n",
      "Epoch 11/100\n",
      "1371/1371 [==============================] - 0s 221us/sample - loss: 0.8916 - val_loss: 0.9824\n",
      "Epoch 12/100\n",
      "1371/1371 [==============================] - 0s 220us/sample - loss: 0.8860 - val_loss: 0.9813\n",
      "Epoch 13/100\n",
      "1371/1371 [==============================] - 0s 221us/sample - loss: 0.8781 - val_loss: 0.9806\n",
      "Epoch 14/100\n",
      "1371/1371 [==============================] - 0s 219us/sample - loss: 0.8727 - val_loss: 0.9819\n",
      "Epoch 15/100\n",
      "1371/1371 [==============================] - 0s 223us/sample - loss: 0.8687 - val_loss: 0.9841\n",
      "Epoch 16/100\n",
      "1371/1371 [==============================] - 0s 220us/sample - loss: 0.8649 - val_loss: 0.9802\n",
      "Epoch 17/100\n",
      "1371/1371 [==============================] - 0s 223us/sample - loss: 0.8565 - val_loss: 0.9771\n",
      "Epoch 18/100\n",
      "1371/1371 [==============================] - 0s 234us/sample - loss: 0.8512 - val_loss: 0.9802\n",
      "Epoch 19/100\n",
      "1371/1371 [==============================] - 0s 243us/sample - loss: 0.8484 - val_loss: 0.9802\n",
      "Epoch 20/100\n",
      "1371/1371 [==============================] - 0s 222us/sample - loss: 0.8432 - val_loss: 0.9804\n",
      "Epoch 21/100\n",
      "1371/1371 [==============================] - 0s 224us/sample - loss: 0.8345 - val_loss: 0.9807\n",
      "Epoch 22/100\n",
      "1371/1371 [==============================] - 0s 223us/sample - loss: 0.8316 - val_loss: 0.9812\n",
      "Epoch 23/100\n",
      "1371/1371 [==============================] - 0s 221us/sample - loss: 0.8247 - val_loss: 0.9841\n",
      "Epoch 24/100\n",
      "1371/1371 [==============================] - 0s 218us/sample - loss: 0.8213 - val_loss: 0.9832\n",
      "Epoch 25/100\n",
      "1371/1371 [==============================] - 0s 223us/sample - loss: 0.8168 - val_loss: 0.9809\n",
      "Epoch 26/100\n",
      "1371/1371 [==============================] - 0s 220us/sample - loss: 0.8097 - val_loss: 0.9838\n",
      "Epoch 27/100\n",
      "1371/1371 [==============================] - 0s 224us/sample - loss: 0.8056 - val_loss: 0.9852\n",
      "Train on 1370 samples, validate on 343 samples\n",
      "Epoch 1/100\n",
      "1370/1370 [==============================] - 1s 721us/sample - loss: 0.4321 - val_loss: 0.3808\n",
      "Epoch 2/100\n",
      "1370/1370 [==============================] - 0s 225us/sample - loss: 0.4019 - val_loss: 0.3751\n",
      "Epoch 3/100\n",
      "1370/1370 [==============================] - 0s 230us/sample - loss: 0.3961 - val_loss: 0.3737\n",
      "Epoch 4/100\n",
      "1370/1370 [==============================] - 0s 226us/sample - loss: 0.3927 - val_loss: 0.3737\n",
      "Epoch 5/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.3903 - val_loss: 0.3734\n",
      "Epoch 6/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.3888 - val_loss: 0.3739\n",
      "Epoch 7/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.3878 - val_loss: 0.3722\n",
      "Epoch 8/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3846 - val_loss: 0.3726\n",
      "Epoch 9/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.3840 - val_loss: 0.3738\n",
      "Epoch 10/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3823 - val_loss: 0.3713\n",
      "Epoch 11/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3808 - val_loss: 0.3738\n",
      "Epoch 12/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.3804 - val_loss: 0.3714\n",
      "Epoch 13/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.3786 - val_loss: 0.3715\n",
      "Epoch 14/100\n",
      "1370/1370 [==============================] - 0s 222us/sample - loss: 0.3776 - val_loss: 0.3728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "1370/1370 [==============================] - 0s 219us/sample - loss: 0.3764 - val_loss: 0.3724\n",
      "Epoch 16/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3750 - val_loss: 0.3730\n",
      "Epoch 17/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3743 - val_loss: 0.3720\n",
      "Epoch 18/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3725 - val_loss: 0.3735\n",
      "Epoch 19/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3722 - val_loss: 0.3720\n",
      "Epoch 20/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3702 - val_loss: 0.3741\n",
      "Train on 1370 samples, validate on 343 samples\n",
      "Epoch 1/100\n",
      "1370/1370 [==============================] - 1s 715us/sample - loss: 0.4849 - val_loss: 0.4618\n",
      "Epoch 2/100\n",
      "1370/1370 [==============================] - 0s 217us/sample - loss: 0.4391 - val_loss: 0.4529\n",
      "Epoch 3/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.4281 - val_loss: 0.4510\n",
      "Epoch 4/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.4207 - val_loss: 0.4493\n",
      "Epoch 5/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.4154 - val_loss: 0.4483\n",
      "Epoch 6/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.4106 - val_loss: 0.4484\n",
      "Epoch 7/100\n",
      "1370/1370 [==============================] - 0s 217us/sample - loss: 0.4065 - val_loss: 0.4482\n",
      "Epoch 8/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.4025 - val_loss: 0.4480\n",
      "Epoch 9/100\n",
      "1370/1370 [==============================] - 0s 219us/sample - loss: 0.3986 - val_loss: 0.4479\n",
      "Epoch 10/100\n",
      "1370/1370 [==============================] - 0s 215us/sample - loss: 0.3952 - val_loss: 0.4488\n",
      "Epoch 11/100\n",
      "1370/1370 [==============================] - 0s 217us/sample - loss: 0.3918 - val_loss: 0.4486\n",
      "Epoch 12/100\n",
      "1370/1370 [==============================] - 0s 218us/sample - loss: 0.3876 - val_loss: 0.4477\n",
      "Epoch 13/100\n",
      "1370/1370 [==============================] - 0s 218us/sample - loss: 0.3850 - val_loss: 0.4483\n",
      "Epoch 14/100\n",
      "1370/1370 [==============================] - 0s 216us/sample - loss: 0.3819 - val_loss: 0.4500\n",
      "Epoch 15/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3788 - val_loss: 0.4491\n",
      "Epoch 16/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3755 - val_loss: 0.4483\n",
      "Epoch 17/100\n",
      "1370/1370 [==============================] - 0s 218us/sample - loss: 0.3721 - val_loss: 0.4498\n",
      "Epoch 18/100\n",
      "1370/1370 [==============================] - 0s 217us/sample - loss: 0.3696 - val_loss: 0.4501\n",
      "Epoch 19/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.3666 - val_loss: 0.4502\n",
      "Epoch 20/100\n",
      "1370/1370 [==============================] - 0s 219us/sample - loss: 0.3636 - val_loss: 0.4508\n",
      "Epoch 21/100\n",
      "1370/1370 [==============================] - 0s 219us/sample - loss: 0.3615 - val_loss: 0.4502\n",
      "Epoch 22/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3583 - val_loss: 0.4504\n",
      "Train on 1372 samples, validate on 343 samples\n",
      "Epoch 1/100\n",
      "1372/1372 [==============================] - 1s 859us/sample - loss: 1.1559 - val_loss: 1.0372\n",
      "Epoch 2/100\n",
      "1372/1372 [==============================] - 0s 198us/sample - loss: 1.0002 - val_loss: 1.0021\n",
      "Epoch 3/100\n",
      "1372/1372 [==============================] - 0s 218us/sample - loss: 0.9702 - val_loss: 0.9912\n",
      "Epoch 4/100\n",
      "1372/1372 [==============================] - 0s 222us/sample - loss: 0.9543 - val_loss: 0.9906\n",
      "Epoch 5/100\n",
      "1372/1372 [==============================] - 0s 222us/sample - loss: 0.9427 - val_loss: 0.9896\n",
      "Epoch 6/100\n",
      "1372/1372 [==============================] - 0s 225us/sample - loss: 0.9339 - val_loss: 0.9803\n",
      "Epoch 7/100\n",
      "1372/1372 [==============================] - 0s 220us/sample - loss: 0.9230 - val_loss: 0.9819\n",
      "Epoch 8/100\n",
      "1372/1372 [==============================] - 0s 219us/sample - loss: 0.9151 - val_loss: 0.9825\n",
      "Epoch 9/100\n",
      "1372/1372 [==============================] - 0s 222us/sample - loss: 0.9084 - val_loss: 0.9778\n",
      "Epoch 10/100\n",
      "1372/1372 [==============================] - 0s 220us/sample - loss: 0.9005 - val_loss: 0.9792\n",
      "Epoch 11/100\n",
      "1372/1372 [==============================] - 0s 220us/sample - loss: 0.8928 - val_loss: 0.9827\n",
      "Epoch 12/100\n",
      "1372/1372 [==============================] - 0s 221us/sample - loss: 0.8884 - val_loss: 0.9920\n",
      "Epoch 13/100\n",
      "1372/1372 [==============================] - 0s 222us/sample - loss: 0.8834 - val_loss: 0.9803\n",
      "Epoch 14/100\n",
      "1372/1372 [==============================] - 0s 222us/sample - loss: 0.8751 - val_loss: 0.9843\n",
      "Epoch 15/100\n",
      "1372/1372 [==============================] - 0s 217us/sample - loss: 0.8682 - val_loss: 0.9780\n",
      "Epoch 16/100\n",
      "1372/1372 [==============================] - 0s 223us/sample - loss: 0.8638 - val_loss: 0.9822\n",
      "Epoch 17/100\n",
      "1372/1372 [==============================] - 0s 220us/sample - loss: 0.8584 - val_loss: 0.9837\n",
      "Epoch 18/100\n",
      "1372/1372 [==============================] - 0s 219us/sample - loss: 0.8521 - val_loss: 0.9895\n",
      "Epoch 19/100\n",
      "1372/1372 [==============================] - 0s 221us/sample - loss: 0.8475 - val_loss: 0.9822\n",
      "Train on 1370 samples, validate on 343 samples\n",
      "Epoch 1/100\n",
      "1370/1370 [==============================] - 1s 831us/sample - loss: 0.4247 - val_loss: 0.4025\n",
      "Epoch 2/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3984 - val_loss: 0.3976\n",
      "Epoch 3/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.3925 - val_loss: 0.3950\n",
      "Epoch 4/100\n",
      "1370/1370 [==============================] - 0s 222us/sample - loss: 0.3890 - val_loss: 0.3946\n",
      "Epoch 5/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3871 - val_loss: 0.3965\n",
      "Epoch 6/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3846 - val_loss: 0.3950\n",
      "Epoch 7/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3834 - val_loss: 0.3941\n",
      "Epoch 8/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3815 - val_loss: 0.3931\n",
      "Epoch 9/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3796 - val_loss: 0.3937\n",
      "Epoch 10/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3792 - val_loss: 0.3943\n",
      "Epoch 11/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3774 - val_loss: 0.3938\n",
      "Epoch 12/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.3761 - val_loss: 0.3945\n",
      "Epoch 13/100\n",
      "1370/1370 [==============================] - 0s 222us/sample - loss: 0.3744 - val_loss: 0.3956\n",
      "Epoch 14/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3745 - val_loss: 0.3934\n",
      "Epoch 15/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3720 - val_loss: 0.3939\n",
      "Epoch 16/100\n",
      "1370/1370 [==============================] - 0s 218us/sample - loss: 0.3713 - val_loss: 0.3960\n",
      "Epoch 17/100\n",
      "1370/1370 [==============================] - 0s 218us/sample - loss: 0.3704 - val_loss: 0.3981\n",
      "Epoch 18/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.3691 - val_loss: 0.3945\n",
      "Train on 1370 samples, validate on 343 samples\n",
      "Epoch 1/100\n",
      "1370/1370 [==============================] - 1s 711us/sample - loss: 0.4776 - val_loss: 0.4827\n",
      "Epoch 2/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.4316 - val_loss: 0.4724\n",
      "Epoch 3/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.4210 - val_loss: 0.4666\n",
      "Epoch 4/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.4144 - val_loss: 0.4652\n",
      "Epoch 5/100\n",
      "1370/1370 [==============================] - 0s 222us/sample - loss: 0.4090 - val_loss: 0.4650\n",
      "Epoch 6/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.4041 - val_loss: 0.4649\n",
      "Epoch 7/100\n",
      "1370/1370 [==============================] - 0s 223us/sample - loss: 0.4004 - val_loss: 0.4641\n",
      "Epoch 8/100\n",
      "1370/1370 [==============================] - 0s 221us/sample - loss: 0.3959 - val_loss: 0.4645\n",
      "Epoch 9/100\n",
      "1370/1370 [==============================] - 0s 251us/sample - loss: 0.3925 - val_loss: 0.4675\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1370/1370 [==============================] - 0s 225us/sample - loss: 0.3893 - val_loss: 0.4657\n",
      "Epoch 11/100\n",
      "1370/1370 [==============================] - 0s 219us/sample - loss: 0.3862 - val_loss: 0.4668\n",
      "Epoch 12/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3826 - val_loss: 0.4664\n",
      "Epoch 13/100\n",
      "1370/1370 [==============================] - 0s 218us/sample - loss: 0.3793 - val_loss: 0.4672\n",
      "Epoch 14/100\n",
      "1370/1370 [==============================] - 0s 217us/sample - loss: 0.3764 - val_loss: 0.4688\n",
      "Epoch 15/100\n",
      "1370/1370 [==============================] - 0s 219us/sample - loss: 0.3740 - val_loss: 0.4683\n",
      "Epoch 16/100\n",
      "1370/1370 [==============================] - 0s 220us/sample - loss: 0.3705 - val_loss: 0.4685\n",
      "Epoch 17/100\n",
      "1370/1370 [==============================] - 0s 227us/sample - loss: 0.3677 - val_loss: 0.4686\n",
      "Train on 1372 samples, validate on 343 samples\n",
      "Epoch 1/100\n",
      "1372/1372 [==============================] - 1s 720us/sample - loss: 1.0910 - val_loss: 0.9803\n",
      "Epoch 2/100\n",
      "1372/1372 [==============================] - 0s 217us/sample - loss: 0.9979 - val_loss: 0.9649\n",
      "Epoch 3/100\n",
      "1372/1372 [==============================] - 0s 222us/sample - loss: 0.9736 - val_loss: 0.9624\n",
      "Epoch 4/100\n",
      "1372/1372 [==============================] - 0s 223us/sample - loss: 0.9594 - val_loss: 0.9564\n",
      "Epoch 5/100\n",
      "1372/1372 [==============================] - 0s 217us/sample - loss: 0.9459 - val_loss: 0.9595\n",
      "Epoch 6/100\n",
      "1372/1372 [==============================] - 0s 220us/sample - loss: 0.9400 - val_loss: 0.9587\n",
      "Epoch 7/100\n",
      "1372/1372 [==============================] - 0s 223us/sample - loss: 0.9281 - val_loss: 0.9597\n",
      "Epoch 8/100\n",
      "1372/1372 [==============================] - 0s 223us/sample - loss: 0.9204 - val_loss: 0.9579\n",
      "Epoch 9/100\n",
      "1372/1372 [==============================] - 0s 221us/sample - loss: 0.9127 - val_loss: 0.9567\n",
      "Epoch 10/100\n",
      "1372/1372 [==============================] - 0s 217us/sample - loss: 0.9050 - val_loss: 0.9580\n",
      "Epoch 11/100\n",
      "1372/1372 [==============================] - 0s 221us/sample - loss: 0.9007 - val_loss: 0.9578\n",
      "Epoch 12/100\n",
      "1372/1372 [==============================] - 0s 222us/sample - loss: 0.8928 - val_loss: 0.9600\n",
      "Epoch 13/100\n",
      "1372/1372 [==============================] - 0s 221us/sample - loss: 0.8859 - val_loss: 0.9607\n",
      "Epoch 14/100\n",
      "1372/1372 [==============================] - 0s 220us/sample - loss: 0.8812 - val_loss: 0.9591\n",
      "Train on 1371 samples, validate on 342 samples\n",
      "Epoch 1/100\n",
      "1371/1371 [==============================] - 1s 713us/sample - loss: 0.4247 - val_loss: 0.3781\n",
      "Epoch 2/100\n",
      "1371/1371 [==============================] - 0s 226us/sample - loss: 0.4055 - val_loss: 0.3721\n",
      "Epoch 3/100\n",
      "1371/1371 [==============================] - 0s 256us/sample - loss: 0.3992 - val_loss: 0.3746\n",
      "Epoch 4/100\n",
      "1371/1371 [==============================] - 0s 278us/sample - loss: 0.3969 - val_loss: 0.3697\n",
      "Epoch 5/100\n",
      "1371/1371 [==============================] - 0s 290us/sample - loss: 0.3937 - val_loss: 0.3698\n",
      "Epoch 6/100\n",
      "1371/1371 [==============================] - 0s 279us/sample - loss: 0.3911 - val_loss: 0.3691\n",
      "Epoch 7/100\n",
      "1371/1371 [==============================] - 0s 292us/sample - loss: 0.3901 - val_loss: 0.3708\n",
      "Epoch 8/100\n",
      "1371/1371 [==============================] - 0s 266us/sample - loss: 0.3879 - val_loss: 0.3748\n",
      "Epoch 9/100\n",
      "1371/1371 [==============================] - 0s 274us/sample - loss: 0.3869 - val_loss: 0.3673\n",
      "Epoch 10/100\n",
      "1371/1371 [==============================] - 0s 284us/sample - loss: 0.3845 - val_loss: 0.3682\n",
      "Epoch 11/100\n",
      "1371/1371 [==============================] - 0s 279us/sample - loss: 0.3837 - val_loss: 0.3713\n",
      "Epoch 12/100\n",
      "1371/1371 [==============================] - 0s 228us/sample - loss: 0.3817 - val_loss: 0.3713\n",
      "Epoch 13/100\n",
      "1371/1371 [==============================] - 0s 243us/sample - loss: 0.3804 - val_loss: 0.3689\n",
      "Epoch 14/100\n",
      "1371/1371 [==============================] - 0s 292us/sample - loss: 0.3792 - val_loss: 0.3672\n",
      "Epoch 15/100\n",
      "1371/1371 [==============================] - 0s 276us/sample - loss: 0.3781 - val_loss: 0.3684\n",
      "Epoch 16/100\n",
      "1371/1371 [==============================] - 0s 236us/sample - loss: 0.3780 - val_loss: 0.3714\n",
      "Epoch 17/100\n",
      "1371/1371 [==============================] - 0s 282us/sample - loss: 0.3762 - val_loss: 0.3695\n",
      "Epoch 18/100\n",
      "1371/1371 [==============================] - 0s 276us/sample - loss: 0.3740 - val_loss: 0.3680\n",
      "Epoch 19/100\n",
      "1371/1371 [==============================] - 0s 278us/sample - loss: 0.3728 - val_loss: 0.3708\n",
      "Epoch 20/100\n",
      "1371/1371 [==============================] - 0s 277us/sample - loss: 0.3720 - val_loss: 0.3695\n",
      "Epoch 21/100\n",
      "1371/1371 [==============================] - 0s 226us/sample - loss: 0.3707 - val_loss: 0.3703\n",
      "Epoch 22/100\n",
      "1371/1371 [==============================] - 0s 259us/sample - loss: 0.3713 - val_loss: 0.3688\n",
      "Epoch 23/100\n",
      "1371/1371 [==============================] - 0s 275us/sample - loss: 0.3691 - val_loss: 0.3681\n",
      "Epoch 24/100\n",
      "1371/1371 [==============================] - 0s 277us/sample - loss: 0.3680 - val_loss: 0.3692\n",
      "Train on 1371 samples, validate on 342 samples\n",
      "Epoch 1/100\n",
      "1371/1371 [==============================] - 1s 804us/sample - loss: 0.4771 - val_loss: 0.4538\n",
      "Epoch 2/100\n",
      "1371/1371 [==============================] - 0s 223us/sample - loss: 0.4375 - val_loss: 0.4442\n",
      "Epoch 3/100\n",
      "1371/1371 [==============================] - 0s 226us/sample - loss: 0.4272 - val_loss: 0.4418\n",
      "Epoch 4/100\n",
      "1371/1371 [==============================] - 0s 226us/sample - loss: 0.4210 - val_loss: 0.4406\n",
      "Epoch 5/100\n",
      "1371/1371 [==============================] - 0s 230us/sample - loss: 0.4160 - val_loss: 0.4415\n",
      "Epoch 6/100\n",
      "1371/1371 [==============================] - 0s 226us/sample - loss: 0.4111 - val_loss: 0.4411\n",
      "Epoch 7/100\n",
      "1371/1371 [==============================] - 0s 290us/sample - loss: 0.4066 - val_loss: 0.4414\n",
      "Epoch 8/100\n",
      "1371/1371 [==============================] - 0s 308us/sample - loss: 0.4028 - val_loss: 0.4420\n",
      "Epoch 9/100\n",
      "1371/1371 [==============================] - 0s 323us/sample - loss: 0.3992 - val_loss: 0.4419\n",
      "Epoch 10/100\n",
      "1371/1371 [==============================] - 0s 227us/sample - loss: 0.3950 - val_loss: 0.4443\n",
      "Epoch 11/100\n",
      "1371/1371 [==============================] - 0s 223us/sample - loss: 0.3919 - val_loss: 0.4430\n",
      "Epoch 12/100\n",
      "1371/1371 [==============================] - 0s 244us/sample - loss: 0.3889 - val_loss: 0.4444\n",
      "Epoch 13/100\n",
      "1371/1371 [==============================] - 0s 288us/sample - loss: 0.3853 - val_loss: 0.4442\n",
      "Epoch 14/100\n",
      "1371/1371 [==============================] - 0s 320us/sample - loss: 0.3820 - val_loss: 0.4448\n",
      "Train on 1372 samples, validate on 343 samples\n",
      "Epoch 1/100\n",
      "1372/1372 [==============================] - 1s 856us/sample - loss: 1.1326 - val_loss: 1.0332\n",
      "Epoch 2/100\n",
      "1372/1372 [==============================] - 0s 223us/sample - loss: 1.0050 - val_loss: 0.9899\n",
      "Epoch 3/100\n",
      "1372/1372 [==============================] - 0s 222us/sample - loss: 0.9751 - val_loss: 0.9894\n",
      "Epoch 4/100\n",
      "1372/1372 [==============================] - 0s 238us/sample - loss: 0.9576 - val_loss: 0.9797\n",
      "Epoch 5/100\n",
      "1372/1372 [==============================] - 0s 254us/sample - loss: 0.9470 - val_loss: 0.9803\n",
      "Epoch 6/100\n",
      "1372/1372 [==============================] - 0s 225us/sample - loss: 0.9377 - val_loss: 0.9784\n",
      "Epoch 7/100\n",
      "1372/1372 [==============================] - 0s 226us/sample - loss: 0.9312 - val_loss: 0.9787\n",
      "Epoch 8/100\n",
      "1372/1372 [==============================] - 0s 269us/sample - loss: 0.9215 - val_loss: 0.9745\n",
      "Epoch 9/100\n",
      "1372/1372 [==============================] - 0s 238us/sample - loss: 0.9126 - val_loss: 0.9737\n",
      "Epoch 10/100\n",
      "1372/1372 [==============================] - 0s 228us/sample - loss: 0.9083 - val_loss: 0.9696\n",
      "Epoch 11/100\n",
      "1372/1372 [==============================] - 0s 230us/sample - loss: 0.8985 - val_loss: 0.9792\n",
      "Epoch 12/100\n",
      "1372/1372 [==============================] - 0s 242us/sample - loss: 0.8908 - val_loss: 0.9766\n",
      "Epoch 13/100\n",
      "1372/1372 [==============================] - 0s 305us/sample - loss: 0.8860 - val_loss: 0.9739\n",
      "Epoch 14/100\n",
      "1372/1372 [==============================] - 0s 236us/sample - loss: 0.8793 - val_loss: 0.9726\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1372/1372 [==============================] - 0s 244us/sample - loss: 0.8771 - val_loss: 0.9711\n",
      "Epoch 16/100\n",
      "1372/1372 [==============================] - 0s 222us/sample - loss: 0.8712 - val_loss: 0.9808\n",
      "Epoch 17/100\n",
      "1372/1372 [==============================] - 0s 227us/sample - loss: 0.8627 - val_loss: 0.9796\n",
      "Epoch 18/100\n",
      "1372/1372 [==============================] - 0s 226us/sample - loss: 0.8581 - val_loss: 0.9769\n",
      "Epoch 19/100\n",
      "1372/1372 [==============================] - 0s 229us/sample - loss: 0.8532 - val_loss: 0.9775\n",
      "Epoch 20/100\n",
      "1372/1372 [==============================] - 0s 229us/sample - loss: 0.8486 - val_loss: 0.9915\n",
      "Train on 1371 samples, validate on 342 samples\n",
      "Epoch 1/100\n",
      "1371/1371 [==============================] - 1s 998us/sample - loss: 0.4171 - val_loss: 0.4309\n",
      "Epoch 2/100\n",
      "1371/1371 [==============================] - 0s 209us/sample - loss: 0.3912 - val_loss: 0.4278\n",
      "Epoch 3/100\n",
      "1371/1371 [==============================] - 0s 223us/sample - loss: 0.3859 - val_loss: 0.4251\n",
      "Epoch 4/100\n",
      "1371/1371 [==============================] - 0s 231us/sample - loss: 0.3829 - val_loss: 0.4236\n",
      "Epoch 5/100\n",
      "1371/1371 [==============================] - 0s 231us/sample - loss: 0.3797 - val_loss: 0.4247\n",
      "Epoch 6/100\n",
      "1371/1371 [==============================] - 0s 226us/sample - loss: 0.3781 - val_loss: 0.4220\n",
      "Epoch 7/100\n",
      "1371/1371 [==============================] - 0s 226us/sample - loss: 0.3762 - val_loss: 0.4221\n",
      "Epoch 8/100\n",
      "1371/1371 [==============================] - 0s 223us/sample - loss: 0.3743 - val_loss: 0.4233\n",
      "Epoch 9/100\n",
      "1371/1371 [==============================] - 0s 227us/sample - loss: 0.3733 - val_loss: 0.4209\n",
      "Epoch 10/100\n",
      "1371/1371 [==============================] - 0s 226us/sample - loss: 0.3719 - val_loss: 0.4206\n",
      "Epoch 11/100\n",
      "1371/1371 [==============================] - 0s 230us/sample - loss: 0.3695 - val_loss: 0.4211\n",
      "Epoch 12/100\n",
      "1371/1371 [==============================] - 0s 223us/sample - loss: 0.3690 - val_loss: 0.4199\n",
      "Epoch 13/100\n",
      "1371/1371 [==============================] - 0s 227us/sample - loss: 0.3674 - val_loss: 0.4228\n",
      "Epoch 14/100\n",
      "1371/1371 [==============================] - 0s 227us/sample - loss: 0.3650 - val_loss: 0.4199\n",
      "Epoch 15/100\n",
      "1371/1371 [==============================] - 0s 222us/sample - loss: 0.3645 - val_loss: 0.4202\n",
      "Epoch 16/100\n",
      "1371/1371 [==============================] - 0s 224us/sample - loss: 0.3639 - val_loss: 0.4211\n",
      "Epoch 17/100\n",
      "1371/1371 [==============================] - 0s 224us/sample - loss: 0.3620 - val_loss: 0.4219\n",
      "Epoch 18/100\n",
      "1371/1371 [==============================] - 0s 226us/sample - loss: 0.3607 - val_loss: 0.4209\n",
      "Epoch 19/100\n",
      "1371/1371 [==============================] - 0s 226us/sample - loss: 0.3605 - val_loss: 0.4210\n",
      "Epoch 20/100\n",
      "1371/1371 [==============================] - 0s 227us/sample - loss: 0.3585 - val_loss: 0.4206\n",
      "Epoch 21/100\n",
      "1371/1371 [==============================] - 0s 224us/sample - loss: 0.3580 - val_loss: 0.4224\n",
      "Epoch 22/100\n",
      "1371/1371 [==============================] - 0s 225us/sample - loss: 0.3573 - val_loss: 0.4208\n",
      "Train on 1371 samples, validate on 342 samples\n",
      "Epoch 1/100\n",
      "1371/1371 [==============================] - 1s 743us/sample - loss: 0.4781 - val_loss: 0.4308\n",
      "Epoch 2/100\n",
      "1371/1371 [==============================] - 0s 225us/sample - loss: 0.4410 - val_loss: 0.4248\n",
      "Epoch 3/100\n",
      "1371/1371 [==============================] - 0s 224us/sample - loss: 0.4312 - val_loss: 0.4227\n",
      "Epoch 4/100\n",
      "1371/1371 [==============================] - 0s 226us/sample - loss: 0.4252 - val_loss: 0.4213\n",
      "Epoch 5/100\n",
      "1371/1371 [==============================] - 0s 225us/sample - loss: 0.4202 - val_loss: 0.4217\n",
      "Epoch 6/100\n",
      "1371/1371 [==============================] - 0s 224us/sample - loss: 0.4153 - val_loss: 0.4209\n",
      "Epoch 7/100\n",
      "1371/1371 [==============================] - 0s 223us/sample - loss: 0.4119 - val_loss: 0.4205\n",
      "Epoch 8/100\n",
      "1371/1371 [==============================] - 0s 241us/sample - loss: 0.4077 - val_loss: 0.4211\n",
      "Epoch 9/100\n",
      "1371/1371 [==============================] - 0s 239us/sample - loss: 0.4043 - val_loss: 0.4208\n",
      "Epoch 10/100\n",
      "1371/1371 [==============================] - 0s 268us/sample - loss: 0.4004 - val_loss: 0.4200\n",
      "Epoch 11/100\n",
      "1371/1371 [==============================] - 0s 228us/sample - loss: 0.3975 - val_loss: 0.4204\n",
      "Epoch 12/100\n",
      "1371/1371 [==============================] - 0s 224us/sample - loss: 0.3937 - val_loss: 0.4234\n",
      "Epoch 13/100\n",
      "1371/1371 [==============================] - 0s 227us/sample - loss: 0.3906 - val_loss: 0.4215\n",
      "Epoch 14/100\n",
      "1371/1371 [==============================] - 0s 244us/sample - loss: 0.3881 - val_loss: 0.4220\n",
      "Epoch 15/100\n",
      "1371/1371 [==============================] - 0s 248us/sample - loss: 0.3850 - val_loss: 0.4216\n",
      "Epoch 16/100\n",
      "1371/1371 [==============================] - 0s 239us/sample - loss: 0.3820 - val_loss: 0.4224\n",
      "Epoch 17/100\n",
      "1371/1371 [==============================] - 0s 247us/sample - loss: 0.3793 - val_loss: 0.4219\n",
      "Epoch 18/100\n",
      "1371/1371 [==============================] - 0s 247us/sample - loss: 0.3765 - val_loss: 0.4226\n",
      "Epoch 19/100\n",
      "1371/1371 [==============================] - 0s 223us/sample - loss: 0.3734 - val_loss: 0.4237\n",
      "Epoch 20/100\n",
      "1371/1371 [==============================] - 0s 234us/sample - loss: 0.3711 - val_loss: 0.4235\n",
      "Train on 1373 samples, validate on 342 samples\n",
      "Epoch 1/100\n",
      "1373/1373 [==============================] - 1s 821us/sample - loss: 1.1015 - val_loss: 1.0517\n",
      "Epoch 2/100\n",
      "1373/1373 [==============================] - 0s 285us/sample - loss: 0.9869 - val_loss: 1.0416\n",
      "Epoch 3/100\n",
      "1373/1373 [==============================] - 0s 250us/sample - loss: 0.9592 - val_loss: 1.0110\n",
      "Epoch 4/100\n",
      "1373/1373 [==============================] - 0s 240us/sample - loss: 0.9428 - val_loss: 1.0167\n",
      "Epoch 5/100\n",
      "1373/1373 [==============================] - 0s 246us/sample - loss: 0.9328 - val_loss: 1.0108\n",
      "Epoch 6/100\n",
      "1373/1373 [==============================] - 0s 248us/sample - loss: 0.9262 - val_loss: 1.0075\n",
      "Epoch 7/100\n",
      "1373/1373 [==============================] - 0s 256us/sample - loss: 0.9160 - val_loss: 1.0199\n",
      "Epoch 8/100\n",
      "1373/1373 [==============================] - 0s 266us/sample - loss: 0.9087 - val_loss: 1.0034\n",
      "Epoch 9/100\n",
      "1373/1373 [==============================] - 0s 232us/sample - loss: 0.8982 - val_loss: 1.0073\n",
      "Epoch 10/100\n",
      "1373/1373 [==============================] - 0s 226us/sample - loss: 0.8959 - val_loss: 1.0080\n",
      "Epoch 11/100\n",
      "1373/1373 [==============================] - 0s 234us/sample - loss: 0.8840 - val_loss: 1.0147\n",
      "Epoch 12/100\n",
      "1373/1373 [==============================] - 0s 233us/sample - loss: 0.8813 - val_loss: 1.0110\n",
      "Epoch 13/100\n",
      "1373/1373 [==============================] - 0s 226us/sample - loss: 0.8770 - val_loss: 1.0115\n",
      "Epoch 14/100\n",
      "1373/1373 [==============================] - 0s 240us/sample - loss: 0.8695 - val_loss: 1.0107\n",
      "Epoch 15/100\n",
      "1373/1373 [==============================] - 0s 243us/sample - loss: 0.8669 - val_loss: 1.0175\n",
      "Epoch 16/100\n",
      "1373/1373 [==============================] - 0s 230us/sample - loss: 0.8601 - val_loss: 1.0084\n",
      "Epoch 17/100\n",
      "1373/1373 [==============================] - 0s 250us/sample - loss: 0.8517 - val_loss: 1.0071\n",
      "Epoch 18/100\n",
      "1373/1373 [==============================] - 0s 258us/sample - loss: 0.8438 - val_loss: 1.0086\n"
     ]
    }
   ],
   "source": [
    "metrics = full_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gene': {'overall': {'mae': 0.7299490896746337,\n",
       "   'rmse': 1.2918968704150449,\n",
       "   'ndcg': 0.44835543717483367},\n",
       "  'annual': {'mae': array([0.41098335, 0.57326106, 0.75468637, 0.88329084, 1.02752384]),\n",
       "   'rmse': array([0.74612466, 0.97067574, 1.33166402, 1.48635163, 1.66849718]),\n",
       "   'ndcg': array([0.46505046, 0.36096419, 0.14908492, 0.19261638, 0.15743147])}},\n",
       " 'transplant': {'overall': {'mae': 0.7718043551135649,\n",
       "   'rmse': 1.2752554128409044,\n",
       "   'ndcg': 0.48122490028670706},\n",
       "  'annual': {'mae': array([0.75218725, 0.77410503, 0.74279975, 0.7759474 , 0.81398235]),\n",
       "   'rmse': array([1.30078556, 1.29846621, 1.21739863, 1.22831554, 1.31962679]),\n",
       "   'ndcg': array([0.09773368, 0.07247887, 0.02053076, 0.10604713, 0.11611737])}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gene': {'overall': {'mae': 0.7323172166659129,\n",
       "   'rmse': 1.296150959780827,\n",
       "   'ndcg': 0.39375426995433405,\n",
       "   'mape': 4.407860713666826,\n",
       "   'r2': 0.23216118467795743,\n",
       "   'pearson': 0.5154964653492857,\n",
       "   'acc': 0.34331252699477943},\n",
       "  'annual': {'mae': array([0.41667306, 0.57881098, 0.75487069, 0.88225787, 1.02897349]),\n",
       "   'rmse': array([0.75489929, 0.98624051, 1.31984687, 1.49443502, 1.67494569]),\n",
       "   'ndcg': array([0.51731997, 0.21897933, 0.15831747, 0.16538815, 0.11366666]),\n",
       "   'mape': array([3.19242965, 2.7242381 , 3.31875722, 6.27535841, 6.52852019]),\n",
       "   'r2': array([0.42758378, 0.25620273, 0.18235494, 0.04360206, 0.01077944]),\n",
       "   'pearson': array([0.66936208, 0.53171588, 0.47137955, 0.31838994, 0.25930228]),\n",
       "   'acc': array([0.60385537, 0.21832896, 0.24209849, 0.33745923, 0.31482059])}},\n",
       " 'transplant': {'overall': {'mae': 0.7708396953327952,\n",
       "   'rmse': 1.2728291969176666,\n",
       "   'ndcg': 0.49547971873051616,\n",
       "   'mape': 3.814376280019359,\n",
       "   'r2': 0.42156821867225547,\n",
       "   'pearson': 0.6577014921087001,\n",
       "   'acc': 0.32909261801286205},\n",
       "  'annual': {'mae': array([0.75587014, 0.77702044, 0.74020801, 0.76954804, 0.81155185]),\n",
       "   'rmse': array([1.30109564, 1.2970383 , 1.2171685 , 1.22326681, 1.31102306]),\n",
       "   'ndcg': array([0.03088219, 0.02123237, 0.02035066, 0.09386946, 0.12103858]),\n",
       "   'mape': array([3.26923626, 3.3395358 , 3.01516713, 6.19913425, 3.24880797]),\n",
       "   'r2': array([0.42958498, 0.41950094, 0.40894916, 0.44554339, 0.40931798]),\n",
       "   'pearson': array([0.66179803, 0.65422372, 0.64943705, 0.67761383, 0.65217729]),\n",
       "   'acc': array([0.3433267 , 0.3131761 , 0.34917541, 0.32542972, 0.31435515])}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
